{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-11T01:48:47.885574300Z",
     "start_time": "2023-09-11T01:48:42.548833900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erfan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from scipy.spatial.distance import squareform\n",
    "%matplotlib inline\n",
    "from toolz import interleave\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "N_REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on GPU')\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.TPUStrategy(TPU)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "# Number of computing cores, is 8 for a TPU V3-8\n",
    "print(f'N_REPLICAS: {N_REPLICAS}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T01:51:05.120973600Z",
     "start_time": "2023-09-11T01:51:05.106149400Z"
    }
   },
   "id": "58e3080e72ae46d8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<function tensorflow.python.eager.context.set_log_device_placement(enabled)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    If the reference is unphased, cannot handle phased target data, so the valid (ref, target) combinations are:\n",
    "    (phased, phased), (phased, unphased), (unphased, unphased)\n",
    "    Important note: for each case, the model should be trained separately\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_panel_file_path, target_file_path):\n",
    "        self.ref_n_header_lines = []\n",
    "        self.ref_n_data_header = \"\"\n",
    "        self.map_values_1_vec = np.vectorize(self.map_hap_2_ind_parent_1)\n",
    "        self.map_values_2_vec = np.vectorize(self.map_hap_2_ind_parent_2)\n",
    "        print(\"Rading the reference file...\")\n",
    "        # get header\n",
    "        root, ext = os.path.splitext(reference_panel_file_path)\n",
    "        with gzip.open(reference_panel_file_path, 'rt') if ext == '.gz' else open(reference_panel_file_path, 'rt') as f_in:\n",
    "            # skip info\n",
    "            while True:\n",
    "                line = f_in.readline()\n",
    "                if line.startswith(\"##\"):\n",
    "                    self.ref_n_header_lines.append(line)\n",
    "                else:\n",
    "                    self.ref_n_data_header = line\n",
    "                    break\n",
    "        self.reference_panel = pd.read_csv(reference_panel_file_path,\n",
    "                                           comment='#',\n",
    "                                           sep='\\t',\n",
    "                                           names=self.ref_n_data_header.strip().split('\\t'))\n",
    "        self.VARIANT_COUNT = self.reference_panel.shape[0]\n",
    "        print(f\"{self.VARIANT_COUNT} variants found. Done!\")\n",
    "        print(\"Rading the target file...\")\n",
    "        self.target_n_header_lines = []\n",
    "        self.target_n_data_header = \"\"\n",
    "        root, ext = os.path.splitext(target_file_path)\n",
    "        # get header\n",
    "        with gzip.open(target_file_path, 'rt') if ext == '.gz' else open(target_file_path, 'rt') as f_in:\n",
    "            # skip info\n",
    "            while True:\n",
    "                line = f_in.readline()\n",
    "                if line.startswith(\"##\"):\n",
    "                    self.target_n_header_lines.append(line)\n",
    "                else:\n",
    "                    self.target_n_data_header = line\n",
    "                    break\n",
    "        real_target_set = pd.read_csv(target_file_path,\n",
    "                                           comment='#',\n",
    "                                           sep='\\t',\n",
    "                                           names=self.target_n_data_header.strip().split('\\t'),)\n",
    "        print(f\"{real_target_set.shape[0]} variants found. Done!\")\n",
    "        target_is_phased = \"|\" in real_target_set.iloc[0, 10]\n",
    "        ref_is_phased = \"|\" in self.reference_panel.iloc[0, 10]\n",
    "        self.is_phased = target_is_phased and ref_is_phased\n",
    "        print(\"Creating the new target dataframe\")\n",
    "        self.target_set = real_target_set.merge(self.reference_panel[\"ID\"], on='ID', how='right')\n",
    "        self.target_set[self.reference_panel.columns[:9]] = self.reference_panel[self.reference_panel.columns[:9]]\n",
    "        self.target_set.fillna(\".|.\" if self.is_phased else \"./.\", inplace=True)\n",
    "        print(\"Extracting genotype information...\")\n",
    "        SEP = \"|\" if self.is_phased else \"/\"\n",
    "        def get_num_allels(g):\n",
    "            v1, v2 = g.split(SEP)\n",
    "            return max(int(v1), int(v2)) + 1\n",
    "\n",
    "        def key_gen(v1, v2):\n",
    "            return f\"{v1}{SEP}{v2}\"\n",
    "\n",
    "        genotype_vals = np.unique(self.reference_panel.iloc[:, 9:].values)\n",
    "        if target_is_phased != ref_is_phased:\n",
    "            phased_to_unphased_dict = {}\n",
    "            for i in range(genotype_vals.shape[0]):\n",
    "                key = genotype_vals[i]\n",
    "                v1, v2 = [int(s) for s in genotype_vals[i].split(\"|\")]\n",
    "                genotype_vals[i] = f\"{min(v1, v2)}{SEP}{max(v1, v2)}\"\n",
    "                phased_to_unphased_dict[key] = genotype_vals[i]\n",
    "            self.reference_panel.replace(phased_to_unphased_dict, inplace=True)\n",
    "        genotype_vals = np.unique(genotype_vals)\n",
    "        allele_count = max(map(get_num_allels, genotype_vals))\n",
    "        if self.is_phased:\n",
    "            self.hap_map = {str(i): i for i in range(allele_count)}\n",
    "            self.hap_map.update({\".\": allele_count})\n",
    "            self.r_hap_map = {i:k for k, i in self.hap_map.items()}\n",
    "            self.map_preds_2_allele = np.vectorize(lambda x: self.r_hap_map[x])\n",
    "        self.MISSING_VALUE = self.SEQ_DEPTH = allele_count + 1 if self.is_phased else len(genotype_vals) + 1\n",
    "        self.genotype_keys = np.array([key_gen(i,j) for i in range(allele_count) for j in range(allele_count)]) if self.is_phased else genotype_vals\n",
    "        self.genotype_keys = np.hstack([self.genotype_keys, [\".|.\"] if self.is_phased else [\"./.\"]])\n",
    "        self.replacement_dict = {g:i for i,g in enumerate(self.genotype_keys)}\n",
    "        self.reverse_replacement_dict = {i:g for g,i in self.replacement_dict.items()}\n",
    "\n",
    "    def map_hap_2_ind_parent_1(self, x):\n",
    "        return self.hap_map[x.split('|')[0]]\n",
    "\n",
    "    def map_hap_2_ind_parent_2(self, x):\n",
    "        return self.hap_map[x.split('|')[1]]\n",
    "\n",
    "    def __get_forward_data(self, data: pd.DataFrame):\n",
    "        if self.is_phased:\n",
    "            # break it into haplotypes\n",
    "            _x = np.empty((data.shape[1] * 2, data.shape[0]), dtype=np.int32)\n",
    "\n",
    "            _x[0::2] = self.map_values_1_vec(data.values.T)\n",
    "            _x[1::2] = self.map_values_2_vec(data.values.T)\n",
    "            return _x\n",
    "        else:\n",
    "            return data.replace(self.replacement_dict).values.T.astype(np.int32)\n",
    "\n",
    "    def get_ref_set(self, starting_var_index=None, ending_var_index=None):\n",
    "        if starting_var_index>=0 and ending_var_index>=starting_var_index:\n",
    "            return self.__get_forward_data(self.reference_panel.iloc[starting_var_index:ending_var_index, 9:])\n",
    "        else:\n",
    "            print(\"No variant indices provided or indices not valid, using the whole sequence...\")\n",
    "            return self.__get_forward_data(self.reference_panel.iloc[:, 9:])\n",
    "\n",
    "    def get_target_set(self, starting_var_index=None, ending_var_index=None):\n",
    "        if starting_var_index>=0 and ending_var_index>=starting_var_index:\n",
    "            return self.__get_forward_data(self.target_set.iloc[starting_var_index:ending_var_index, 9:])\n",
    "        else:\n",
    "            print(\"No variant indices provided or indices not valid, using the whole sequence...\")\n",
    "            return self.__get_forward_data(self.target_set.iloc[:, 9:])\n",
    "\n",
    "    def convert_haps_to_genotypes(self, allele_probs):\n",
    "      '''output format: GT:DS:GP'''\n",
    "      FORMAT = \"GT:DS:GP\"\n",
    "      n_haploids, n_variants, n_alleles = allele_probs.shape\n",
    "      allele_probs_normalized = softmax(allele_probs, axis=-1)\n",
    "\n",
    "      if n_haploids % 2 != 0:\n",
    "          raise ValueError(\"Number of haploids should be even.\")\n",
    "\n",
    "      n_samples = n_haploids // 2\n",
    "      genotypes = np.zeros((n_samples, n_variants), dtype=object)\n",
    "\n",
    "      for i in tqdm(range(n_samples)):\n",
    "        haploid_1 = allele_probs_normalized[2 * i]\n",
    "        haploid_2 = allele_probs_normalized[2 * i + 1]\n",
    "\n",
    "        for j in range(n_variants):\n",
    "          phased_probs = np.multiply.outer(haploid_1[j], haploid_2[j]).flatten()\n",
    "          unphased_probs = np.array([phased_probs[0], sum(phased_probs[1:3]), phased_probs[-1]])\n",
    "          unphased_probs_str = \",\".join([f\"{v:.6f}\" for v in unphased_probs])\n",
    "          alt_dosage = np.dot(unphased_probs, [0, 1, 2])\n",
    "          variant_genotypes = [str(v) for v in np.argmax(allele_probs_normalized[i*2:(i+1)*2, j], axis=-1)]\n",
    "          genotypes[i, j] = '|'.join(variant_genotypes) + f\":{alt_dosage:.3f}:{unphased_probs_str}\"\n",
    "\n",
    "      new_vcf = self.target_set.copy()\n",
    "      new_vcf.iloc[:n_variants, 9:] = genotypes.T\n",
    "      new_vcf[\"FORMAT\"] = FORMAT\n",
    "      new_vcf[\"QUAL\"] = \".\"\n",
    "      new_vcf[\"FILTER\"] = \".\"\n",
    "      new_vcf[\"INFO\"] = \"IMPUTED\"\n",
    "      return new_vcf\n",
    "\n",
    "    def convert_unphased_probs_to_genotypes(self, allele_probs):\n",
    "      '''output format: GT:DS:GP'''\n",
    "      FORMAT = \"GT:DS:GP\"\n",
    "      n_samples, n_variants, n_alleles = allele_probs.shape\n",
    "      allele_probs_normalized = softmax(allele_probs, axis=-1)\n",
    "      genotypes = np.zeros((n_samples, n_variants), dtype=object)\n",
    "\n",
    "      for i in tqdm(range(n_samples)):\n",
    "          for j in range(n_variants):\n",
    "              unphased_probs = allele_probs_normalized[i, j]\n",
    "              unphased_probs_str = \",\".join([f\"{v:.6f}\" for v in unphased_probs])\n",
    "              alt_dosage = np.dot(unphased_probs, [0, 1, 2])\n",
    "              variant_genotypes = np.vectorize(self.reverse_replacement_dict.get)(np.argmax(unphased_probs, axis=-1)).flatten()\n",
    "              genotypes[i, j] = '/'.join(variant_genotypes) + f\":{unphased_probs_str}:{alt_dosage:.3f}\"\n",
    "\n",
    "      new_vcf = self.target_set.copy()\n",
    "      new_vcf.iloc[:, 9:] = genotypes.T\n",
    "      new_vcf[\"FORMAT\"] = FORMAT\n",
    "      new_vcf[\"QUAL\"] = \".\"\n",
    "      new_vcf[\"FILTER\"] = \".\"\n",
    "      new_vcf[\"INFO\"] = \"IMPUTED\"\n",
    "      return new_vcf\n",
    "\n",
    "    def __get_headers_for_output(self):\n",
    "      headers = [\"##fileformat=VCFv4.2\",\n",
    "           '''##source=STI v1.0.0''',\n",
    "           '''##INFO=<ID=IMPUTED,Number=0,Type=Flag,Description=\"Marker was imputed\">''',\n",
    "           '''##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">''',\n",
    "           '''##FORMAT=<ID=DS,Number=A,Type=Float,Description=\"Estimated Alternate Allele Dosage : [P(0/1)+2*P(1/1)]\">''',\n",
    "           '''##FORMAT=<ID=GP,Number=G,Type=Float,Description=\"Estimated Posterior Probabilities for Genotypes 0/0, 0/1 and 1/1\">''']\n",
    "      return headers\n",
    "\n",
    "    def preds_to_genotypes(self, preds):\n",
    "        \"\"\"\n",
    "        WARNING: This only supports bi-allelic data right now!\n",
    "        :param preds: numpy array of (n_samples, n_variants, n_alleles)\n",
    "        :return: numpy array of the same shape, with genotype calls, e.g., \"0/1\"\n",
    "        \"\"\"\n",
    "        if self.is_phased:\n",
    "          return self.convert_haps_to_genotypes(preds)\n",
    "        else:\n",
    "          return self.convert_unphased_probs_to_genotypes(preds)\n",
    "\n",
    "    def write_ligated_results_to_vcf(self, df, file_name):\n",
    "      with gzip.open(file_name, 'wt') if file_name.endswith(\".gz\") else open(file_name, 'wt') as f_out:\n",
    "          # write info\n",
    "          f_out.write(\"\\n\".join(self.__get_headers_for_output())+\"\\n\")\n",
    "      df.to_csv(file_name, sep=\"\\t\", mode='a', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T01:49:11.141485100Z",
     "start_time": "2023-09-11T01:49:11.122423900Z"
    }
   },
   "id": "addd78d2ffdfdbf0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fecfa6c805e681e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
