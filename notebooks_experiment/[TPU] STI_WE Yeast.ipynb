{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9691,"status":"ok","timestamp":1673128238929,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"liJJGzQp4qzO","outputId":"4aa035e9-3a14-4548-e2a1-f3cc8ce315c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n","Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (0.12.0)\n"]}],"source":["!pip install tensorflow-addons\n","!pip install pyyaml h5py\n","!pip install toolz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20898,"status":"ok","timestamp":1673128259823,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"s-9aa8yrHj9j","outputId":"8c7b4d84-280c-43ad-e725-a45563057dcb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2693,"status":"ok","timestamp":1673128262511,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"ZWzi3Z3L5RO2","outputId":"613f14ad-fbb9-447c-f851-c0a603650648"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Tensorflow version 2.9.2\n"]}],"source":["import numpy as np\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","print(\"Tensorflow version \" + tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"RjGOO5PdFPf7"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1921,"status":"ok","timestamp":1673128264430,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"odmhCqSVFPf8","outputId":"efe0b1da-d80a-4796-a951-7e7189019590"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version 2.9.2\n"]}],"source":["import os\n","# os.environ[\"MODIN_CPUS\"] = \"8\"\n","# from distributed import Client\n","# client = Client()\n","import numpy as np\n","import math\n","import re\n","import random\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import layers\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow_addons as tfa\n","from sklearn import metrics\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import constraints\n","from tensorflow.keras import initializers\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.applications import efficientnet as efn\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from tensorflow.keras.constraints import Constraint\n","# import allel\n","from scipy.spatial.distance import squareform\n","%matplotlib inline   \n","from toolz import interleave\n","from tqdm import tqdm\n","from matplotlib import pyplot as plt\n","import tensorflow_datasets as tfds\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import LassoCV, ElasticNetCV\n","from sklearn.model_selection import KFold,StratifiedKFold\n","\n","print(\"Tensorflow version \" + tf.__version__)\n","# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","# tf.config.experimental_connect_to_cluster(resolver)\n","# # This is the TPU initialization code that has to be at the beginning.\n","# tf.tpu.experimental.initialize_tpu_system(resolver)\n","# print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","# strategy = tf.distribute.TPUStrategy(resolver)"]},{"cell_type":"markdown","metadata":{"id":"SLd26RspFhaS"},"source":["## Hardware Config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8261,"status":"ok","timestamp":1673128272688,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"SLd7mAFgFUnR","outputId":"60a90a16-7f85-4d65-d78b-10465da724a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.7.162.162:8470\n","N_REPLICAS: 8\n"]}],"source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', TPU.master())\n","except ValueError:\n","    print('Running on GPU')\n","    TPU = None\n","\n","if TPU:\n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    strategy = tf.distribute.TPUStrategy(TPU)\n","else:\n","    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","N_REPLICAS = strategy.num_replicas_in_sync\n","# Number of computing cores, is 8 for a TPU V3-8\n","print(f'N_REPLICAS: {N_REPLICAS}')"]},{"cell_type":"markdown","metadata":{"id":"A77GFE3xFPf8"},"source":["## Prepare the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3zy8i_8FPf_"},"outputs":[],"source":["# load genotype\n","genotypes = pd.read_csv('/[path]]/genotype_full.txt', sep='\\t', index_col=0)\n","genotypes[genotypes == -1] = 0\n","\n","headers = genotypes.columns[:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673128311502,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"H2LdnKzXnW0P","outputId":"f7071ba3-fc5f-42e7-a49c-eeb313f7a224"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       33070_chrI_33070_A_T  33147_chrI_33147_G_T  33152_chrI_33152_T_C  \\\n","SAMID                                                                     \n","01_01                     1                     1                     1   \n","01_02                     1                     1                     1   \n","01_03                     0                     0                     0   \n","01_04                     1                     1                     1   \n","01_06                     0                     0                     0   \n","\n","       33200_chrI_33200_C_T  33293_chrI_33293_A_T  33328_chrI_33328_C_A  \\\n","SAMID                                                                     \n","01_01                     1                     1                     1   \n","01_02                     1                     1                     1   \n","01_03                     0                     0                     0   \n","01_04                     1                     1                     1   \n","01_06                     0                     0                     0   \n","\n","       33348_chrI_33348_G_C  33403_chrI_33403_C_T  33502_chrI_33502_A_G  \\\n","SAMID                                                                     \n","01_01                     1                     1                     1   \n","01_02                     1                     1                     1   \n","01_03                     0                     0                     0   \n","01_04                     1                     1                     1   \n","01_06                     0                     0                     0   \n","\n","       33548_chrI_33548_A_C  ...  12048853_chrXVI_925593_G_C  \\\n","SAMID                        ...                               \n","01_01                     1  ...                           0   \n","01_02                     1  ...                           0   \n","01_03                     0  ...                           1   \n","01_04                     1  ...                           1   \n","01_06                     0  ...                           0   \n","\n","       12049199_chrXVI_925939_T_C  12049441_chrXVI_926181_C_T  \\\n","SAMID                                                           \n","01_01                           0                           0   \n","01_02                           0                           0   \n","01_03                           1                           1   \n","01_04                           1                           1   \n","01_06                           0                           0   \n","\n","       12050613_chrXVI_927353_T_G  12051167_chrXVI_927907_A_C  \\\n","SAMID                                                           \n","01_01                           0                           0   \n","01_02                           0                           0   \n","01_03                           1                           1   \n","01_04                           1                           1   \n","01_06                           0                           0   \n","\n","       12051240_chrXVI_927980_A_G  12051367_chrXVI_928107_C_T  \\\n","SAMID                                                           \n","01_01                           0                           0   \n","01_02                           0                           0   \n","01_03                           1                           1   \n","01_04                           1                           1   \n","01_06                           0                           0   \n","\n","       12052782_chrXVI_929522_C_T  12052988_chrXVI_929728_A_G  \\\n","SAMID                                                           \n","01_01                           0                           0   \n","01_02                           0                           0   \n","01_03                           1                           1   \n","01_04                           1                           1   \n","01_06                           0                           0   \n","\n","       12053130_chrXVI_929870_C_T  \n","SAMID                              \n","01_01                           0  \n","01_02                           0  \n","01_03                           1  \n","01_04                           1  \n","01_06                           0  \n","\n","[5 rows x 28220 columns]"],"text/html":["\n","  <div id=\"df-05922ead-5f72-4af5-afed-e63f79bc9024\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>33070_chrI_33070_A_T</th>\n","      <th>33147_chrI_33147_G_T</th>\n","      <th>33152_chrI_33152_T_C</th>\n","      <th>33200_chrI_33200_C_T</th>\n","      <th>33293_chrI_33293_A_T</th>\n","      <th>33328_chrI_33328_C_A</th>\n","      <th>33348_chrI_33348_G_C</th>\n","      <th>33403_chrI_33403_C_T</th>\n","      <th>33502_chrI_33502_A_G</th>\n","      <th>33548_chrI_33548_A_C</th>\n","      <th>...</th>\n","      <th>12048853_chrXVI_925593_G_C</th>\n","      <th>12049199_chrXVI_925939_T_C</th>\n","      <th>12049441_chrXVI_926181_C_T</th>\n","      <th>12050613_chrXVI_927353_T_G</th>\n","      <th>12051167_chrXVI_927907_A_C</th>\n","      <th>12051240_chrXVI_927980_A_G</th>\n","      <th>12051367_chrXVI_928107_C_T</th>\n","      <th>12052782_chrXVI_929522_C_T</th>\n","      <th>12052988_chrXVI_929728_A_G</th>\n","      <th>12053130_chrXVI_929870_C_T</th>\n","    </tr>\n","    <tr>\n","      <th>SAMID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01_01</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>01_02</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>01_03</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>01_04</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>01_06</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28220 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05922ead-5f72-4af5-afed-e63f79bc9024')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-05922ead-5f72-4af5-afed-e63f79bc9024 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-05922ead-5f72-4af5-afed-e63f79bc9024');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["genotypes.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1673128311503,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"hiP0EEwsEMNP","outputId":"d7f3f2bf-180e-4482-e212-f80417b53214"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4390, 28220)"]},"metadata":{},"execution_count":8}],"source":["X = genotypes\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pZoO-FvKdr3"},"outputs":[],"source":["# hyperparameters\n","feature_size = X.shape[1]\n","inChannel = 3\n","learning_rate = 0.01\n","weight_decay = 0.00001\n","embed_dim = 64  # Embedding size for each token\n","num_heads = 8 # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n","regularization_coef_l1 = 1e-4\n","batch_size = 20\n","dropout_rate = 0.25\n","attention_range = 100\n","chunk_size = 1000"]},{"cell_type":"markdown","metadata":{"id":"LtSxW2eMOOCU"},"source":["## Convert to tensorflow dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDiVoe67JHcy"},"outputs":[],"source":["@tf.function()\n","def add_attention_mask(X_sample, y_sample):\n","  depth = 3\n","  mask_size = tf.cast(X_sample.shape[0]*0.5, dtype=tf.int64)\n","  mask_idx = tf.reshape(tf.random.shuffle(tf.range(X_sample.shape[0]))[:mask_size], (-1, 1))\n","  updates = tf.math.add(tf.ones(shape=(mask_idx.shape[0]), dtype=tf.int64), 1)\n","  X_masked = tf.tensor_scatter_nd_update(X_sample, mask_idx, updates)\n","\n","  return tf.one_hot(X_masked, depth), tf.one_hot(y_sample, depth-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlyxYCy96H7V"},"outputs":[],"source":["def map_values_1(x):\n","  return 0 if (x == 0 or x == 1) else 1\n","\n","def map_values_2(x):\n","  return 0 if (x == 0 or x == 2) else 1\n","\n","def get_dataset(x, chunk_start, chunk_end, start_offset, end_offset, batch_size, training=True):\n","  AUTO = tf.data.AUTOTUNE\n","  new_chunk_end = x.shape[1]\n","\n","  dataset = tf.data.Dataset.from_tensor_slices((x,\n","                                                x[:, start_offset:new_chunk_end-end_offset]))\n","  \n","  if training:\n","    dataset = dataset.shuffle(x.shape[0], reshuffle_each_iteration=True)\n","    dataset = dataset.repeat()\n","  \n","  # Add Attention Mask\n","  dataset = dataset.map(add_attention_mask, num_parallel_calls=AUTO, deterministic=False)\n","\n","  # Prefetech to not map the whole dataset\n","  dataset = dataset.prefetch(AUTO)\n","\n","  dataset = dataset.batch(batch_size, drop_remainder=True, num_parallel_calls=AUTO)\n","\n","  return dataset"]},{"cell_type":"markdown","metadata":{"id":"NpRUjMp_L914"},"source":["## Custom Layers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sD7WOyyoNYGv"},"outputs":[],"source":["class CrossAttentionLayer(layers.Layer):\n","  def __init__(self, local_dim, global_dim,\n","               start_offset=0, end_offset=0,\n","               activation=tf.nn.gelu, dropout_rate=0.1,\n","               n_heads=num_heads):\n","    super(CrossAttentionLayer, self).__init__()\n","    self.local_dim = local_dim\n","    self.global_dim = global_dim\n","    self.dropout_rate = dropout_rate\n","    self.activation = activation\n","    self.start_offset = start_offset\n","    self.end_offset = end_offset\n","    self.num_heads = n_heads\n","    self.layer_norm00 = layers.LayerNormalization()\n","    self.layer_norm01 = layers.LayerNormalization()\n","    self.layer_norm1 = layers.LayerNormalization()\n","    self.ffn = tf.keras.Sequential(\n","          [\n","            layers.Dense(self.local_dim//2, activation=self.activation, \n","                        ),\n","            layers.Dense(self.local_dim, \n","                        activation=self.activation,\n","                        ), ]\n","      )\n","    self.add0 = layers.Add()\n","    self.add1 = layers.Add()\n","    self.attention = layers.MultiHeadAttention(num_heads=self.num_heads,\n","                                               key_dim=self.local_dim,)\n","\n","  def call(self, inputs, training):\n","    local_repr = self.layer_norm00(inputs[0])\n","    global_repr = self.layer_norm01(inputs[1])\n","    query = local_repr[:, self.start_offset:local_repr.shape[1]-self.end_offset, :]\n","    key = global_repr\n","    value = global_repr\n","\n","    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n","    attention_output = self.attention(\n","        query, key, value\n","    )\n","    # Skip connection 1.\n","    attention_output = self.add0([attention_output, query])\n","\n","    # Apply layer norm.\n","    attention_output = self.layer_norm1(attention_output)\n","    # Apply Feedforward network.\n","    outputs = self.ffn(attention_output)\n","    # Skip connection 2.\n","    outputs = self.add1([outputs, attention_output])\n","    return outputs\n","\n","class MaskedTransformerBlock(layers.Layer):\n","  def __init__(self, embed_dim, num_heads, ff_dim, attention_range, start_offset=0, end_offset=0, attn_block_repeats=1, activation=tf.nn.gelu, dropout_rate=0.1, use_ffn=True):\n","    super(MaskedTransformerBlock, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.num_heads = num_heads\n","    self.ff_dim = ff_dim\n","    self.start_offset = start_offset\n","    self.end_offset = end_offset\n","    self.attention_range = attention_range\n","    self.attn_block_repeats = attn_block_repeats\n","    self.activation = activation\n","    self.dropout_rate = dropout_rate\n","    self.use_ffn = use_ffn\n","    self.att0 = [layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim) for _ in range(attn_block_repeats)]\n","    if self.use_ffn:\n","      self.ffn = [tf.keras.Sequential(\n","          [\n","            layers.Dense(self.ff_dim, activation=self.activation, \n","                        ),\n","            layers.Dense(self.embed_dim, \n","                        activation=self.activation,\n","                        ), ]\n","      ) for _ in range(attn_block_repeats)]\n","    self.layer_norm0 = [layers.LayerNormalization() for _ in range(attn_block_repeats)]\n","    self.layer_norm1 = [layers.LayerNormalization() for _ in range(attn_block_repeats)]\n","\n","  def build(self, input_shape):\n","    assert(self.end_offset >= 0)\n","    self.feature_size = input_shape[1]\n","    attention_mask = np.zeros((self.feature_size,\n","                               self.feature_size), dtype=bool)\n","    for i in range(self.start_offset, self.feature_size - self.end_offset):\n","      attention_indices = np.arange(max(0, i-self.attention_range), min(self.feature_size, i+self.attention_range))\n","      attention_mask[i, attention_indices] = True\n","    self.attention_mask = tf.constant(attention_mask[self.start_offset:self.feature_size-self.end_offset])\n","\n","  def call(self, inputs, training):\n","    \n","    x = inputs\n","    for i in range(self.attn_block_repeats-1):\n","      x = self.layer_norm0[i](x)\n","      attn_output = self.att0[i](x, x)\n","      out1 = x + attn_output\n","      out1 = self.layer_norm1[i](out1)\n","      if self.use_ffn:\n","        ffn_output = self.ffn[i](out1)\n","        x = out1 + ffn_output\n","      else:\n","        x = out1\n","\n","    x = self.layer_norm0[-1](inputs)\n","    attn_output = self.att0[-1](x[:, self.start_offset:x.shape[1]-self.end_offset, :], x,\n","                            )\n","    out1 = x[:, self.start_offset:x.shape[1]-self.end_offset, :] + attn_output\n","    out1 = self.layer_norm1[-1](out1)\n","    if self.use_ffn:\n","      ffn_output = self.ffn[-1](out1)\n","      x = out1 + ffn_output\n","    else:\n","      x = out1\n","    return x\n","\n","class GenoEmbeddings(layers.Layer):\n","  def __init__(self, embedding_dim, \n","               embeddings_initializer='glorot_uniform',\n","               embeddings_regularizer=None,\n","               activity_regularizer=None,\n","               embeddings_constraint=None):\n","    super(GenoEmbeddings, self).__init__()\n","    self.embedding_dim = embedding_dim\n","    self.embeddings_initializer = initializers.get(embeddings_initializer)\n","    self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n","    self.activity_regularizer = regularizers.get(activity_regularizer)\n","    self.embeddings_constraint = constraints.get(embeddings_constraint)\n","\n","  def build(self, input_shape):\n","    # print(input_shape)\n","    \n","    self.num_of_allels = input_shape[-1]\n","    self.n_snps = input_shape[-2]\n","    self.position_embedding = layers.Embedding(\n","            input_dim=self.n_snps, output_dim=self.embedding_dim\n","        )\n","    self.embedding = self.add_weight(\n","            shape=(self.num_of_allels, self.embedding_dim),\n","            initializer=self.embeddings_initializer,\n","            trainable=True, name='geno_embeddings',\n","            regularizer=self.embeddings_regularizer,\n","            constraint=self.embeddings_constraint,\n","            experimental_autocast=False\n","        )\n","    self.positions = tf.range(start=0, limit=self.n_snps, delta=1)\n","  def call(self, inputs):\n","    self.immediate_result = tf.einsum('ijk,kl->ijl', inputs, self.embedding)\n","    return self.immediate_result + self.position_embedding(self.positions)\n","\n","\n","class Chunker(layers.Layer):\n","  def __init__(self, embed_dim, num_heads, ff_dim, chk_size=chunk_size,\n","               activation=tf.nn.gelu, dropout_rate=0.25, attn_block_repeats=1,\n","               attention_range=attention_range, include_embedding_layer=False):\n","    super(Chunker, self).__init__()\n","    self.concat = layers.Concatenate(axis=-2)\n","    self.chunk_size = chk_size\n","    self.embed_dim = embed_dim\n","    self.num_heads = num_heads\n","    self.ff_dim = ff_dim\n","    self.activation = activation\n","    self.dropout_rate = dropout_rate\n","    self.attention_range = attention_range\n","    self.attn_block_repeats = attn_block_repeats\n","    self.include_embedding_layer = include_embedding_layer\n","    \n","  def build(self, input_shape):\n","    self.chunk_starts = list(range(0, input_shape[1], self.chunk_size))\n","    self.chunk_ends = []\n","    for cs in self.chunk_starts:\n","      self.chunk_ends.append(min(cs+self.chunk_size, input_shape[1]))\n","    self.mask_starts = [max(0, cs-self.attention_range) for cs in self.chunk_starts]\n","    self.mask_ends = [min(ce+self.attention_range, input_shape[1]) for ce in self.chunk_ends]\n","    self.chunkers = [SelfAttnChunk(self.embed_dim, self.num_heads, self.ff_dim,\n","                           attention_range,\n","                           include_embedding_layer=self.include_embedding_layer,\n","                           start_offset=cs - self.mask_starts[i], \n","                            end_offset=self.mask_ends[i]-self.chunk_ends[i],\n","                           attn_block_repeats=self.attn_block_repeats) for i, cs in enumerate(self.chunk_starts)]\n","\n","  def call(self, inputs, training):\n","    x = inputs\n","    chunks = [chunker(x[:, self.mask_starts[i]:self.mask_ends[i]]) for i, chunker in enumerate(self.chunkers)]\n","    y = self.concat(chunks)\n","    return y\n","\n","\n","class SelfAttnChunk(layers.Layer):\n","  def __init__(self, embed_dim, num_heads, ff_dim, attention_range,\n","               start_offset=0, end_offset=0,\n","               attn_block_repeats=1,\n","               include_embedding_layer=False):\n","    super(SelfAttnChunk, self).__init__()\n","    self.attention_range = attention_range\n","    self.ff_dim = ff_dim\n","    self.num_heads = num_heads\n","    self.embed_dim = embed_dim\n","    self.attn_block_repeats = attn_block_repeats\n","    self.include_embedding_layer = include_embedding_layer\n","\n","    self.attention_block = MaskedTransformerBlock(self.embed_dim,\n","                                                   self.num_heads, self.ff_dim,\n","                                                   attention_range, start_offset,\n","                                                   end_offset, attn_block_repeats=1)\n","    if include_embedding_layer:\n","      self.embedding = GenoEmbeddings(embed_dim)\n","    \n","\n","  def build(self, input_shape):\n","    pass\n","  \n","  def call(self, inputs, training):\n","    if self.include_embedding_layer:\n","      x = self.embedding(inputs)\n","    else:\n","      x = inputs\n","    x = self.attention_block(x)\n","    return x\n","\n","class CrossAttnChunk(layers.Layer):\n","  def __init__(self, start_offset=0, end_offset=0, n_heads = num_heads):\n","    super(CrossAttnChunk, self).__init__()\n","    self.attention_range = attention_range\n","    self.start_offset = start_offset\n","    self.end_offset = end_offset\n","    self.n_heads = n_heads\n","    \n","\n","  def build(self, input_shape):\n","    self.local_dim = input_shape[0][-1]\n","    self.global_dim = input_shape[1][-1]\n","    self.attention_block = CrossAttentionLayer(self.local_dim, self.global_dim,\n","                                              self.start_offset, self.end_offset,\n","                                              n_heads=self.n_heads)\n","    pass\n","  \n","  def call(self, inputs, training):\n","    x = inputs\n","    x = self.attention_block(x)\n","    return x\n"]},{"cell_type":"markdown","source":["## Modules"],"metadata":{"id":"HqmHhclvOPiU"}},{"cell_type":"code","source":["class ConvBlock(layers.Layer):\n","  def __init__(self, embed_dim):\n","    super(ConvBlock, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.const = None\n","    self.conv000 = layers.Conv1D(embed_dim, 3, padding='same', activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,\n","                    )\n","    self.conv010 = layers.Conv1D(embed_dim, 5, padding='same', activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,\n","                    )\n","    self.conv011 = layers.Conv1D(embed_dim, 7, padding='same', activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,\n","                    )\n","    \n","    self.conv020 = layers.Conv1D(embed_dim, 7, padding='same', activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,\n","                    )\n","    self.conv021 = layers.Conv1D(embed_dim, 15, padding='same', activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,\n","                    )\n","    self.add = layers.Add()\n","    \n","    self.conv100 = layers.Conv1D(embed_dim, 3, padding='same',\n","                                 activation=tf.nn.gelu,\n","                                 kernel_constraint=self.const,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,)\n","    self.bn0 = layers.BatchNormalization()\n","    self.bn1 = layers.BatchNormalization()\n","    self.dw_conv = layers.DepthwiseConv1D(embed_dim, 1, padding='same',\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,)\n","    self.activation = layers.Activation(tf.nn.gelu)\n","\n","\n","  def call(self, inputs, training):\n","    xa = self.conv000(inputs)\n","    \n","    xb = self.conv010(xa)\n","    xb = self.conv011(xb)\n","\n","    xc = self.conv020(xa)\n","    xc = self.conv021(xc)\n","\n","    xa = self.add([xb, xc])\n","    xa = self.conv100(xa)\n","    xa = self.bn0(xa)\n","    xa = self.dw_conv(xa)\n","    xa = self.bn1(xa)\n","    xa = self.activation(xa)\n","    return xa\n","\n","def chunk_module(embed_dim, num_heads, input_len, input_channels, attention_range,\n","               start_offset=0, end_offset=0,\n","               attn_block_repeats=1, include_embedding=False):\n","  projection_dim = embed_dim\n","  inputs = layers.Input(shape=(input_len, embed_dim))\n","  xa = inputs\n","  xa0 = SelfAttnChunk(projection_dim, num_heads, projection_dim//2, attention_range,\n","            start_offset, end_offset, 1, include_embedding_layer=False)(xa)\n","  \n","  xa = ConvBlock(projection_dim)(xa0)\n","  xa_skip = ConvBlock(projection_dim)(xa)\n","\n","  xa = layers.Dense(projection_dim, activation=tf.nn.gelu)(xa)\n","  xa = ConvBlock(projection_dim)(xa)\n","  xa = CrossAttnChunk(0, 0)([xa, xa0])\n","  xa = layers.Dropout(0.25)(xa)\n","  xa = ConvBlock(projection_dim)(xa)\n","\n","  xa = layers.Concatenate(axis=-1)([xa_skip, xa])\n","  \n","  xa = layers.Conv1D(projection_dim//2, 5, padding='same', activation=tf.nn.gelu,\n","                                 kernel_initializer=tf.keras.initializers.variance_scaling,)(xa)\n","  \n","  xa_out1 = layers.Conv1D(inChannel - 1, 5, padding='same',\n","                          kernel_initializer=tf.keras.initializers.glorot_normal,\n","                          activation=tf.nn.softmax)(xa)\n","  \n","  model = keras.Model(inputs=inputs, outputs=xa_out1)\n","  return model"],"metadata":{"id":"tE4IWuS-N9cp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCkow4q5MJk_"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgGz9_6u8u-O"},"outputs":[],"source":["class SplitTransformer(keras.Model):\n","  def __init__(\n","      self,\n","      embed_dim,\n","      num_heads,\n","      # latent_dim = 512,\n","      chunk_size=chunk_size,\n","      activation=tf.nn.gelu,\n","      dropout_rate=0.25,\n","      attn_block_repeats=1,\n","      attention_range=attention_range):\n","    super(SplitTransformer, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.num_heads = num_heads\n","    self.chunk_size = chunk_size\n","    self.activation = activation\n","    self.dropout_rate = dropout_rate\n","    self.attn_block_repeats = attn_block_repeats\n","    self.attention_range = attention_range\n","\n","  def build(self, input_shape):\n","    self.chunk_starts = list(range(0, input_shape[1], self.chunk_size))\n","    self.chunk_ends = []\n","    for cs in self.chunk_starts:\n","      self.chunk_ends.append(min(cs+self.chunk_size, input_shape[1]))\n","    self.mask_starts = [max(0, cs-self.attention_range) for cs in self.chunk_starts]\n","    self.mask_ends = [min(ce+self.attention_range, input_shape[1]) for ce in self.chunk_ends]\n","    self.chunkers = [chunk_module(self.embed_dim, self.num_heads,\n","                                  self.mask_ends[i] - self.mask_starts[i],\n","                                  inChannel, self.attention_range,\n","                                  start_offset=cs - self.mask_starts[i],\n","                                  end_offset=self.mask_ends[i]-self.chunk_ends[i],\n","                                  attn_block_repeats=1, include_embedding=True) for i,cs in enumerate(self.chunk_starts)]\n","\n","    self.concat_layer = layers.Concatenate(axis=-2)\n","    self.embedding = layers.Conv1D(self.embed_dim, int(self.embed_dim//2), padding='same', activation=tf.nn.gelu)\n","    super(SplitTransformer, self).build(input_shape)\n","\n","\n","  def call(self, inputs):\n","    x = self.embedding(inputs)\n","    chunks = [self.chunkers[i](x[:, self.mask_starts[i]:self.mask_ends[i]]) for i, chunker in enumerate(self.chunkers)]\n","    y = self.concat_layer(chunks)\n","    return y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69stM-Pzhskh"},"outputs":[],"source":["class MyCustomLoss(tf.keras.losses.Loss):\n","\n","  def call(self, y_true, y_pred):\n","    y_pred = tf.convert_to_tensor(y_pred)\n","    y_true = tf.cast(y_true, y_pred.dtype)\n","    \n","    loss_obj = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n","    cat_loss = loss_obj(y_true, y_pred)\n","\n","    loss_obj = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.SUM)\n","    kl_loss = loss_obj(y_true, y_pred)\n","\n","    return cat_loss + kl_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcbAoT90Ihvc"},"outputs":[],"source":["def create_model():\n","  model =  SplitTransformer(embed_dim=128,\n","      num_heads=4,\n","      attn_block_repeats=1,\n","      chunk_size=2000,\n","      activation=\"gelu\")\n","  optimizer = tfa.optimizers.LAMB(learning_rate=learning_rate)\n","  model.compile(optimizer, loss=MyCustomLoss(), metrics=tf.keras.metrics.CategoricalAccuracy())\n","  return model\n"]},{"cell_type":"code","source":["model = create_model()\n","model.build((1, feature_size, inChannel))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0Py1VVVTfdf","executionInfo":{"status":"ok","timestamp":1673128336667,"user_tz":300,"elapsed":25007,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"}},"outputId":"8512f0ff-771b-4316-c25f-be28aec4eac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"split_transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," model (Functional)          (None, 2000, 2)           3619522   \n","                                                                 \n"," model_1 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_2 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_3 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_4 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_5 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_6 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_7 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_8 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_9 (Functional)        (None, 2000, 2)           3619522   \n","                                                                 \n"," model_10 (Functional)       (None, 2000, 2)           3619522   \n","                                                                 \n"," model_11 (Functional)       (None, 2000, 2)           3619522   \n","                                                                 \n"," model_12 (Functional)       (None, 2000, 2)           3619522   \n","                                                                 \n"," model_13 (Functional)       (None, 2000, 2)           3619522   \n","                                                                 \n"," model_14 (Functional)       (None, 220, 2)            3619522   \n","                                                                 \n"," concatenate_15 (Concatenate  multiple                 0         \n"," )                                                               \n","                                                                 \n"," conv1d_390 (Conv1D)         multiple                  24704     \n","                                                                 \n","=================================================================\n","Total params: 54,317,534\n","Trainable params: 54,286,814\n","Non-trainable params: 30,720\n","_________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61EgnuNmoFLT"},"outputs":[],"source":["METRIC = \"val_categorical_accuracy\"\n","\n","def create_callbacks(kfold=0, metric = METRIC):\n","\n","    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n","        monitor= metric,\n","        mode='auto',\n","        factor=0.5,\n","        patience=3,\n","        verbose=0\n","    )\n","\n","    earlystop = tf.keras.callbacks.EarlyStopping(\n","        monitor= metric,\n","        mode='auto',\n","        patience= 10, \n","        verbose=1,\n","        restore_best_weights=True\n","    )\n","    \n","    callbacks = [\n","                 reducelr,\n","                 earlystop\n","                 ]         \n","    \n","    return callbacks"]},{"cell_type":"markdown","metadata":{"id":"TOA_NexzN5Qq"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673128336669,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"},"user_tz":300},"id":"Ey5lpPElXlUd","outputId":"3a14015c-6b86-440b-bbc2-b754323d169e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":21}],"source":["# A TPU V3-8 has 8 computing cores, the global batch size will be 1/16 x 8 = 8/128\n","BATCH_SIZE_BASE = 4\n","# Training configuration\n","BATCH_SIZE = BATCH_SIZE_BASE * N_REPLICAS if TPU else 32\n","BATCH_SIZE"]},{"cell_type":"code","source":["N_SPLITS=3\n","NUM_EPOCHS = 1000\n","results = None\n","kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n","fold = 0\n","_x = X.to_numpy()\n","for train_index, test_index in kf.split(_x):\n","  fold += 1\n","  if fold < 3:\n","    continue\n","  accuracies = []\n","  print(f\"Training using fold {fold}\")\n","  \n","  x_train = _x[train_index]\n","  test_dataset = _x[test_index]\n","  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n","                                      random_state=fold,\n","                                      shuffle=True,)\n","  \n","  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n","  validation_steps = x_valid.shape[0]//BATCH_SIZE\n","  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n","  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n","\n","  K.clear_session()\n","  callbacks = create_callbacks()\n","  with strategy.scope():\n","    model = create_model()\n","    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS, \n","            validation_data=valid_dataset,\n","            validation_steps=validation_steps,\n","            callbacks=callbacks, verbose=1)\n","  for missing_perc in [\n","                        0.01,\n","                        0.05,\n","                        0.1,\n","                        0.2\n","                        ]:\n","    save_name = f\"[path]/YEAST/STI_wo_emb/preds_mixed_mr_{missing_perc}_fold_{fold}_.csv\"\n","    avg_accuracy = []\n","    preds = []\n","    true_labels = []\n","    \n","    to_save_array = np.zeros((test_dataset.shape[0], test_dataset.shape[1]), dtype=object)\n","    test_X_missing = np.copy(test_dataset)\n","    test_X_missing = to_categorical(test_X_missing, 3)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n","      # predict\n","    predict_onehot = model.predict(test_X_missing, verbose=1)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      predict_missing_onehot = predict_onehot[i:i+1, missing_index, :]\n","      # predict label\n","      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n","      \n","      preds.extend(predict_missing.ravel().tolist())\n","      \n","      predict_haplotypes = np.argmax(predict_onehot[i:i+1, :, :], axis=2)\n","      to_save_array[i] = np.where(predict_haplotypes==0, -1, 1)\n","      # real label\n","      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n","      # label_missing = np.argmax(label_missing_onehot, axis=2)\n","      label_missing = test_dataset[i:i + 1, missing_index]\n","      true_labels.extend(label_missing.ravel().tolist())\n","      # accuracy\n","      correct_prediction = np.equal(predict_missing, label_missing)\n","      accuracy = np.mean(correct_prediction)\n","\n","      avg_accuracy.append(accuracy)\n","\n","    df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n","    df.to_csv(save_name)\n","    print('The average imputation accuracy' \\\n","          'on test data with {} missing genotypes is {:.4f}: '\n","        .format(missing_perc, np.mean(avg_accuracy)))\n","    cnf_matrix = confusion_matrix(true_labels, preds)\n","    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n","    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n","    TP = np.diag(cnf_matrix)\n","    TN = cnf_matrix.sum() - (FP + FN + TP)\n","    FP = FP.astype(float)\n","    FN = FN.astype(float)\n","    TP = TP.astype(float)\n","    TN = TN.astype(float)\n","    # Sensitivity, hit rate, recall, or true positive rate\n","    TPR = TP/(TP+FN)\n","    # Specificity or true negative rate\n","    TNR = TN/(TN+FP)\n","    print(f\"Sensitivity: {np.mean(TPR)}\")\n","    print(f\"Specificity: {np.mean(TNR)}\")\n","    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n","    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n","    accuracies.append(np.mean(avg_accuracy))\n","      \n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxAX2BuYNiUy","executionInfo":{"status":"ok","timestamp":1673133860940,"user_tz":300,"elapsed":5524121,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"}},"outputId":"c1aa14c7-cb33-4e72-c01c-4223c7a8787c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training using fold 3\n","Epoch 1/1000\n","82/82 [==============================] - 916s 2s/step - loss: 7642.1733 - categorical_accuracy: 0.9858 - val_loss: 198707.0469 - val_categorical_accuracy: 0.9014 - lr: 0.0100\n","Epoch 2/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1772.0165 - categorical_accuracy: 0.9971 - val_loss: 20867.6035 - val_categorical_accuracy: 0.9877 - lr: 0.0100\n","Epoch 3/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1333.1654 - categorical_accuracy: 0.9978 - val_loss: 7529.7881 - val_categorical_accuracy: 0.9958 - lr: 0.0100\n","Epoch 4/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1228.2042 - categorical_accuracy: 0.9980 - val_loss: 347852.0625 - val_categorical_accuracy: 0.8808 - lr: 0.0100\n","Epoch 5/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1241.9768 - categorical_accuracy: 0.9981 - val_loss: 41221.9180 - val_categorical_accuracy: 0.9818 - lr: 0.0100\n","Epoch 6/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1259.4589 - categorical_accuracy: 0.9980 - val_loss: 60972.1953 - val_categorical_accuracy: 0.9607 - lr: 0.0100\n","Epoch 7/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1036.9878 - categorical_accuracy: 0.9983 - val_loss: 68962.2656 - val_categorical_accuracy: 0.9477 - lr: 0.0050\n","Epoch 8/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1037.1265 - categorical_accuracy: 0.9983 - val_loss: 6658.0952 - val_categorical_accuracy: 0.9959 - lr: 0.0050\n","Epoch 9/1000\n","82/82 [==============================] - 95s 1s/step - loss: 927.0172 - categorical_accuracy: 0.9984 - val_loss: 5102.9365 - val_categorical_accuracy: 0.9966 - lr: 0.0050\n","Epoch 10/1000\n","82/82 [==============================] - 90s 1s/step - loss: 917.8286 - categorical_accuracy: 0.9984 - val_loss: 13186.5078 - val_categorical_accuracy: 0.9942 - lr: 0.0050\n","Epoch 11/1000\n","82/82 [==============================] - 90s 1s/step - loss: 844.8120 - categorical_accuracy: 0.9985 - val_loss: 6059.0576 - val_categorical_accuracy: 0.9957 - lr: 0.0050\n","Epoch 12/1000\n","82/82 [==============================] - 95s 1s/step - loss: 813.1959 - categorical_accuracy: 0.9985 - val_loss: 2448.6887 - val_categorical_accuracy: 0.9977 - lr: 0.0050\n","Epoch 13/1000\n","82/82 [==============================] - 90s 1s/step - loss: 807.7044 - categorical_accuracy: 0.9985 - val_loss: 15929.7119 - val_categorical_accuracy: 0.9677 - lr: 0.0050\n","Epoch 14/1000\n","82/82 [==============================] - 90s 1s/step - loss: 782.8802 - categorical_accuracy: 0.9986 - val_loss: 4074.7188 - val_categorical_accuracy: 0.9975 - lr: 0.0050\n","Epoch 15/1000\n","82/82 [==============================] - 95s 1s/step - loss: 762.4125 - categorical_accuracy: 0.9986 - val_loss: 1412.9659 - val_categorical_accuracy: 0.9979 - lr: 0.0050\n","Epoch 16/1000\n","82/82 [==============================] - 90s 1s/step - loss: 762.8284 - categorical_accuracy: 0.9985 - val_loss: 5480.2422 - val_categorical_accuracy: 0.9926 - lr: 0.0050\n","Epoch 17/1000\n","82/82 [==============================] - 95s 1s/step - loss: 742.0523 - categorical_accuracy: 0.9986 - val_loss: 1076.6622 - val_categorical_accuracy: 0.9984 - lr: 0.0050\n","Epoch 18/1000\n","82/82 [==============================] - 90s 1s/step - loss: 740.9197 - categorical_accuracy: 0.9986 - val_loss: 23273.0254 - val_categorical_accuracy: 0.9725 - lr: 0.0050\n","Epoch 19/1000\n","82/82 [==============================] - 90s 1s/step - loss: 744.1696 - categorical_accuracy: 0.9985 - val_loss: 1331.0413 - val_categorical_accuracy: 0.9982 - lr: 0.0050\n","Epoch 20/1000\n","82/82 [==============================] - 90s 1s/step - loss: 737.4809 - categorical_accuracy: 0.9986 - val_loss: 4960.3013 - val_categorical_accuracy: 0.9972 - lr: 0.0050\n","Epoch 21/1000\n","82/82 [==============================] - 95s 1s/step - loss: 677.4587 - categorical_accuracy: 0.9986 - val_loss: 885.3333 - val_categorical_accuracy: 0.9985 - lr: 0.0025\n","Epoch 22/1000\n","82/82 [==============================] - 95s 1s/step - loss: 654.5323 - categorical_accuracy: 0.9986 - val_loss: 721.9822 - val_categorical_accuracy: 0.9986 - lr: 0.0025\n","Epoch 23/1000\n","82/82 [==============================] - 95s 1s/step - loss: 648.9980 - categorical_accuracy: 0.9986 - val_loss: 671.3236 - val_categorical_accuracy: 0.9986 - lr: 0.0025\n","Epoch 24/1000\n","82/82 [==============================] - 90s 1s/step - loss: 653.6747 - categorical_accuracy: 0.9986 - val_loss: 1664.0637 - val_categorical_accuracy: 0.9972 - lr: 0.0025\n","Epoch 25/1000\n","82/82 [==============================] - 90s 1s/step - loss: 630.8149 - categorical_accuracy: 0.9986 - val_loss: 2458.8176 - val_categorical_accuracy: 0.9975 - lr: 0.0012\n","Epoch 26/1000\n","82/82 [==============================] - 90s 1s/step - loss: 626.5673 - categorical_accuracy: 0.9987 - val_loss: 782.9809 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 27/1000\n","82/82 [==============================] - 90s 1s/step - loss: 624.5530 - categorical_accuracy: 0.9986 - val_loss: 688.0466 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 28/1000\n","82/82 [==============================] - 95s 1s/step - loss: 618.9570 - categorical_accuracy: 0.9986 - val_loss: 651.0508 - val_categorical_accuracy: 0.9987 - lr: 6.2500e-04\n","Epoch 29/1000\n","82/82 [==============================] - 90s 1s/step - loss: 611.1810 - categorical_accuracy: 0.9987 - val_loss: 646.8149 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 30/1000\n","82/82 [==============================] - 90s 1s/step - loss: 610.6984 - categorical_accuracy: 0.9987 - val_loss: 626.6443 - val_categorical_accuracy: 0.9987 - lr: 6.2500e-04\n","Epoch 31/1000\n","82/82 [==============================] - 95s 1s/step - loss: 612.3094 - categorical_accuracy: 0.9987 - val_loss: 628.4703 - val_categorical_accuracy: 0.9987 - lr: 6.2500e-04\n","Epoch 32/1000\n","82/82 [==============================] - 90s 1s/step - loss: 609.1823 - categorical_accuracy: 0.9987 - val_loss: 614.0078 - val_categorical_accuracy: 0.9987 - lr: 3.1250e-04\n","Epoch 33/1000\n","82/82 [==============================] - 95s 1s/step - loss: 607.2391 - categorical_accuracy: 0.9987 - val_loss: 616.8977 - val_categorical_accuracy: 0.9987 - lr: 3.1250e-04\n","Epoch 34/1000\n","82/82 [==============================] - 95s 1s/step - loss: 592.6006 - categorical_accuracy: 0.9987 - val_loss: 606.5182 - val_categorical_accuracy: 0.9987 - lr: 3.1250e-04\n","Epoch 35/1000\n","82/82 [==============================] - 95s 1s/step - loss: 606.3618 - categorical_accuracy: 0.9987 - val_loss: 616.4003 - val_categorical_accuracy: 0.9987 - lr: 1.5625e-04\n","Epoch 36/1000\n","82/82 [==============================] - 95s 1s/step - loss: 603.6653 - categorical_accuracy: 0.9987 - val_loss: 595.5140 - val_categorical_accuracy: 0.9987 - lr: 1.5625e-04\n","Epoch 37/1000\n","82/82 [==============================] - 93s 1s/step - loss: 595.1185 - categorical_accuracy: 0.9987 - val_loss: 629.5022 - val_categorical_accuracy: 0.9987 - lr: 1.5625e-04\n","Epoch 38/1000\n","82/82 [==============================] - 90s 1s/step - loss: 598.3264 - categorical_accuracy: 0.9987 - val_loss: 603.3073 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 39/1000\n","82/82 [==============================] - 90s 1s/step - loss: 601.5391 - categorical_accuracy: 0.9987 - val_loss: 611.0707 - val_categorical_accuracy: 0.9986 - lr: 7.8125e-05\n","Epoch 40/1000\n","82/82 [==============================] - 90s 1s/step - loss: 597.7988 - categorical_accuracy: 0.9987 - val_loss: 599.3854 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 41/1000\n","82/82 [==============================] - 90s 1s/step - loss: 597.3265 - categorical_accuracy: 0.9987 - val_loss: 641.0252 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 42/1000\n","82/82 [==============================] - 90s 1s/step - loss: 599.6705 - categorical_accuracy: 0.9987 - val_loss: 601.7985 - val_categorical_accuracy: 0.9986 - lr: 3.9062e-05\n","Epoch 43/1000\n","82/82 [==============================] - 90s 1s/step - loss: 594.2829 - categorical_accuracy: 0.9987 - val_loss: 615.8299 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 44/1000\n","82/82 [==============================] - 90s 1s/step - loss: 597.7357 - categorical_accuracy: 0.9987 - val_loss: 612.2618 - val_categorical_accuracy: 0.9987 - lr: 1.9531e-05\n","Epoch 45/1000\n","82/82 [==============================] - 90s 1s/step - loss: 596.4150 - categorical_accuracy: 0.9987 - val_loss: 640.2084 - val_categorical_accuracy: 0.9986 - lr: 1.9531e-05\n","Epoch 46/1000\n","82/82 [==============================] - ETA: 0s - loss: 593.1794 - categorical_accuracy: 0.9987Restoring model weights from the end of the best epoch: 36.\n","82/82 [==============================] - 112s 1s/step - loss: 593.1794 - categorical_accuracy: 0.9987 - val_loss: 626.5733 - val_categorical_accuracy: 0.9987 - lr: 1.9531e-05\n","Epoch 46: early stopping\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 12527.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 164s 3s/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 1935.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.01 missing genotypes is 0.9980: \n","Sensitivity: 0.9980315045726909\n","Specificity: 0.9980315045726909\n","F1-score macro: 0.9980293702189913\n","F1-score micro: 0.9980294062040983\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 6942.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 1506.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.05 missing genotypes is 0.9980: \n","Sensitivity: 0.998044901033188\n","Specificity: 0.998044901033188\n","F1-score macro: 0.9980433767399325\n","F1-score micro: 0.9980433979091147\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 4707.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:01<00:00, 1159.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.1 missing genotypes is 0.9980: \n","Sensitivity: 0.9980238234527967\n","Specificity: 0.9980238234527967\n","F1-score macro: 0.9980225507490368\n","F1-score micro: 0.9980225675328066\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 2882.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:01<00:00, 866.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.2 missing genotypes is 0.9979: \n","Sensitivity: 0.9979505738250651\n","Specificity: 0.9979505738250651\n","F1-score macro: 0.9979496456103716\n","F1-score micro: 0.9979496612157286\n"]}]},{"cell_type":"code","source":["N_SPLITS=3\n","NUM_EPOCHS = 1000\n","results = None\n","kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n","fold = 0\n","_x = X.to_numpy()\n","for train_index, test_index in kf.split(_x):\n","  fold += 1\n","  if fold < 2:\n","    continue\n","  accuracies = []\n","  print(f\"Training using fold {fold}\")\n","  \n","  x_train = _x[train_index]\n","  test_dataset = _x[test_index]\n","  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n","                                      random_state=fold,\n","                                      shuffle=True,)\n","  \n","  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n","  validation_steps = x_valid.shape[0]//BATCH_SIZE\n","  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n","  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n","\n","  K.clear_session()\n","  callbacks = create_callbacks()\n","  with strategy.scope():\n","    model = create_model()\n","    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS, \n","            validation_data=valid_dataset,\n","            validation_steps=validation_steps,\n","            callbacks=callbacks, verbose=1)\n","  for missing_perc in [\n","                        0.01,\n","                        0.05,\n","                        0.1,\n","                        0.2\n","                        ]:\n","    save_name = f\"[path]/YEAST/STI_wo_emb/preds_mixed_mr_{missing_perc}_fold_{fold}_.csv\"\n","    avg_accuracy = []\n","    preds = []\n","    true_labels = []\n","    \n","    to_save_array = np.zeros((test_dataset.shape[0], test_dataset.shape[1]), dtype=object)\n","    test_X_missing = np.copy(test_dataset)\n","    test_X_missing = to_categorical(test_X_missing, 3)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n","      # predict\n","    predict_onehot = model.predict(test_X_missing, verbose=1)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      predict_missing_onehot = predict_onehot[i:i+1, missing_index, :]\n","      # predict label\n","      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n","      \n","      preds.extend(predict_missing.ravel().tolist())\n","      \n","      predict_haplotypes = np.argmax(predict_onehot[i:i+1, :, :], axis=2)\n","      to_save_array[i] = np.where(predict_haplotypes==0, -1, 1)\n","      # real label\n","      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n","      # label_missing = np.argmax(label_missing_onehot, axis=2)\n","      label_missing = test_dataset[i:i + 1, missing_index]\n","      true_labels.extend(label_missing.ravel().tolist())\n","      # accuracy\n","      correct_prediction = np.equal(predict_missing, label_missing)\n","      accuracy = np.mean(correct_prediction)\n","\n","      avg_accuracy.append(accuracy)\n","\n","    df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n","    df.to_csv(save_name)\n","    print('The average imputation accuracy' \\\n","          'on test data with {} missing genotypes is {:.4f}: '\n","        .format(missing_perc, np.mean(avg_accuracy)))\n","    cnf_matrix = confusion_matrix(true_labels, preds)\n","    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n","    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n","    TP = np.diag(cnf_matrix)\n","    TN = cnf_matrix.sum() - (FP + FN + TP)\n","    FP = FP.astype(float)\n","    FN = FN.astype(float)\n","    TP = TP.astype(float)\n","    TN = TN.astype(float)\n","    # Sensitivity, hit rate, recall, or true positive rate\n","    TPR = TP/(TP+FN)\n","    # Specificity or true negative rate\n","    TNR = TN/(TN+FP)\n","    print(f\"Sensitivity: {np.mean(TPR)}\")\n","    print(f\"Specificity: {np.mean(TNR)}\")\n","    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n","    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n","    accuracies.append(np.mean(avg_accuracy))\n","      \n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Uos12sSsx0xQ","executionInfo":{"status":"error","timestamp":1673126439471,"user_tz":300,"elapsed":5372191,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"}},"outputId":"2b606344-eb6a-478f-a0e2-eb2997b59dac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training using fold 2\n","Epoch 1/1000\n","82/82 [==============================] - 1000s 2s/step - loss: 7413.2710 - categorical_accuracy: 0.9861 - val_loss: 140448.2344 - val_categorical_accuracy: 0.9067 - lr: 0.0100\n","Epoch 2/1000\n","82/82 [==============================] - 96s 1s/step - loss: 1540.6588 - categorical_accuracy: 0.9974 - val_loss: 153390.0469 - val_categorical_accuracy: 0.9433 - lr: 0.0100\n","Epoch 3/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1391.8503 - categorical_accuracy: 0.9978 - val_loss: 117915.1641 - val_categorical_accuracy: 0.9251 - lr: 0.0100\n","Epoch 4/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1237.3580 - categorical_accuracy: 0.9980 - val_loss: 112000.7109 - val_categorical_accuracy: 0.9409 - lr: 0.0100\n","Epoch 5/1000\n","82/82 [==============================] - 96s 1s/step - loss: 1223.0530 - categorical_accuracy: 0.9980 - val_loss: 32449.4141 - val_categorical_accuracy: 0.9795 - lr: 0.0100\n","Epoch 6/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1263.5463 - categorical_accuracy: 0.9981 - val_loss: 178674.7344 - val_categorical_accuracy: 0.9402 - lr: 0.0100\n","Epoch 7/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1120.5725 - categorical_accuracy: 0.9981 - val_loss: 204424.7188 - val_categorical_accuracy: 0.9062 - lr: 0.0100\n","Epoch 8/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1210.1102 - categorical_accuracy: 0.9981 - val_loss: 130127.9609 - val_categorical_accuracy: 0.9571 - lr: 0.0100\n","Epoch 9/1000\n","82/82 [==============================] - 96s 1s/step - loss: 1007.6711 - categorical_accuracy: 0.9983 - val_loss: 1934.9645 - val_categorical_accuracy: 0.9978 - lr: 0.0050\n","Epoch 10/1000\n","82/82 [==============================] - 90s 1s/step - loss: 966.6779 - categorical_accuracy: 0.9984 - val_loss: 3500.8904 - val_categorical_accuracy: 0.9953 - lr: 0.0050\n","Epoch 11/1000\n","82/82 [==============================] - 90s 1s/step - loss: 833.7419 - categorical_accuracy: 0.9985 - val_loss: 27502.8691 - val_categorical_accuracy: 0.9486 - lr: 0.0050\n","Epoch 12/1000\n","82/82 [==============================] - 90s 1s/step - loss: 783.7569 - categorical_accuracy: 0.9985 - val_loss: 5713.3979 - val_categorical_accuracy: 0.9926 - lr: 0.0050\n","Epoch 13/1000\n","82/82 [==============================] - 90s 1s/step - loss: 820.1743 - categorical_accuracy: 0.9985 - val_loss: 8238.3574 - val_categorical_accuracy: 0.9724 - lr: 0.0025\n","Epoch 14/1000\n","82/82 [==============================] - 90s 1s/step - loss: 695.0266 - categorical_accuracy: 0.9986 - val_loss: 6602.9365 - val_categorical_accuracy: 0.9774 - lr: 0.0025\n","Epoch 15/1000\n","82/82 [==============================] - 96s 1s/step - loss: 687.8307 - categorical_accuracy: 0.9986 - val_loss: 743.6276 - val_categorical_accuracy: 0.9985 - lr: 0.0025\n","Epoch 16/1000\n","82/82 [==============================] - 90s 1s/step - loss: 679.4005 - categorical_accuracy: 0.9986 - val_loss: 781.8442 - val_categorical_accuracy: 0.9985 - lr: 0.0025\n","Epoch 17/1000\n","82/82 [==============================] - 90s 1s/step - loss: 676.1356 - categorical_accuracy: 0.9986 - val_loss: 1870.4857 - val_categorical_accuracy: 0.9982 - lr: 0.0025\n","Epoch 18/1000\n","82/82 [==============================] - 96s 1s/step - loss: 659.1686 - categorical_accuracy: 0.9986 - val_loss: 742.1188 - val_categorical_accuracy: 0.9986 - lr: 0.0025\n","Epoch 19/1000\n","82/82 [==============================] - 90s 1s/step - loss: 636.8401 - categorical_accuracy: 0.9986 - val_loss: 670.5272 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 20/1000\n","82/82 [==============================] - 96s 1s/step - loss: 640.1407 - categorical_accuracy: 0.9986 - val_loss: 640.3975 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 21/1000\n","82/82 [==============================] - 90s 1s/step - loss: 628.9915 - categorical_accuracy: 0.9986 - val_loss: 746.1235 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 22/1000\n","82/82 [==============================] - 96s 1s/step - loss: 623.9727 - categorical_accuracy: 0.9986 - val_loss: 615.3947 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 23/1000\n","82/82 [==============================] - 90s 1s/step - loss: 623.5154 - categorical_accuracy: 0.9986 - val_loss: 611.4356 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 24/1000\n","82/82 [==============================] - 90s 1s/step - loss: 619.7416 - categorical_accuracy: 0.9986 - val_loss: 633.2603 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 25/1000\n","82/82 [==============================] - 90s 1s/step - loss: 619.8969 - categorical_accuracy: 0.9986 - val_loss: 614.8245 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 26/1000\n","82/82 [==============================] - 96s 1s/step - loss: 611.3138 - categorical_accuracy: 0.9986 - val_loss: 608.7012 - val_categorical_accuracy: 0.9986 - lr: 3.1250e-04\n","Epoch 27/1000\n","82/82 [==============================] - 90s 1s/step - loss: 614.0194 - categorical_accuracy: 0.9986 - val_loss: 604.0320 - val_categorical_accuracy: 0.9986 - lr: 3.1250e-04\n","Epoch 28/1000\n","82/82 [==============================] - 96s 1s/step - loss: 642.2203 - categorical_accuracy: 0.9986 - val_loss: 602.0836 - val_categorical_accuracy: 0.9987 - lr: 3.1250e-04\n","Epoch 29/1000\n","82/82 [==============================] - 90s 1s/step - loss: 611.3120 - categorical_accuracy: 0.9986 - val_loss: 602.6002 - val_categorical_accuracy: 0.9986 - lr: 1.5625e-04\n","Epoch 30/1000\n","82/82 [==============================] - 90s 1s/step - loss: 605.2466 - categorical_accuracy: 0.9986 - val_loss: 597.7484 - val_categorical_accuracy: 0.9986 - lr: 1.5625e-04\n","Epoch 31/1000\n","82/82 [==============================] - 90s 1s/step - loss: 609.8857 - categorical_accuracy: 0.9986 - val_loss: 602.9626 - val_categorical_accuracy: 0.9986 - lr: 1.5625e-04\n","Epoch 32/1000\n","82/82 [==============================] - 90s 1s/step - loss: 607.1196 - categorical_accuracy: 0.9986 - val_loss: 589.7711 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 33/1000\n","82/82 [==============================] - 90s 1s/step - loss: 622.3866 - categorical_accuracy: 0.9986 - val_loss: 659.5560 - val_categorical_accuracy: 0.9986 - lr: 7.8125e-05\n","Epoch 34/1000\n","82/82 [==============================] - 90s 1s/step - loss: 606.8784 - categorical_accuracy: 0.9986 - val_loss: 584.7934 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 35/1000\n","82/82 [==============================] - 90s 1s/step - loss: 597.9153 - categorical_accuracy: 0.9987 - val_loss: 584.1268 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 36/1000\n","82/82 [==============================] - 90s 1s/step - loss: 609.8116 - categorical_accuracy: 0.9986 - val_loss: 599.0131 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 37/1000\n","82/82 [==============================] - 90s 1s/step - loss: 605.1596 - categorical_accuracy: 0.9986 - val_loss: 594.9241 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 38/1000\n","82/82 [==============================] - ETA: 0s - loss: 600.1385 - categorical_accuracy: 0.9987Restoring model weights from the end of the best epoch: 28.\n","82/82 [==============================] - 113s 1s/step - loss: 600.1385 - categorical_accuracy: 0.9987 - val_loss: 596.5560 - val_categorical_accuracy: 0.9986 - lr: 1.9531e-05\n","Epoch 38: early stopping\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 7797.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 169s 3s/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 1760.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.01 missing genotypes is 0.9980: \n","Sensitivity: 0.9980462785414617\n","Specificity: 0.9980462785414617\n","F1-score macro: 0.9980463721533575\n","F1-score micro: 0.9980463731863508\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 3836.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:01<00:00, 1326.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.05 missing genotypes is 0.9980: \n","Sensitivity: 0.9980404802832198\n","Specificity: 0.9980404802832198\n","F1-score macro: 0.9980409714760904\n","F1-score micro: 0.9980409757723346\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 2607.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 312ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:01<00:00, 1047.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.1 missing genotypes is 0.9980: \n","Sensitivity: 0.9979608169101248\n","Specificity: 0.9979608169101248\n","F1-score macro: 0.9979612828968237\n","F1-score micro: 0.9979612874722726\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:00<00:00, 1686.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1463/1463 [00:01<00:00, 790.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.2 missing genotypes is 0.9979: \n","Sensitivity: 0.9979256534433375\n","Specificity: 0.9979256534433375\n","F1-score macro: 0.9979260400377455\n","F1-score micro: 0.9979260453821236\n","Training using fold 3\n","Epoch 1/1000\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-66abb534241e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS, \n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: 4 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1309097}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_train_function/_execute_7_0/_79]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[TPUReplicate/_compile/_9230941669075983740/_2/_44]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1309097}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_train_function/_execute_7_0/_79]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1309097}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) CANCELLED: {{function_node __inference_train_function_1309097}} Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","source":["N_SPLITS=3\n","NUM_EPOCHS = 1000\n","results = None\n","kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n","fold = 0\n","_x = X.to_numpy()\n","for train_index, test_index in kf.split(_x):\n","  fold += 1\n","  accuracies = []\n","  print(f\"Training using fold {fold}\")\n","  \n","  x_train = _x[train_index]\n","  test_dataset = _x[test_index]\n","  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n","                                      random_state=fold,\n","                                      shuffle=True,)\n","  \n","  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n","  validation_steps = x_valid.shape[0]//BATCH_SIZE\n","  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n","  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n","\n","  K.clear_session()\n","  callbacks = create_callbacks()\n","  with strategy.scope():\n","    model = create_model()\n","    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS, \n","            validation_data=valid_dataset,\n","            validation_steps=validation_steps,\n","            callbacks=callbacks, verbose=1)\n","  for missing_perc in [\n","                        0.01,\n","                        0.05,\n","                        0.1,\n","                        0.2\n","                        ]:\n","    save_name = f\"[path]/YEAST/STI_wo_emb/preds_mixed_mr_{missing_perc}_fold_{fold}_.csv\"\n","    avg_accuracy = []\n","    preds = []\n","    true_labels = []\n","    \n","    to_save_array = np.zeros((test_dataset.shape[0], test_dataset.shape[1]), dtype=object)\n","    test_X_missing = np.copy(test_dataset)\n","    test_X_missing = to_categorical(test_X_missing, 3)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n","      # predict\n","    predict_onehot = model.predict(test_X_missing, verbose=1)\n","    for i in tqdm(list(range(test_dataset.shape[0]))):\n","      rng = np.random.default_rng(i + fold)\n","      # Generates missing genotypes\n","      missing_size = int(missing_perc * test_X_missing.shape[1])\n","      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n","                                        size=missing_size)\n","      predict_missing_onehot = predict_onehot[i:i+1, missing_index, :]\n","      # predict label\n","      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n","      \n","      preds.extend(predict_missing.ravel().tolist())\n","      \n","      predict_haplotypes = np.argmax(predict_onehot[i:i+1, :, :], axis=2)\n","      to_save_array[i] = np.where(predict_haplotypes==0, -1, 1)\n","      # real label\n","      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n","      # label_missing = np.argmax(label_missing_onehot, axis=2)\n","      label_missing = test_dataset[i:i + 1, missing_index]\n","      true_labels.extend(label_missing.ravel().tolist())\n","      # accuracy\n","      correct_prediction = np.equal(predict_missing, label_missing)\n","      accuracy = np.mean(correct_prediction)\n","\n","      avg_accuracy.append(accuracy)\n","\n","    df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n","    df.to_csv(save_name)\n","    print('The average imputation accuracy' \\\n","          'on test data with {} missing genotypes is {:.4f}: '\n","        .format(missing_perc, np.mean(avg_accuracy)))\n","    cnf_matrix = confusion_matrix(true_labels, preds)\n","    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n","    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n","    TP = np.diag(cnf_matrix)\n","    TN = cnf_matrix.sum() - (FP + FN + TP)\n","    FP = FP.astype(float)\n","    FN = FN.astype(float)\n","    TP = TP.astype(float)\n","    TN = TN.astype(float)\n","    # Sensitivity, hit rate, recall, or true positive rate\n","    TPR = TP/(TP+FN)\n","    # Specificity or true negative rate\n","    TNR = TN/(TN+FP)\n","    print(f\"Sensitivity: {np.mean(TPR)}\")\n","    print(f\"Specificity: {np.mean(TNR)}\")\n","    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n","    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n","    accuracies.append(np.mean(avg_accuracy))\n","      \n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YY5dshO_hNrs","executionInfo":{"status":"error","timestamp":1673114308441,"user_tz":300,"elapsed":4988463,"user":{"displayName":"net crowmaster","userId":"14126946344391667924"}},"outputId":"c8c714de-2020-4d90-e91c-56d696a7e403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training using fold 1\n","Epoch 1/1000\n","82/82 [==============================] - 913s 2s/step - loss: 7620.6919 - categorical_accuracy: 0.9858 - val_loss: 365576.7188 - val_categorical_accuracy: 0.8583 - lr: 0.0100\n","Epoch 2/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1900.2145 - categorical_accuracy: 0.9970 - val_loss: 83305.0156 - val_categorical_accuracy: 0.9620 - lr: 0.0100\n","Epoch 3/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1484.6418 - categorical_accuracy: 0.9977 - val_loss: 183074.3594 - val_categorical_accuracy: 0.9066 - lr: 0.0100\n","Epoch 4/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1693.3523 - categorical_accuracy: 0.9975 - val_loss: 43284.5391 - val_categorical_accuracy: 0.9636 - lr: 0.0100\n","Epoch 5/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1222.2999 - categorical_accuracy: 0.9980 - val_loss: 119676.8047 - val_categorical_accuracy: 0.9616 - lr: 0.0100\n","Epoch 6/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1236.6202 - categorical_accuracy: 0.9981 - val_loss: 144629.0312 - val_categorical_accuracy: 0.9532 - lr: 0.0100\n","Epoch 7/1000\n","82/82 [==============================] - 90s 1s/step - loss: 1433.4860 - categorical_accuracy: 0.9979 - val_loss: 205918.2188 - val_categorical_accuracy: 0.9248 - lr: 0.0100\n","Epoch 8/1000\n","82/82 [==============================] - 95s 1s/step - loss: 1105.6971 - categorical_accuracy: 0.9982 - val_loss: 3275.7227 - val_categorical_accuracy: 0.9974 - lr: 0.0050\n","Epoch 9/1000\n","82/82 [==============================] - 90s 1s/step - loss: 954.7891 - categorical_accuracy: 0.9984 - val_loss: 3491.5659 - val_categorical_accuracy: 0.9962 - lr: 0.0050\n","Epoch 10/1000\n","82/82 [==============================] - 95s 1s/step - loss: 869.7850 - categorical_accuracy: 0.9985 - val_loss: 1641.6884 - val_categorical_accuracy: 0.9974 - lr: 0.0050\n","Epoch 11/1000\n","82/82 [==============================] - 90s 1s/step - loss: 846.2794 - categorical_accuracy: 0.9985 - val_loss: 8753.8252 - val_categorical_accuracy: 0.9958 - lr: 0.0050\n","Epoch 12/1000\n","82/82 [==============================] - 95s 1s/step - loss: 796.1772 - categorical_accuracy: 0.9985 - val_loss: 2411.7246 - val_categorical_accuracy: 0.9985 - lr: 0.0025\n","Epoch 13/1000\n","82/82 [==============================] - 90s 1s/step - loss: 779.7425 - categorical_accuracy: 0.9986 - val_loss: 3134.1082 - val_categorical_accuracy: 0.9984 - lr: 0.0025\n","Epoch 14/1000\n","82/82 [==============================] - 90s 1s/step - loss: 736.1343 - categorical_accuracy: 0.9986 - val_loss: 1307.4800 - val_categorical_accuracy: 0.9983 - lr: 0.0025\n","Epoch 15/1000\n","82/82 [==============================] - 95s 1s/step - loss: 712.7239 - categorical_accuracy: 0.9986 - val_loss: 757.0439 - val_categorical_accuracy: 0.9986 - lr: 0.0025\n","Epoch 16/1000\n","82/82 [==============================] - 95s 1s/step - loss: 678.3475 - categorical_accuracy: 0.9986 - val_loss: 717.4355 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 17/1000\n","82/82 [==============================] - 90s 1s/step - loss: 672.6263 - categorical_accuracy: 0.9986 - val_loss: 4143.3125 - val_categorical_accuracy: 0.9976 - lr: 0.0012\n","Epoch 18/1000\n","82/82 [==============================] - 95s 1s/step - loss: 662.4040 - categorical_accuracy: 0.9986 - val_loss: 681.9968 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 19/1000\n","82/82 [==============================] - 90s 1s/step - loss: 768.4645 - categorical_accuracy: 0.9986 - val_loss: 677.3499 - val_categorical_accuracy: 0.9986 - lr: 0.0012\n","Epoch 20/1000\n","82/82 [==============================] - 90s 1s/step - loss: 663.2413 - categorical_accuracy: 0.9986 - val_loss: 672.8322 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 21/1000\n","82/82 [==============================] - 95s 1s/step - loss: 649.6174 - categorical_accuracy: 0.9986 - val_loss: 680.5807 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 22/1000\n","82/82 [==============================] - 95s 1s/step - loss: 647.9272 - categorical_accuracy: 0.9986 - val_loss: 646.8748 - val_categorical_accuracy: 0.9986 - lr: 6.2500e-04\n","Epoch 23/1000\n","82/82 [==============================] - 95s 1s/step - loss: 637.5913 - categorical_accuracy: 0.9986 - val_loss: 644.1636 - val_categorical_accuracy: 0.9987 - lr: 3.1250e-04\n","Epoch 24/1000\n","82/82 [==============================] - 90s 1s/step - loss: 644.0942 - categorical_accuracy: 0.9986 - val_loss: 691.7892 - val_categorical_accuracy: 0.9986 - lr: 3.1250e-04\n","Epoch 25/1000\n","82/82 [==============================] - 90s 1s/step - loss: 649.3917 - categorical_accuracy: 0.9986 - val_loss: 638.4570 - val_categorical_accuracy: 0.9986 - lr: 3.1250e-04\n","Epoch 26/1000\n","82/82 [==============================] - 95s 1s/step - loss: 636.2010 - categorical_accuracy: 0.9986 - val_loss: 625.3607 - val_categorical_accuracy: 0.9987 - lr: 1.5625e-04\n","Epoch 27/1000\n","82/82 [==============================] - 90s 1s/step - loss: 629.9431 - categorical_accuracy: 0.9986 - val_loss: 649.2806 - val_categorical_accuracy: 0.9986 - lr: 1.5625e-04\n","Epoch 28/1000\n","82/82 [==============================] - 90s 1s/step - loss: 625.7646 - categorical_accuracy: 0.9987 - val_loss: 625.6990 - val_categorical_accuracy: 0.9987 - lr: 1.5625e-04\n","Epoch 29/1000\n","82/82 [==============================] - 90s 1s/step - loss: 635.0193 - categorical_accuracy: 0.9986 - val_loss: 631.5615 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 30/1000\n","82/82 [==============================] - 90s 1s/step - loss: 628.3007 - categorical_accuracy: 0.9987 - val_loss: 614.6006 - val_categorical_accuracy: 0.9987 - lr: 7.8125e-05\n","Epoch 31/1000\n","82/82 [==============================] - 90s 1s/step - loss: 634.7073 - categorical_accuracy: 0.9986 - val_loss: 636.6057 - val_categorical_accuracy: 0.9986 - lr: 7.8125e-05\n","Epoch 32/1000\n","82/82 [==============================] - 90s 1s/step - loss: 628.9866 - categorical_accuracy: 0.9986 - val_loss: 623.5458 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 33/1000\n","82/82 [==============================] - 90s 1s/step - loss: 627.0456 - categorical_accuracy: 0.9987 - val_loss: 624.2963 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 34/1000\n","82/82 [==============================] - 90s 1s/step - loss: 635.0709 - categorical_accuracy: 0.9986 - val_loss: 623.4268 - val_categorical_accuracy: 0.9987 - lr: 3.9062e-05\n","Epoch 35/1000\n","82/82 [==============================] - 93s 1s/step - loss: 631.9870 - categorical_accuracy: 0.9986 - val_loss: 641.5443 - val_categorical_accuracy: 0.9987 - lr: 1.9531e-05\n","Epoch 36/1000\n","82/82 [==============================] - ETA: 0s - loss: 627.4425 - categorical_accuracy: 0.9987Restoring model weights from the end of the best epoch: 26.\n","82/82 [==============================] - 112s 1s/step - loss: 627.4425 - categorical_accuracy: 0.9987 - val_loss: 636.1414 - val_categorical_accuracy: 0.9987 - lr: 1.9531e-05\n","Epoch 36: early stopping\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 12415.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 165s 3s/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 2138.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.01 missing genotypes is 0.9981: \n","Sensitivity: 0.9980645723261212\n","Specificity: 0.9980645723261212\n","F1-score macro: 0.9980646572512772\n","F1-score micro: 0.9980646630236795\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 7421.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 1559.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.05 missing genotypes is 0.9980: \n","Sensitivity: 0.9980384201971909\n","Specificity: 0.9980384201971909\n","F1-score macro: 0.998038440729201\n","F1-score micro: 0.9980384411319337\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 4750.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 15s 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:01<00:00, 1232.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.1 missing genotypes is 0.9980: \n","Sensitivity: 0.9980107847319619\n","Specificity: 0.9980107847319619\n","F1-score macro: 0.9980108428779711\n","F1-score micro: 0.9980108476335429\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:00<00:00, 2997.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 14s 313ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1464/1464 [00:01<00:00, 897.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The average imputation accuracyon test data with 0.2 missing genotypes is 0.9979: \n","Sensitivity: 0.9979473745339895\n","Specificity: 0.9979473745339895\n","F1-score macro: 0.9979474284412247\n","F1-score micro: 0.9979474309968902\n","Training using fold 2\n","Epoch 1/1000\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d7100cb2c77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS, \n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: 4 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1329983}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_train_function/_execute_0_0/_51]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[TPUReplicate/_compile/_11984434425481919367/_2/_20]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1329983}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_train_function/_execute_0_0/_51]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED: {{function_node __inference_train_function_1329983}} Attempting to reserve 5.80G at the bottom of memory. That was not possible. There are 6.17G free, 0B reserved, and 5.28G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) CANCELLED: {{function_node __inference_train_function_1329983}} Function was cancelled before it was started\n0 successful operations.\n1 derived errors ignored."]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQ7TbkVjCnw8"},"outputs":[],"source":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      "]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1lo9cmptjRRESsVlVECvlJFHbLeaygq2s","timestamp":1640128751823},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/perceiver_image_classification.ipynb","timestamp":1621552889682}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}