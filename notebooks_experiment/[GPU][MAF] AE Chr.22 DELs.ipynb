{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165232,
     "status": "ok",
     "timestamp": 1690833097213,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "doSuiA3dyTyg",
    "outputId": "3d83d560-310e-4827-9184-84a1f63e15cf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11491,
     "status": "ok",
     "timestamp": 1690833108697,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "liJJGzQp4qzO",
    "outputId": "958f98dd-f6b3-419a-968e-e15bc9321e29"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m612.1/612.1 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Collecting scikit-allel\n",
      "  Downloading scikit_allel-1.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.4/7.4 MB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-allel) (1.22.4)\n",
      "Requirement already satisfied: dask[array] in /usr/local/lib/python3.10/dist-packages (from scikit-allel) (2022.12.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (8.1.6)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (23.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array]->scikit-allel) (6.0.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask[array]->scikit-allel) (1.0.0)\n",
      "Installing collected packages: scikit-allel\n",
      "Successfully installed scikit-allel-1.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "!pip install toolz scikit-allel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4651,
     "status": "ok",
     "timestamp": 1690833113344,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "ZWzi3Z3L5RO2",
    "outputId": "8ab68f48-364a-4480-d808-62caf906eb11"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjGOO5PdFPf7"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4021,
     "status": "ok",
     "timestamp": 1690833117363,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "odmhCqSVFPf8",
    "outputId": "60745087-4121-4d8e-a4c9-8289d536feb7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"MODIN_CPUS\"] = \"8\"\n",
    "# from distributed import Client\n",
    "# client = Client()\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "# import allel\n",
    "from scipy.spatial.distance import squareform\n",
    "%matplotlib inline\n",
    "from toolz import interleave\n",
    "from tqdm import tqdm\n",
    "import allel\n",
    "from scipy.spatial.distance import squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLd26RspFhaS"
   },
   "source": [
    "## Hardware Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1690833117365,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "SLd7mAFgFUnR",
    "outputId": "9d7629f9-8aca-4d65-e6e6-f1adf1c5ee0a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on GPU\n",
      "N_REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on GPU')\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "# Number of computing cores, is 8 for a TPU V3-8\n",
    "print(f'N_REPLICAS: {N_REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A77GFE3xFPf8"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j3zy8i_8FPf_",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833121630,
     "user_tz": 240,
     "elapsed": 4276,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "ba170f7d-e563-4bc3-c0aa-6eaec2917cec"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9    ...  562  563  564  \\\n",
       "HG00096  0|0  0|0  0|0  0|0  0|0  0|0  1|1  0|0  0|0  0|0  ...  0|0  0|0  0|1   \n",
       "HG00097  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  0|1   \n",
       "HG00099  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  0|0   \n",
       "HG00100  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  0|0   \n",
       "HG00101  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  0|0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "NA21137  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  ...  0|0  0|0  0|0   \n",
       "NA21141  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  1|0   \n",
       "NA21142  0|0  0|0  0|0  0|0  0|0  0|0  0|1  0|0  0|0  0|0  ...  0|0  0|0  1|0   \n",
       "NA21143  0|0  0|0  0|0  0|0  0|0  0|0  1|0  0|0  0|0  0|0  ...  0|0  0|0  0|1   \n",
       "NA21144  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  0|0  ...  0|0  0|0  0|0   \n",
       "\n",
       "         565  566  567  568  569  570  571  \n",
       "HG00096  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "HG00097  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "HG00099  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "HG00100  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "HG00101  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "...      ...  ...  ...  ...  ...  ...  ...  \n",
       "NA21137  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "NA21141  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "NA21142  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "NA21143  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "NA21144  0|0  0|0  0|0  0|0  0|0  0|0  0|0  \n",
       "\n",
       "[2504 rows x 572 columns]"
      ],
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-b51465f0-c723-475b-9343-d2982d91cf4b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>562</th>\n",
       "      <th>563</th>\n",
       "      <th>564</th>\n",
       "      <th>565</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|1</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|1</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|1</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21137</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21141</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21142</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|1</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21143</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>1|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|1</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21144</th>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>...</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "      <td>0|0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 572 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b51465f0-c723-475b-9343-d2982d91cf4b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-4769438f-0a2f-4873-9160-21071e83a334\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4769438f-0a2f-4873-9160-21071e83a334')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-4769438f-0a2f-4873-9160-21071e83a334 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b51465f0-c723-475b-9343-d2982d91cf4b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b51465f0-c723-475b-9343-d2982d91cf4b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "root_dir = '[data_path]'\n",
    "new_data_header = \"\"\n",
    "# get header\n",
    "with open(root_dir + \"DELL.chr22.genotypes.full.vcf\", 'r') as f_in:\n",
    "    # skip info\n",
    "    for line_num in range(70):\n",
    "        f_in.readline()\n",
    "\n",
    "    new_data_header = f_in.readline()\n",
    "# load data\n",
    "\n",
    "# load genotype\n",
    "genotypes = pd.read_csv(root_dir + \"DELL.chr22.genotypes.full.vcf\", comment='#', sep='\\t', names=new_data_header.strip().split('\\t'), header=None)\n",
    "info = genotypes.iloc[:-1, :9]\n",
    "genotypes = genotypes.iloc[:-1, 9:].T\n",
    "headers = genotypes.columns[:]\n",
    "genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-gFMrUnhV80n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833122449,
     "user_tz": 240,
     "elapsed": 823,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "outputs": [],
   "source": [
    "ped_file = root_dir+'integrated_call_samples.20130502.ALL.ped'\n",
    "pedigree = pd.read_csv(ped_file, sep='\\t', index_col='Individual ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1690833122450,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "Zgb8Fn-EV_PU",
    "outputId": "89431a86-912e-4170-afdf-279eca021bdc"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Family ID Paternal ID Maternal ID  Gender  Phenotype Population  \\\n",
       "Individual ID                                                                   \n",
       "HG00096         HG00096           0           0       1          0        GBR   \n",
       "HG00097         HG00097           0           0       2          0        GBR   \n",
       "HG00098         HG00098           0           0       1          0        GBR   \n",
       "HG00099         HG00099           0           0       2          0        GBR   \n",
       "HG00100         HG00100           0           0       2          0        GBR   \n",
       "\n",
       "              Relationship Siblings Second Order Third Order Children  \\\n",
       "Individual ID                                                           \n",
       "HG00096              unrel        0            0           0        0   \n",
       "HG00097              unrel        0            0           0        0   \n",
       "HG00098              unrel        0            0           0        0   \n",
       "HG00099              unrel        0            0           0        0   \n",
       "HG00100              unrel        0            0           0        0   \n",
       "\n",
       "              Other Comments  \n",
       "Individual ID                 \n",
       "HG00096                    0  \n",
       "HG00097                    0  \n",
       "HG00098                    0  \n",
       "HG00099                    0  \n",
       "HG00100                    0  "
      ],
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-0313e02b-bf00-4219-9609-b80574acc9b7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family ID</th>\n",
       "      <th>Paternal ID</th>\n",
       "      <th>Maternal ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Phenotype</th>\n",
       "      <th>Population</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Siblings</th>\n",
       "      <th>Second Order</th>\n",
       "      <th>Third Order</th>\n",
       "      <th>Children</th>\n",
       "      <th>Other Comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Individual ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>unrel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>unrel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00098</th>\n",
       "      <td>HG00098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>unrel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>HG00099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>unrel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>HG00100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>unrel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0313e02b-bf00-4219-9609-b80574acc9b7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-97b430e1-4a4c-4a12-8c4c-cf4bbe1edc73\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97b430e1-4a4c-4a12-8c4c-cf4bbe1edc73')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-97b430e1-4a4c-4a12-8c4c-cf4bbe1edc73 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0313e02b-bf00-4219-9609-b80574acc9b7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0313e02b-bf00-4219-9609-b80574acc9b7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pedigree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1690833122451,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "GBSfo4FlV_A_",
    "outputId": "e8d528be-0090-4b2e-f2bf-713ee48ac568"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2504,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "Y_train = pedigree.loc[genotypes.index]['Population']\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1690833123627,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "hiP0EEwsEMNP",
    "outputId": "aa81c647-c76c-4280-c70b-0502b2b1d8c7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2504, 572)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X = genotypes[genotypes.index.isin(Y_train.index)]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3174,
     "status": "ok",
     "timestamp": 1690833127449,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     },
     "user_tz": 240
    },
    "id": "DNU6deVHXIdE",
    "outputId": "e662c03f-88d9-4b8e-cec0-18639769be1b"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2504, 572)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X = X.replace({\n",
    "    '0|0': 0,\n",
    "    '0|1': 1,\n",
    "    '1|0': 2,\n",
    "    '1|1': 3\n",
    "})\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAF"
   ],
   "metadata": {
    "id": "Utkz6Di_pMRJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_max_genotype(g):\n",
    "  v1, v2 = g.split(\"|\")\n",
    "  return max(int(v1), int(v2)) + 1\n",
    "\n",
    "def key_gen(v1, v2):\n",
    "  return f\"{v1}|{v2}\""
   ],
   "metadata": {
    "id": "6ggpJYA-fhKs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833127450,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def maf_mapper(txt):\n",
    "  af = min(list(map(lambda x: float(x), txt.split(\";\")[1].split(\"=\")[1].split(\",\"))))\n",
    "  return min(af, 1-af)"
   ],
   "metadata": {
    "id": "zkgK-B2vnSqg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833127450,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mafs = info.iloc[:, 7:8].applymap(maf_mapper)\n",
    "mafs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "juhDH1Hfnb5Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833127451,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "6d0f6aae-dfa3-487a-ebf5-0d47cec71f4e"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         INFO\n",
       "0    0.024960\n",
       "1    0.005791\n",
       "2    0.037141\n",
       "3    0.000399\n",
       "4    0.000399\n",
       "..        ...\n",
       "567  0.000799\n",
       "568  0.000599\n",
       "569  0.023562\n",
       "570  0.000200\n",
       "571  0.000200\n",
       "\n",
       "[572 rows x 1 columns]"
      ],
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-5f0ca847-47d6-4909-8bf1-8da8e819b533\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.023562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f0ca847-47d6-4909-8bf1-8da8e819b533')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-c9f39116-2b7a-438c-9b09-625df40a5114\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9f39116-2b7a-438c-9b09-625df40a5114')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-c9f39116-2b7a-438c-9b09-625df40a5114 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5f0ca847-47d6-4909-8bf1-8da8e819b533 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5f0ca847-47d6-4909-8bf1-8da8e819b533');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist(mafs, bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5]);"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "VPcxBWGbn1dq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833128544,
     "user_tz": 240,
     "elapsed": 1099,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "5c85154f-41fc-4060-91ed-f4ad3fd580ce"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bin_labels = np.digitize(mafs, bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5], right=False)\n",
    "bin_general_labels, bin_counts = np.unique(bin_labels, return_counts=True)\n",
    "bin_general_labels, bin_counts"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWiEzZuzeABb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833128544,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "d2ac549b-c7d2-41eb-cc4c-3fee7073453a"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5]), array([528,  18,  10,  10,   6]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_pZoO-FvKdr3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833128545,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "feature_size = X.shape[1]\n",
    "inChannel = 5\n",
    "# optimizer learning rate\n",
    "learning_rate = 0.001\n",
    "epochs = 60\n",
    "#epochs = 100   # chr20 LOS 5K\n",
    "\n",
    "\n",
    "# training batch size\n",
    "#batch_size = 32   # u19, 4984 samples\n",
    "bs = 32\n",
    "\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# l1 regulalization\n",
    "kr = 1e-6\n",
    "k_initial = 'glorot_uniform'\n",
    "\n",
    "\n",
    "# channel = inChannel\n",
    "channel = inChannel\n",
    "\n",
    "ndf_num = 128\n",
    "kernel_len = 32\n",
    "num_latent = ndf_num*4\n",
    "p_size = 2\n",
    "\n",
    "\n",
    "\n",
    "#dr_rate = drop_prec\n",
    "dr_rate = 0.2  # avoid overfitting for missing ratio of 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCkow4q5MJk_"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vgGz9_6u8u-O",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833128545,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "outputs": [],
   "source": [
    "# AE model in one cell\n",
    "# # V1: verify our own ae model with yeast genotype data\n",
    "\n",
    "# # 2.2.8 build variatial autoencoder for snp with subclassing function.\n",
    "\n",
    "class SNP_ENCODER(tf.keras.Model):\n",
    "    def __init__(self, feature_size, channel=channel, ndf=ndf_num, kernel_len=kernel_len, n_latent=num_latent, dr=dr_rate):\n",
    "        super(SNP_ENCODER, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.channel = channel\n",
    "        self.ndf = ndf\n",
    "        self.n_latent = n_latent\n",
    "        self.dr = dr # dropout rate\n",
    "\n",
    "        # object, can be saved in tf mode\n",
    "        self.stride=1\n",
    "        self.kl = kernel_len\n",
    "\n",
    "\n",
    "    def build(self, inputs):\n",
    "        #encoder\n",
    "        # dense layer 1\n",
    "        self.c1 = layers.Conv1D(filters=self.ndf, kernel_size=self.kl, strides=self.stride, padding=\"same\",\n",
    "                      activation='relu', use_bias=True,\n",
    "                      kernel_initializer=k_initial, kernel_regularizer=tf.keras.regularizers.L1(kr),\n",
    "                      input_shape=(self.feature_size, self.channel))\n",
    "        self.p1 = layers.MaxPooling1D(pool_size=p_size)\n",
    "        self.drop1 = layers.Dropout(rate=self.dr)\n",
    "\n",
    "        # dense layer 2\n",
    "        self.c2 = layers.Conv1D(filters=(2*self.ndf), kernel_size=self.kl, strides=self.stride, padding=\"same\",\n",
    "                      activation='relu', use_bias=True, kernel_initializer=k_initial,\n",
    "                      kernel_regularizer=tf.keras.regularizers.L1(kr))\n",
    "        self.p2 = layers.MaxPooling1D(pool_size=p_size)\n",
    "        self.drop2 = layers.Dropout(rate=self.dr)\n",
    "\n",
    "        # dense layer 3\n",
    "        self.c3 = layers.Conv1D(filters=(4*self.ndf), kernel_size=self.kl, strides=1, padding=\"same\",\n",
    "                      activation='relu', use_bias=True, kernel_initializer=k_initial,\n",
    "                      kernel_regularizer=tf.keras.regularizers.L1(kr))\n",
    "        self.p3 = layers.MaxPooling1D(pool_size=p_size)\n",
    "        self.drop3 = layers.Dropout(rate=self.dr)\n",
    "\n",
    "        super(SNP_ENCODER, self).build(inputs)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        #print('SNP_ENCODER training flag: ', training)\n",
    "        x = self.c1(inputs)\n",
    "        x = self.p1(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = self.p2(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        return x\n",
    "\n",
    "    # AFAIK: The most convenient method to print model.summary()\n",
    "    # similar to the sequential or functional API like.\n",
    "    def build_graph(self):\n",
    "        x = layers.Input(shape=(self.feature_size, self.channel))\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "\n",
    "\n",
    "# SNP_DECODER(keras.Model):\n",
    "class SNP_DECODER(tf.keras.Model):\n",
    "    def __init__(self, feature_size, channel=channel, ndf=ndf_num, kernel_len=kernel_len, n_latent=num_latent, dr=dr_rate):\n",
    "        super(SNP_DECODER, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.channel = channel\n",
    "        self.ndf = ndf\n",
    "        self.n_latent = n_latent\n",
    "        self.dr = dr # dropout rate\n",
    "\n",
    "        # object, can be saved in tf mode\n",
    "        self.stride=1\n",
    "        self.kl=kernel_len\n",
    "\n",
    "    def build(self, inputs):\n",
    "        #decoder\n",
    "        self.c1 = layers.Conv1D(filters=(2*self.ndf), kernel_size=self.kl, strides=self.stride, padding=\"same\",\n",
    "                      activation='relu', use_bias=True,\n",
    "                      kernel_initializer=k_initial, kernel_regularizer=tf.keras.regularizers.L1(kr),\n",
    "                      input_shape=((self.feature_size>>2), self.n_latent))\n",
    "\n",
    "\n",
    "        self.s1 = layers.UpSampling1D(size=p_size)\n",
    "        self.drop1 = layers.Dropout(rate=self.dr)\n",
    "\n",
    "        # dense layer 2\n",
    "        self.c2 = layers.Conv1D(filters=(1*self.ndf), kernel_size=self.kl, strides=self.stride, padding=\"same\",\n",
    "                      activation='relu', use_bias=True,\n",
    "                      kernel_initializer=k_initial, kernel_regularizer=tf.keras.regularizers.L1(kr))\n",
    "\n",
    "        self.s2 = layers.UpSampling1D(size=p_size)\n",
    "        self.drop2 = layers.Dropout(rate=self.dr)\n",
    "\n",
    "\n",
    "        # dense layer6\n",
    "        self.c3 = layers.Conv1D(filters=self.channel, kernel_size=self.kl, strides=1, padding=\"same\",\n",
    "                      activation='softmax', use_bias=True)\n",
    "\n",
    "        super(SNP_DECODER, self).build(inputs)\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        #print('SNP_DECODER training flag: ', training)\n",
    "        x = self.c1(inputs)\n",
    "        x = self.s1(x)\n",
    "        x = self.drop1(x, training=training)\n",
    "\n",
    "        x = self.c2(x)\n",
    "        x = self.s2(x)\n",
    "        x = self.drop2(x, training=training)\n",
    "\n",
    "\n",
    "        d_out = self.c3(x)\n",
    "        return d_out\n",
    "\n",
    "    # AFAIK: The most convenient method to print model.summary()\n",
    "    # similar to the sequential or functional API like.\n",
    "    def build_graph(self):\n",
    "        x = layers.Input(shape=(self.feature_size>>2, self.n_latent))\n",
    "\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "\n",
    "\n",
    "#class SNP_AE(keras.Model):\n",
    "class SNP_AE(tf.keras.Model):\n",
    "    def __init__(self, feature_size, channel=channel, ndf=ndf_num, n_latent=num_latent, dr=dr_rate):\n",
    "        super(SNP_AE, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.channel = channel\n",
    "        self.ndf = ndf\n",
    "        self.n_latent = n_latent\n",
    "        self.dr = dr # dropout rate\n",
    "\n",
    "        self.encoder = SNP_ENCODER(self.feature_size)\n",
    "        self.decoder = SNP_DECODER(self.feature_size)\n",
    "\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        latent = self.encoder(x, training)\n",
    "        res = self.decoder(latent, training)\n",
    "\n",
    "        return res, latent\n",
    "\n",
    "    # AFAIK: The most convenient method to print model.summary()\n",
    "    # similar to the sequential or functional API like.\n",
    "    def build_graph(self):\n",
    "        x = layers.Input(shape=(self.feature_size, self.channel))\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# plot snp vae encoder model\n",
    "\n",
    "SNP_encoder = SNP_ENCODER(feature_size)\n",
    "SNP_encoder.build((None, feature_size, channel))\n",
    "SNP_encoder.build_graph().summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaAkHl0XKyIM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833132663,
     "user_tz": 240,
     "elapsed": 4122,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "052fc783-f33d-4530-b707-c058302304f8"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 572, 5)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 572, 128)          20608     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 286, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 286, 128)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 286, 256)          1048832   \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 143, 256)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 143, 256)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 143, 512)          4194816   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,264,256\n",
      "Trainable params: 5,264,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# plot snp vae decoder model\n",
    "\n",
    "SNP_decoder = SNP_DECODER(feature_size)\n",
    "\n",
    "SNP_decoder.build((None, feature_size>>2, num_latent))\n",
    "SNP_decoder.build_graph().summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SEoV7YaLzwv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833133149,
     "user_tz": 240,
     "elapsed": 489,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "ac8efaa5-3b11-4dfc-a451-1a24b22a257c"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 143, 512)]        0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 143, 256)          4194560   \n",
      "                                                                 \n",
      " up_sampling1d (UpSampling1D  (None, 286, 256)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 286, 256)          0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 286, 128)          1048704   \n",
      "                                                                 \n",
      " up_sampling1d_1 (UpSampling  (None, 572, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 572, 128)          0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 572, 5)            20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,263,749\n",
      "Trainable params: 5,263,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# plot snp vae model\n",
    "\n",
    "SNP_ae = SNP_AE(feature_size)\n",
    "SNP_ae.build((None, feature_size, channel))\n",
    "SNP_ae.build_graph().summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmP5dBy-L2Ep",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833134051,
     "user_tz": 240,
     "elapsed": 904,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "a99118da-933c-47ed-bced-fafd182c4342"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 572, 5)]          0         \n",
      "                                                                 \n",
      " snp_encoder_1 (SNP_ENCODER)  (None, 143, 512)         5264256   \n",
      "                                                                 \n",
      " snp_decoder_1 (SNP_DECODER)  (None, 572, 5)           5263749   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,528,005\n",
      "Trainable params: 10,528,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# AE model sub-functions\n",
    "\n",
    "def generate_fake_missing(x_in, missing_ratio=0.5):\n",
    "\n",
    "        # Generates missing genotypes\n",
    "        # different missing loci for each individuals\n",
    "        x_fake = x_in.copy()   # with .copy() to not overwrite the original data\n",
    "\n",
    "        for i in range(x_in.shape[0]):\n",
    "            missing_size = int(missing_ratio * x_in.shape[1])\n",
    "\n",
    "            # without repeat random numbers: set replace with false\n",
    "            missing_index = np.random.choice(x_in.shape[1], size=missing_size, replace=False)\n",
    "\n",
    "            # missing loci are encoded as [0, 0]\n",
    "            # x_fake[i, missing_index, :] = [0, 0, 1]  # yeast\n",
    "            x_fake[i, missing_index, :] = [0, 0, 0, 0, 1]  # human\n",
    "\n",
    "        return x_fake\n",
    "        #return x_fake, x_in\n",
    "\n",
    "\n",
    "\n",
    "def loss_function_cce(recon_x, x):\n",
    "    # orders: y_true, y_pred\n",
    "    cce = tf.keras.losses.categorical_crossentropy(x, recon_x)\n",
    "\n",
    "    #cce = np.double(cce)\n",
    "    cce = K.cast(cce, dtype='float32')\n",
    "\n",
    "    lamb1 = 1.0\n",
    "    loss = lamb1*cce\n",
    "    #print('loss:', loss)\n",
    "\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    #print('ave loss:', loss)\n",
    "\n",
    "    return loss\n"
   ],
   "metadata": {
    "id": "-EXc-erqK16d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833134052,
     "user_tz": 240,
     "elapsed": 2,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOA_NexzN5Qq"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "save_dir = \"save_path\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "  # shutil.rmtree(save_dir)\n",
    "  os.makedirs(save_dir)"
   ],
   "metadata": {
    "id": "yF74_Kb360yz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690833135536,
     "user_tz": 240,
     "elapsed": 1486,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# With constraint\n",
    "N_SPLITS=3\n",
    "results = None\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n",
    "fold = 0\n",
    "_x = tf.keras.utils.to_categorical(X[X.index.isin(Y_train.index)].to_numpy(), inChannel)\n",
    "_y = Y_train.to_numpy()\n",
    "for train_index, test_index in kf.split(_x):\n",
    "  fold += 1\n",
    "  accuracies = []\n",
    "  print(f\"Training using fold {fold}\")\n",
    "  print(\"*******************************************\")\n",
    "  print(\"*******************************************\")\n",
    "\n",
    "  x_train, y_train, test_dataset, test_indices = _x[train_index], _y[train_index], (_x[test_index], _y[test_index]),Y_train.index[test_index]\n",
    "  x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10,\n",
    "                                      random_state=fold,\n",
    "                                      shuffle=True,\n",
    "                                      stratify=y_train)\n",
    "\n",
    "\n",
    "  for missing_ratio in [\n",
    "                        0.05,\n",
    "                        0.1,\n",
    "                        0.2\n",
    "                        ]:\n",
    "    train_X = np.copy(x_train)\n",
    "    valid_X = np.copy(x_valid)\n",
    "    print(f\"Missing rate {missing_ratio}\")\n",
    "    print(\"=====================================================\")\n",
    "    train_X_fake = generate_fake_missing(train_X, missing_ratio)\n",
    "\n",
    "    diff = np.absolute(np.array(train_X) - np.array(train_X_fake))\n",
    "    print('train_X_fake diff:', np.sum(diff))\n",
    "\n",
    "\n",
    "    valid_X_fake = generate_fake_missing(valid_X, missing_ratio)\n",
    "    diff = np.absolute(np.array(valid_X) - np.array(valid_X_fake))\n",
    "    print('valid_X_fake diff:', np.sum(diff))\n",
    "\n",
    "\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "      model = SNP_AE(feature_size)\n",
    "      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "      train_loss_metric = tf.keras.metrics.CategoricalCrossentropy()\n",
    "      val_loss_metric = tf.keras.metrics.CategoricalCrossentropy()\n",
    "\n",
    "      train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "      val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "      for epoch in range(epochs):\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "        #----shuffle train data and lablel for each epoch-----------------------------------------------------------------------------------#\n",
    "        # shuffle data and labels at the same time\n",
    "        idx = train_X.shape[0]\n",
    "\n",
    "\n",
    "        indices = tf.range(start=0, limit=idx, dtype=tf.int32)\n",
    "\n",
    "        shuffled_indices = tf.random.shuffle(indices)\n",
    "\n",
    "        train_X_fake = tf.gather(train_X_fake, shuffled_indices)\n",
    "        train_X = tf.gather(train_X, shuffled_indices)\n",
    "\n",
    "        snp_x = tf.data.Dataset.from_tensor_slices(train_X_fake).batch(bs, drop_remainder=True)\n",
    "        snp_y = tf.data.Dataset.from_tensor_slices(train_X).batch(bs, drop_remainder=True)\n",
    "\n",
    "        snp_x_v = tf.data.Dataset.from_tensor_slices(valid_X_fake).batch(bs, drop_remainder=True)\n",
    "        snp_y_v = tf.data.Dataset.from_tensor_slices(valid_X).batch(bs, drop_remainder=True)\n",
    "\n",
    "        loss_batch = []\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, (snp_fake_batch, snp_label_batch) in enumerate(zip(snp_x, snp_y)):\n",
    "          with tf.GradientTape() as tape:\n",
    "              recon_inputs, latents= model(snp_fake_batch, training=True)\n",
    "              loss = loss_function_cce(recon_inputs, snp_label_batch)\n",
    "\n",
    "\n",
    "          grads = tape.gradient(loss, model.trainable_variables)\n",
    "          optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "          loss_batch.append(loss.numpy())\n",
    "\n",
    "\n",
    "          # Update training metric.\n",
    "          train_acc_metric.update_state(snp_label_batch, recon_inputs)\n",
    "          train_loss_metric.update_state(snp_label_batch, recon_inputs)\n",
    "\n",
    "\n",
    "        # Display metrics at the end of each epoch.\n",
    "        train_loss = train_loss_metric.result()\n",
    "        print(\"Training loss over epoch: \", epoch, train_loss.numpy())\n",
    "\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print(\"Training acc over epoch: \", epoch, train_acc.numpy())\n",
    "\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        train_loss_metric.reset_states()\n",
    "        train_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for x_batch_val, y_batch_val in zip(snp_x_v, snp_y_v):\n",
    "\n",
    "            val_recons, latents = model(x_batch_val, training=False)\n",
    "            # Update val metrics\n",
    "            val_loss_metric.update_state(y_batch_val, val_recons)\n",
    "            val_acc_metric.update_state(y_batch_val, val_recons)\n",
    "\n",
    "        val_loss = val_loss_metric.result()\n",
    "        val_acc = val_acc_metric.result()\n",
    "\n",
    "        val_loss_metric.reset_states()\n",
    "        val_acc_metric.reset_states()\n",
    "        #print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        print(\"Validation loss: \", epoch, val_loss.numpy())\n",
    "        print(\"Validation acc: \", epoch, val_acc.numpy())\n",
    "\n",
    "\n",
    "        #print('epoch %s: batch loss = %s' % (epoch, loss_batch))\n",
    "        loss_epoch = np.mean(loss_batch)\n",
    "        print('epoch %s: loss = %s' % (epoch, loss_epoch))\n",
    "\n",
    "    save_name = save_dir + f\"preds_mixed_mr_{missing_ratio}_fold_{fold}_probs\"\n",
    "    avg_accuracy = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    to_save_array = np.zeros((test_dataset[0].shape[0], test_dataset[0].shape[1], inChannel-1), dtype='float32')\n",
    "    test_X_missing = np.copy(test_dataset[0])\n",
    "    for i in tqdm(list(range(test_dataset[0].shape[0]))):\n",
    "      missing_index, _ = train_test_split(np.arange(x_train.shape[1]), train_size=missing_ratio,\n",
    "                                    random_state=i + fold,\n",
    "                                    shuffle=True,\n",
    "                                    stratify=bin_labels\n",
    "                                    )\n",
    "      test_X_missing[i:i+1, missing_index, :] = [0, 0, 0, 0, 1]\n",
    "      # predict\n",
    "      predict_onehot, _ = model(test_X_missing[i:i+1, :, :], training=False)\n",
    "      predict_onehot = predict_onehot.numpy()\n",
    "      # only care the missing position\n",
    "      predict_missing_onehot = predict_onehot[0:1, missing_index, :]\n",
    "      # predict label\n",
    "      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n",
    "\n",
    "      preds.extend(predict_missing.ravel().tolist())\n",
    "\n",
    "      # predict_haplotypes = np.argmax(predict_onehot, axis=2)\n",
    "      # Only for haploids\n",
    "      to_save_array[i] = predict_onehot[:, :, :-1]\n",
    "      # real label\n",
    "      label_missing_onehot = np.argmax(test_dataset[0][i:i + 1, missing_index], axis=2)\n",
    "      label_missing = np.argmax(test_dataset[0][i:i + 1, missing_index], axis=2)\n",
    "      true_labels.extend(label_missing.ravel().tolist())\n",
    "      # accuracy\n",
    "      correct_prediction = np.equal(predict_missing, label_missing)\n",
    "      accuracy = np.mean(correct_prediction)\n",
    "\n",
    "      avg_accuracy.append(accuracy)\n",
    "\n",
    "    # df = pd.DataFrame(to_save_array, columns= headers[:], index = Y_train.index[test_index])\n",
    "    # df.to_csv(save_name)\n",
    "    np.save(save_name, to_save_array)\n",
    "    print('The average imputation accuracy' \\\n",
    "          'on test data with {} missing genotypes is {:.4f}: '\n",
    "        .format(missing_ratio, np.mean(avg_accuracy)))\n",
    "    cnf_matrix = confusion_matrix(true_labels, preds)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP)\n",
    "    print(f\"Sensitivity: {np.mean(TPR)}\")\n",
    "    print(f\"Specificity: {np.mean(TNR)}\")\n",
    "    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n",
    "    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n",
    "    accuracies.append(np.mean(avg_accuracy))\n",
    "\n"
   ],
   "metadata": {
    "id": "Gq5VWuKWVZVx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1690836093267,
     "user_tz": 240,
     "elapsed": 2957736,
     "user": {
      "displayName": "Erfan Mowlaei",
      "userId": "07890245825539195560"
     }
    },
    "outputId": "c77199dd-a21a-4e67-b6de-08e7e0a1759b"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training using fold 1\n",
      "*******************************************\n",
      "*******************************************\n",
      "Missing rate 0.05\n",
      "=====================================================\n",
      "train_X_fake diff: 84112.0\n",
      "valid_X_fake diff: 9352.0\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7a49a4934940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7a49a4934940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss over epoch:  0 0.95916414\n",
      "Training acc over epoch:  0 0.86214346\n",
      "Validation loss:  0 0.23652948\n",
      "Validation acc:  0 0.9578562\n",
      "epoch 0: loss = 0.9591639\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.2254466\n",
      "Training acc over epoch:  1 0.9582961\n",
      "Validation loss:  1 0.21613528\n",
      "Validation acc:  1 0.9578562\n",
      "epoch 1: loss = 0.2254466\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.2132088\n",
      "Training acc over epoch:  2 0.95827\n",
      "Validation loss:  2 0.20903525\n",
      "Validation acc:  2 0.9578562\n",
      "epoch 2: loss = 0.21320878\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.20840837\n",
      "Training acc over epoch:  3 0.9583472\n",
      "Validation loss:  3 0.20566398\n",
      "Validation acc:  3 0.9578562\n",
      "epoch 3: loss = 0.20840834\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.20303015\n",
      "Training acc over epoch:  4 0.95827234\n",
      "Validation loss:  4 0.1944666\n",
      "Validation acc:  4 0.9578562\n",
      "epoch 4: loss = 0.20303012\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.19201201\n",
      "Training acc over epoch:  5 0.95828897\n",
      "Validation loss:  5 0.18278977\n",
      "Validation acc:  5 0.9578562\n",
      "epoch 5: loss = 0.192012\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.18125412\n",
      "Training acc over epoch:  6 0.9582522\n",
      "Validation loss:  6 0.17174637\n",
      "Validation acc:  6 0.9578562\n",
      "epoch 6: loss = 0.1812541\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.17219068\n",
      "Training acc over epoch:  7 0.9582759\n",
      "Validation loss:  7 0.16294265\n",
      "Validation acc:  7 0.9578562\n",
      "epoch 7: loss = 0.17219065\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.16510433\n",
      "Training acc over epoch:  8 0.9584422\n",
      "Validation loss:  8 0.15372281\n",
      "Validation acc:  8 0.9583807\n",
      "epoch 8: loss = 0.16510434\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.15680529\n",
      "Training acc over epoch:  9 0.95937335\n",
      "Validation loss:  9 0.14204122\n",
      "Validation acc:  9 0.960271\n",
      "epoch 9: loss = 0.1568053\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.14471611\n",
      "Training acc over epoch:  10 0.9603009\n",
      "Validation loss:  10 0.12707376\n",
      "Validation acc:  10 0.9617242\n",
      "epoch 10: loss = 0.1447161\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.13034649\n",
      "Training acc over epoch:  11 0.9613722\n",
      "Validation loss:  11 0.107495554\n",
      "Validation acc:  11 0.9653409\n",
      "epoch 11: loss = 0.13034648\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.114674106\n",
      "Training acc over epoch:  12 0.96399695\n",
      "Validation loss:  12 0.0863917\n",
      "Validation acc:  12 0.9712303\n",
      "epoch 12: loss = 0.11467411\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.096177116\n",
      "Training acc over epoch:  13 0.96887827\n",
      "Validation loss:  13 0.06816831\n",
      "Validation acc:  13 0.97878057\n",
      "epoch 13: loss = 0.09617713\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.08010149\n",
      "Training acc over epoch:  14 0.97430354\n",
      "Validation loss:  14 0.053736303\n",
      "Validation acc:  14 0.9838068\n",
      "epoch 14: loss = 0.080101475\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.067303896\n",
      "Training acc over epoch:  15 0.97872764\n",
      "Validation loss:  15 0.047213312\n",
      "Validation acc:  15 0.98658216\n",
      "epoch 15: loss = 0.0673039\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.059006866\n",
      "Training acc over epoch:  16 0.98177993\n",
      "Validation loss:  16 0.037568636\n",
      "Validation acc:  16 0.98978364\n",
      "epoch 16: loss = 0.059006862\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.052331366\n",
      "Training acc over epoch:  17 0.98402584\n",
      "Validation loss:  17 0.032163806\n",
      "Validation acc:  17 0.99105114\n",
      "epoch 17: loss = 0.05233137\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.047323823\n",
      "Training acc over epoch:  18 0.98573846\n",
      "Validation loss:  18 0.031194651\n",
      "Validation acc:  18 0.99184877\n",
      "epoch 18: loss = 0.047323823\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.044315513\n",
      "Training acc over epoch:  19 0.9867943\n",
      "Validation loss:  19 0.028253233\n",
      "Validation acc:  19 0.99295235\n",
      "epoch 19: loss = 0.04431551\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.04085903\n",
      "Training acc over epoch:  20 0.98802114\n",
      "Validation loss:  20 0.02419628\n",
      "Validation acc:  20 0.9936626\n",
      "epoch 20: loss = 0.040859018\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.038632903\n",
      "Training acc over epoch:  21 0.98858887\n",
      "Validation loss:  21 0.023872344\n",
      "Validation acc:  21 0.994045\n",
      "epoch 21: loss = 0.038632892\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.03635619\n",
      "Training acc over epoch:  22 0.9892789\n",
      "Validation loss:  22 0.021566523\n",
      "Validation acc:  22 0.9945039\n",
      "epoch 22: loss = 0.036356192\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.03366441\n",
      "Training acc over epoch:  23 0.99019104\n",
      "Validation loss:  23 0.022176312\n",
      "Validation acc:  23 0.9949191\n",
      "epoch 23: loss = 0.03366441\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.032081645\n",
      "Training acc over epoch:  24 0.99069935\n",
      "Validation loss:  24 0.020533614\n",
      "Validation acc:  24 0.99521416\n",
      "epoch 24: loss = 0.03208165\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.030397303\n",
      "Training acc over epoch:  25 0.99115187\n",
      "Validation loss:  25 0.018736748\n",
      "Validation acc:  25 0.99570584\n",
      "epoch 25: loss = 0.030397309\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.029127603\n",
      "Training acc over epoch:  26 0.99156636\n",
      "Validation loss:  26 0.017349668\n",
      "Validation acc:  26 0.99603367\n",
      "epoch 26: loss = 0.029127605\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.027986355\n",
      "Training acc over epoch:  27 0.9919951\n",
      "Validation loss:  27 0.017220475\n",
      "Validation acc:  27 0.9959681\n",
      "epoch 27: loss = 0.027986355\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.026471809\n",
      "Training acc over epoch:  28 0.99229914\n",
      "Validation loss:  28 0.016155442\n",
      "Validation acc:  28 0.99615383\n",
      "epoch 28: loss = 0.026471801\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.025624907\n",
      "Training acc over epoch:  29 0.99256873\n",
      "Validation loss:  29 0.01596636\n",
      "Validation acc:  29 0.9964707\n",
      "epoch 29: loss = 0.0256249\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.02447892\n",
      "Training acc over epoch:  30 0.9929393\n",
      "Validation loss:  30 0.015144157\n",
      "Validation acc:  30 0.99649256\n",
      "epoch 30: loss = 0.02447892\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.023413222\n",
      "Training acc over epoch:  31 0.9932279\n",
      "Validation loss:  31 0.015048472\n",
      "Validation acc:  31 0.9966346\n",
      "epoch 31: loss = 0.023413217\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.023120983\n",
      "Training acc over epoch:  32 0.9932742\n",
      "Validation loss:  32 0.014721357\n",
      "Validation acc:  32 0.9965909\n",
      "epoch 32: loss = 0.02312098\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.02191163\n",
      "Training acc over epoch:  33 0.99357945\n",
      "Validation loss:  33 0.014009969\n",
      "Validation acc:  33 0.9968094\n",
      "epoch 33: loss = 0.021911632\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.021270677\n",
      "Training acc over epoch:  34 0.9937778\n",
      "Validation loss:  34 0.013977934\n",
      "Validation acc:  34 0.9967876\n",
      "epoch 34: loss = 0.021270681\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.020498255\n",
      "Training acc over epoch:  35 0.9940011\n",
      "Validation loss:  35 0.013485883\n",
      "Validation acc:  35 0.99698424\n",
      "epoch 35: loss = 0.020498255\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.019907683\n",
      "Training acc over epoch:  36 0.9941056\n",
      "Validation loss:  36 0.013595453\n",
      "Validation acc:  36 0.9967985\n",
      "epoch 36: loss = 0.019907683\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.019016877\n",
      "Training acc over epoch:  37 0.9943087\n",
      "Validation loss:  37 0.012727628\n",
      "Validation acc:  37 0.9970608\n",
      "epoch 37: loss = 0.019016875\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.018056793\n",
      "Training acc over epoch:  38 0.9945308\n",
      "Validation loss:  38 0.013172374\n",
      "Validation acc:  38 0.9970498\n",
      "epoch 38: loss = 0.018056791\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.01799852\n",
      "Training acc over epoch:  39 0.99461037\n",
      "Validation loss:  39 0.0129776485\n",
      "Validation acc:  39 0.99714816\n",
      "epoch 39: loss = 0.017998518\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.01746481\n",
      "Training acc over epoch:  40 0.994817\n",
      "Validation loss:  40 0.012686261\n",
      "Validation acc:  40 0.9970389\n",
      "epoch 40: loss = 0.017464811\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.016785176\n",
      "Training acc over epoch:  41 0.9949928\n",
      "Validation loss:  41 0.012418605\n",
      "Validation acc:  41 0.99712634\n",
      "epoch 41: loss = 0.016785176\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.017233236\n",
      "Training acc over epoch:  42 0.9948289\n",
      "Validation loss:  42 0.012674226\n",
      "Validation acc:  42 0.9970826\n",
      "epoch 42: loss = 0.017233236\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.015941817\n",
      "Training acc over epoch:  43 0.9952077\n",
      "Validation loss:  43 0.012760053\n",
      "Validation acc:  43 0.99697334\n",
      "epoch 43: loss = 0.015941817\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.01552364\n",
      "Training acc over epoch:  44 0.9952802\n",
      "Validation loss:  44 0.012458228\n",
      "Validation acc:  44 0.99736667\n",
      "epoch 44: loss = 0.015523643\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.015159199\n",
      "Training acc over epoch:  45 0.99534196\n",
      "Validation loss:  45 0.01245833\n",
      "Validation acc:  45 0.99697334\n",
      "epoch 45: loss = 0.015159197\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.014865876\n",
      "Training acc over epoch:  46 0.9954845\n",
      "Validation loss:  46 0.012380492\n",
      "Validation acc:  46 0.99713725\n",
      "epoch 46: loss = 0.014865878\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.014601985\n",
      "Training acc over epoch:  47 0.995475\n",
      "Validation loss:  47 0.012544465\n",
      "Validation acc:  47 0.99739945\n",
      "epoch 47: loss = 0.014601982\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.0141816875\n",
      "Training acc over epoch:  48 0.9957042\n",
      "Validation loss:  48 0.012405346\n",
      "Validation acc:  48 0.99718094\n",
      "epoch 48: loss = 0.0141816875\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.0139504885\n",
      "Training acc over epoch:  49 0.9956638\n",
      "Validation loss:  49 0.012405164\n",
      "Validation acc:  49 0.997323\n",
      "epoch 49: loss = 0.01395049\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.01332426\n",
      "Training acc over epoch:  50 0.9958075\n",
      "Validation loss:  50 0.012518863\n",
      "Validation acc:  50 0.99734485\n",
      "epoch 50: loss = 0.013324261\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.013095794\n",
      "Training acc over epoch:  51 0.9958847\n",
      "Validation loss:  51 0.012004239\n",
      "Validation acc:  51 0.9972356\n",
      "epoch 51: loss = 0.013095792\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.012850385\n",
      "Training acc over epoch:  52 0.99596786\n",
      "Validation loss:  52 0.012465659\n",
      "Validation acc:  52 0.997323\n",
      "epoch 52: loss = 0.012850386\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.012246204\n",
      "Training acc over epoch:  53 0.9961769\n",
      "Validation loss:  53 0.012284811\n",
      "Validation acc:  53 0.99719185\n",
      "epoch 53: loss = 0.012246204\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.012281672\n",
      "Training acc over epoch:  54 0.996108\n",
      "Validation loss:  54 0.012121362\n",
      "Validation acc:  54 0.99735576\n",
      "epoch 54: loss = 0.012281673\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.011850536\n",
      "Training acc over epoch:  55 0.9962292\n",
      "Validation loss:  55 0.012310694\n",
      "Validation acc:  55 0.9972684\n",
      "epoch 55: loss = 0.011850537\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.011487502\n",
      "Training acc over epoch:  56 0.99635744\n",
      "Validation loss:  56 0.012088098\n",
      "Validation acc:  56 0.997465\n",
      "epoch 56: loss = 0.011487502\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.010912597\n",
      "Training acc over epoch:  57 0.99649996\n",
      "Validation loss:  57 0.01215589\n",
      "Validation acc:  57 0.99736667\n",
      "epoch 57: loss = 0.010912598\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.011144987\n",
      "Training acc over epoch:  58 0.9964928\n",
      "Validation loss:  58 0.012855175\n",
      "Validation acc:  58 0.9975306\n",
      "epoch 58: loss = 0.011144986\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.010638183\n",
      "Training acc over epoch:  59 0.99653673\n",
      "Validation loss:  59 0.0122186355\n",
      "Validation acc:  59 0.9972356\n",
      "epoch 59: loss = 0.010638183\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:22<00:00, 37.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.05 missing genotypes is 0.9639: \n",
      "Sensitivity: 0.38520768346167844\n",
      "Specificity: 0.8118580212683558\n",
      "F1-score macro: 0.4423259067088037\n",
      "F1-score micro: 0.9639007698887938\n",
      "Missing rate 0.1\n",
      "=====================================================\n",
      "train_X_fake diff: 171228.0\n",
      "valid_X_fake diff: 19038.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 1.0488324\n",
      "Training acc over epoch:  0 0.93651307\n",
      "Validation loss:  0 0.25589588\n",
      "Validation acc:  0 0.9578562\n",
      "epoch 0: loss = 1.0488323\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.24748233\n",
      "Training acc over epoch:  1 0.9582997\n",
      "Validation loss:  1 0.22890557\n",
      "Validation acc:  1 0.9578562\n",
      "epoch 1: loss = 0.24748234\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.22646806\n",
      "Training acc over epoch:  2 0.9582807\n",
      "Validation loss:  2 0.21208088\n",
      "Validation acc:  2 0.9578562\n",
      "epoch 2: loss = 0.22646807\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.21001935\n",
      "Training acc over epoch:  3 0.95827234\n",
      "Validation loss:  3 0.19926165\n",
      "Validation acc:  3 0.9578562\n",
      "epoch 3: loss = 0.21001932\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.20112054\n",
      "Training acc over epoch:  4 0.9582961\n",
      "Validation loss:  4 0.19551517\n",
      "Validation acc:  4 0.9578562\n",
      "epoch 4: loss = 0.20112057\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.19673619\n",
      "Training acc over epoch:  5 0.9582961\n",
      "Validation loss:  5 0.1900214\n",
      "Validation acc:  5 0.9578562\n",
      "epoch 5: loss = 0.19673622\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.19217362\n",
      "Training acc over epoch:  6 0.95826167\n",
      "Validation loss:  6 0.18675657\n",
      "Validation acc:  6 0.9578562\n",
      "epoch 6: loss = 0.19217367\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.18786469\n",
      "Training acc over epoch:  7 0.958327\n",
      "Validation loss:  7 0.18056361\n",
      "Validation acc:  7 0.9578562\n",
      "epoch 7: loss = 0.18786466\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.18001385\n",
      "Training acc over epoch:  8 0.9583033\n",
      "Validation loss:  8 0.16939028\n",
      "Validation acc:  8 0.9578562\n",
      "epoch 8: loss = 0.18001382\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.17073546\n",
      "Training acc over epoch:  9 0.9582759\n",
      "Validation loss:  9 0.15921031\n",
      "Validation acc:  9 0.9578562\n",
      "epoch 9: loss = 0.17073546\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.16431798\n",
      "Training acc over epoch:  10 0.9583567\n",
      "Validation loss:  10 0.15095156\n",
      "Validation acc:  10 0.9579764\n",
      "epoch 10: loss = 0.164318\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.15573391\n",
      "Training acc over epoch:  11 0.9587308\n",
      "Validation loss:  11 0.14352359\n",
      "Validation acc:  11 0.95878494\n",
      "epoch 11: loss = 0.15573394\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.14891273\n",
      "Training acc over epoch:  12 0.9592736\n",
      "Validation loss:  12 0.13657928\n",
      "Validation acc:  12 0.9596591\n",
      "epoch 12: loss = 0.14891271\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.1428892\n",
      "Training acc over epoch:  13 0.95976645\n",
      "Validation loss:  13 0.12912846\n",
      "Validation acc:  13 0.96041304\n",
      "epoch 13: loss = 0.14288922\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.13656369\n",
      "Training acc over epoch:  14 0.9603983\n",
      "Validation loss:  14 0.12120071\n",
      "Validation acc:  14 0.9613636\n",
      "epoch 14: loss = 0.1365637\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.12958337\n",
      "Training acc over epoch:  15 0.9612772\n",
      "Validation loss:  15 0.11399693\n",
      "Validation acc:  15 0.96395326\n",
      "epoch 15: loss = 0.12958336\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.12392152\n",
      "Training acc over epoch:  16 0.96223444\n",
      "Validation loss:  16 0.10533803\n",
      "Validation acc:  16 0.96608394\n",
      "epoch 16: loss = 0.12392152\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.11596471\n",
      "Training acc over epoch:  17 0.96366084\n",
      "Validation loss:  17 0.09847598\n",
      "Validation acc:  17 0.9687063\n",
      "epoch 17: loss = 0.11596471\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.11131698\n",
      "Training acc over epoch:  18 0.9649459\n",
      "Validation loss:  18 0.090493314\n",
      "Validation acc:  18 0.970236\n",
      "epoch 18: loss = 0.11131697\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.10437359\n",
      "Training acc over epoch:  19 0.9665908\n",
      "Validation loss:  19 0.08387066\n",
      "Validation acc:  19 0.9730332\n",
      "epoch 19: loss = 0.1043736\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.098353684\n",
      "Training acc over epoch:  20 0.9685754\n",
      "Validation loss:  20 0.07767576\n",
      "Validation acc:  20 0.97691214\n",
      "epoch 20: loss = 0.09835367\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.09562939\n",
      "Training acc over epoch:  21 0.9698902\n",
      "Validation loss:  21 0.07452241\n",
      "Validation acc:  21 0.9782343\n",
      "epoch 21: loss = 0.09562938\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.09019337\n",
      "Training acc over epoch:  22 0.9716265\n",
      "Validation loss:  22 0.071159065\n",
      "Validation acc:  22 0.9786276\n",
      "epoch 22: loss = 0.090193346\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.086865395\n",
      "Training acc over epoch:  23 0.9728368\n",
      "Validation loss:  23 0.0665601\n",
      "Validation acc:  23 0.9810424\n",
      "epoch 23: loss = 0.0868654\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.084300056\n",
      "Training acc over epoch:  24 0.9738772\n",
      "Validation loss:  24 0.06473422\n",
      "Validation acc:  24 0.9829436\n",
      "epoch 24: loss = 0.08430005\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.081141695\n",
      "Training acc over epoch:  25 0.97498643\n",
      "Validation loss:  25 0.062855996\n",
      "Validation acc:  25 0.9827032\n",
      "epoch 25: loss = 0.0811417\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.07932176\n",
      "Training acc over epoch:  26 0.97563374\n",
      "Validation loss:  26 0.06035451\n",
      "Validation acc:  26 0.9841455\n",
      "epoch 26: loss = 0.07932176\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.07713456\n",
      "Training acc over epoch:  27 0.97626674\n",
      "Validation loss:  27 0.058859102\n",
      "Validation acc:  27 0.98382866\n",
      "epoch 27: loss = 0.07713456\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.07604806\n",
      "Training acc over epoch:  28 0.9767775\n",
      "Validation loss:  28 0.057703108\n",
      "Validation acc:  28 0.9850306\n",
      "epoch 28: loss = 0.076048076\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.07446269\n",
      "Training acc over epoch:  29 0.9772917\n",
      "Validation loss:  29 0.0581588\n",
      "Validation acc:  29 0.9842111\n",
      "epoch 29: loss = 0.07446267\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.07238092\n",
      "Training acc over epoch:  30 0.97816825\n",
      "Validation loss:  30 0.05506097\n",
      "Validation acc:  30 0.98571897\n",
      "epoch 30: loss = 0.07238091\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.071600564\n",
      "Training acc over epoch:  31 0.97848654\n",
      "Validation loss:  31 0.05456322\n",
      "Validation acc:  31 0.9855769\n",
      "epoch 31: loss = 0.071600564\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.06992178\n",
      "Training acc over epoch:  32 0.9787965\n",
      "Validation loss:  32 0.053172782\n",
      "Validation acc:  32 0.9860468\n",
      "epoch 32: loss = 0.069921784\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.06874418\n",
      "Training acc over epoch:  33 0.9792205\n",
      "Validation loss:  33 0.05132825\n",
      "Validation acc:  33 0.9871722\n",
      "epoch 33: loss = 0.06874418\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.06783598\n",
      "Training acc over epoch:  34 0.9794616\n",
      "Validation loss:  34 0.050976332\n",
      "Validation acc:  34 0.9869318\n",
      "epoch 34: loss = 0.06783598\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.06679421\n",
      "Training acc over epoch:  35 0.9797585\n",
      "Validation loss:  35 0.050304398\n",
      "Validation acc:  35 0.98706293\n",
      "epoch 35: loss = 0.0667942\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.06576606\n",
      "Training acc over epoch:  36 0.980287\n",
      "Validation loss:  36 0.050635897\n",
      "Validation acc:  36 0.98706293\n",
      "epoch 36: loss = 0.06576605\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.06527465\n",
      "Training acc over epoch:  37 0.98031557\n",
      "Validation loss:  37 0.04907262\n",
      "Validation acc:  37 0.9877732\n",
      "epoch 37: loss = 0.06527464\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.063614056\n",
      "Training acc over epoch:  38 0.98061126\n",
      "Validation loss:  38 0.047547802\n",
      "Validation acc:  38 0.98806816\n",
      "epoch 38: loss = 0.06361406\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.06279664\n",
      "Training acc over epoch:  39 0.98102105\n",
      "Validation loss:  39 0.047689743\n",
      "Validation acc:  39 0.98772943\n",
      "epoch 39: loss = 0.06279664\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.06207661\n",
      "Training acc over epoch:  40 0.98114693\n",
      "Validation loss:  40 0.04690001\n",
      "Validation acc:  40 0.9881447\n",
      "epoch 40: loss = 0.0620766\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.061234277\n",
      "Training acc over epoch:  41 0.98123956\n",
      "Validation loss:  41 0.046366088\n",
      "Validation acc:  41 0.9885927\n",
      "epoch 41: loss = 0.061234273\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.0599331\n",
      "Training acc over epoch:  42 0.9817194\n",
      "Validation loss:  42 0.04720006\n",
      "Validation acc:  42 0.98849434\n",
      "epoch 42: loss = 0.059933092\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.059322204\n",
      "Training acc over epoch:  43 0.9819094\n",
      "Validation loss:  43 0.046533726\n",
      "Validation acc:  43 0.98871285\n",
      "epoch 43: loss = 0.0593222\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.05914719\n",
      "Training acc over epoch:  44 0.98181677\n",
      "Validation loss:  44 0.044979203\n",
      "Validation acc:  44 0.98937935\n",
      "epoch 44: loss = 0.059147187\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.05829371\n",
      "Training acc over epoch:  45 0.98194027\n",
      "Validation loss:  45 0.045902256\n",
      "Validation acc:  45 0.98928106\n",
      "epoch 45: loss = 0.058293726\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.0575249\n",
      "Training acc over epoch:  46 0.9821006\n",
      "Validation loss:  46 0.044821545\n",
      "Validation acc:  46 0.9894559\n",
      "epoch 46: loss = 0.057524893\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.057126716\n",
      "Training acc over epoch:  47 0.9824189\n",
      "Validation loss:  47 0.044514444\n",
      "Validation acc:  47 0.98928106\n",
      "epoch 47: loss = 0.05712671\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.056755517\n",
      "Training acc over epoch:  48 0.9823655\n",
      "Validation loss:  48 0.045468677\n",
      "Validation acc:  48 0.98912805\n",
      "epoch 48: loss = 0.056755513\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.055804\n",
      "Training acc over epoch:  49 0.98261845\n",
      "Validation loss:  49 0.04622697\n",
      "Validation acc:  49 0.9889751\n",
      "epoch 49: loss = 0.05580399\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.05506991\n",
      "Training acc over epoch:  50 0.98272413\n",
      "Validation loss:  50 0.04434084\n",
      "Validation acc:  50 0.98973995\n",
      "epoch 50: loss = 0.05506991\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.054430615\n",
      "Training acc over epoch:  51 0.9829047\n",
      "Validation loss:  51 0.043589372\n",
      "Validation acc:  51 0.9899148\n",
      "epoch 51: loss = 0.05443063\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.053842884\n",
      "Training acc over epoch:  52 0.98305076\n",
      "Validation loss:  52 0.043615103\n",
      "Validation acc:  52 0.98978364\n",
      "epoch 52: loss = 0.05384289\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.053802997\n",
      "Training acc over epoch:  53 0.98312557\n",
      "Validation loss:  53 0.043057065\n",
      "Validation acc:  53 0.98996943\n",
      "epoch 53: loss = 0.053802993\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.052780166\n",
      "Training acc over epoch:  54 0.98317665\n",
      "Validation loss:  54 0.043166853\n",
      "Validation acc:  54 0.99015516\n",
      "epoch 54: loss = 0.052780163\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.05240509\n",
      "Training acc over epoch:  55 0.9833572\n",
      "Validation loss:  55 0.04531675\n",
      "Validation acc:  55 0.98975086\n",
      "epoch 55: loss = 0.05240509\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.051859766\n",
      "Training acc over epoch:  56 0.98351395\n",
      "Validation loss:  56 0.043828167\n",
      "Validation acc:  56 0.9901115\n",
      "epoch 56: loss = 0.051859766\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.05138349\n",
      "Training acc over epoch:  57 0.9834819\n",
      "Validation loss:  57 0.044981845\n",
      "Validation acc:  57 0.98994756\n",
      "epoch 57: loss = 0.051383484\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.050943725\n",
      "Training acc over epoch:  58 0.98368615\n",
      "Validation loss:  58 0.043113846\n",
      "Validation acc:  58 0.9902753\n",
      "epoch 58: loss = 0.050943732\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.050118234\n",
      "Training acc over epoch:  59 0.9839094\n",
      "Validation loss:  59 0.04367857\n",
      "Validation acc:  59 0.99002403\n",
      "epoch 59: loss = 0.050118245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:21<00:00, 38.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.1 missing genotypes is 0.9656: \n",
      "Sensitivity: 0.3497025595004156\n",
      "Specificity: 0.7837061889672639\n",
      "F1-score macro: 0.39926468410716764\n",
      "F1-score micro: 0.9655636096228596\n",
      "Missing rate 0.2\n",
      "=====================================================\n",
      "train_X_fake diff: 342456.0\n",
      "valid_X_fake diff: 38076.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 1.1404835\n",
      "Training acc over epoch:  0 0.9177039\n",
      "Validation loss:  0 0.24131435\n",
      "Validation acc:  0 0.9578562\n",
      "epoch 0: loss = 1.1404835\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.23824416\n",
      "Training acc over epoch:  1 0.9582225\n",
      "Validation loss:  1 0.23152615\n",
      "Validation acc:  1 0.9578562\n",
      "epoch 1: loss = 0.23824412\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.22419709\n",
      "Training acc over epoch:  2 0.95828897\n",
      "Validation loss:  2 0.21935976\n",
      "Validation acc:  2 0.9578562\n",
      "epoch 2: loss = 0.22419707\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.21851319\n",
      "Training acc over epoch:  3 0.9582605\n",
      "Validation loss:  3 0.21791863\n",
      "Validation acc:  3 0.9578562\n",
      "epoch 3: loss = 0.21851318\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.21790098\n",
      "Training acc over epoch:  4 0.9583009\n",
      "Validation loss:  4 0.21747261\n",
      "Validation acc:  4 0.9578562\n",
      "epoch 4: loss = 0.21790102\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.21749556\n",
      "Training acc over epoch:  5 0.9582759\n",
      "Validation loss:  5 0.21722843\n",
      "Validation acc:  5 0.9578562\n",
      "epoch 5: loss = 0.2174956\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.21683481\n",
      "Training acc over epoch:  6 0.9583543\n",
      "Validation loss:  6 0.21697544\n",
      "Validation acc:  6 0.9578562\n",
      "epoch 6: loss = 0.21683486\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.21685193\n",
      "Training acc over epoch:  7 0.9582712\n",
      "Validation loss:  7 0.21658355\n",
      "Validation acc:  7 0.9578562\n",
      "epoch 7: loss = 0.21685196\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.21644633\n",
      "Training acc over epoch:  8 0.95828664\n",
      "Validation loss:  8 0.21630463\n",
      "Validation acc:  8 0.9578562\n",
      "epoch 8: loss = 0.21644624\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.21627952\n",
      "Training acc over epoch:  9 0.9582747\n",
      "Validation loss:  9 0.21606345\n",
      "Validation acc:  9 0.9578562\n",
      "epoch 9: loss = 0.21627952\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.21575308\n",
      "Training acc over epoch:  10 0.9583199\n",
      "Validation loss:  10 0.21573573\n",
      "Validation acc:  10 0.9578562\n",
      "epoch 10: loss = 0.21575308\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.21554273\n",
      "Training acc over epoch:  11 0.9582973\n",
      "Validation loss:  11 0.2153628\n",
      "Validation acc:  11 0.9578562\n",
      "epoch 11: loss = 0.21554273\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.21527445\n",
      "Training acc over epoch:  12 0.95828307\n",
      "Validation loss:  12 0.21507885\n",
      "Validation acc:  12 0.9578562\n",
      "epoch 12: loss = 0.21527444\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.21468431\n",
      "Training acc over epoch:  13 0.9583508\n",
      "Validation loss:  13 0.21493803\n",
      "Validation acc:  13 0.9578562\n",
      "epoch 13: loss = 0.2146843\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.21455127\n",
      "Training acc over epoch:  14 0.958327\n",
      "Validation loss:  14 0.21430856\n",
      "Validation acc:  14 0.9578562\n",
      "epoch 14: loss = 0.21455128\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.2144611\n",
      "Training acc over epoch:  15 0.9582985\n",
      "Validation loss:  15 0.21408036\n",
      "Validation acc:  15 0.9578562\n",
      "epoch 15: loss = 0.21446107\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.21428259\n",
      "Training acc over epoch:  16 0.95825577\n",
      "Validation loss:  16 0.2138569\n",
      "Validation acc:  16 0.9578562\n",
      "epoch 16: loss = 0.21428257\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.21385087\n",
      "Training acc over epoch:  17 0.95829374\n",
      "Validation loss:  17 0.2134303\n",
      "Validation acc:  17 0.9578562\n",
      "epoch 17: loss = 0.21385087\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.21355316\n",
      "Training acc over epoch:  18 0.9583246\n",
      "Validation loss:  18 0.21309605\n",
      "Validation acc:  18 0.9578562\n",
      "epoch 18: loss = 0.21355316\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.21360727\n",
      "Training acc over epoch:  19 0.9582581\n",
      "Validation loss:  19 0.21306513\n",
      "Validation acc:  19 0.9578562\n",
      "epoch 19: loss = 0.2136073\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.2132235\n",
      "Training acc over epoch:  20 0.9582819\n",
      "Validation loss:  20 0.21263005\n",
      "Validation acc:  20 0.9578562\n",
      "epoch 20: loss = 0.2132235\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.21279986\n",
      "Training acc over epoch:  21 0.95828897\n",
      "Validation loss:  21 0.21225479\n",
      "Validation acc:  21 0.9578562\n",
      "epoch 21: loss = 0.21279983\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.21274374\n",
      "Training acc over epoch:  22 0.95828784\n",
      "Validation loss:  22 0.2123072\n",
      "Validation acc:  22 0.9578562\n",
      "epoch 22: loss = 0.2127437\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.21235098\n",
      "Training acc over epoch:  23 0.95828664\n",
      "Validation loss:  23 0.21162385\n",
      "Validation acc:  23 0.9578562\n",
      "epoch 23: loss = 0.212351\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.21212974\n",
      "Training acc over epoch:  24 0.95828307\n",
      "Validation loss:  24 0.21139121\n",
      "Validation acc:  24 0.9578562\n",
      "epoch 24: loss = 0.21212974\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.21175651\n",
      "Training acc over epoch:  25 0.95828897\n",
      "Validation loss:  25 0.21137717\n",
      "Validation acc:  25 0.9578562\n",
      "epoch 25: loss = 0.2117565\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.21178441\n",
      "Training acc over epoch:  26 0.9582819\n",
      "Validation loss:  26 0.21089102\n",
      "Validation acc:  26 0.9578562\n",
      "epoch 26: loss = 0.21178438\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.21148069\n",
      "Training acc over epoch:  27 0.9582712\n",
      "Validation loss:  27 0.21035588\n",
      "Validation acc:  27 0.9578562\n",
      "epoch 27: loss = 0.21148068\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.21114525\n",
      "Training acc over epoch:  28 0.9583068\n",
      "Validation loss:  28 0.21073025\n",
      "Validation acc:  28 0.9578562\n",
      "epoch 28: loss = 0.21114524\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.21103482\n",
      "Training acc over epoch:  29 0.95831156\n",
      "Validation loss:  29 0.20990597\n",
      "Validation acc:  29 0.9578562\n",
      "epoch 29: loss = 0.21103483\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.21066803\n",
      "Training acc over epoch:  30 0.95831156\n",
      "Validation loss:  30 0.20987427\n",
      "Validation acc:  30 0.9578562\n",
      "epoch 30: loss = 0.210668\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.210549\n",
      "Training acc over epoch:  31 0.95836854\n",
      "Validation loss:  31 0.2094572\n",
      "Validation acc:  31 0.9578562\n",
      "epoch 31: loss = 0.210549\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.21046965\n",
      "Training acc over epoch:  32 0.95831156\n",
      "Validation loss:  32 0.20962441\n",
      "Validation acc:  32 0.9578562\n",
      "epoch 32: loss = 0.21046962\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.21025802\n",
      "Training acc over epoch:  33 0.9583555\n",
      "Validation loss:  33 0.20949863\n",
      "Validation acc:  33 0.9578562\n",
      "epoch 33: loss = 0.21025802\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.21000332\n",
      "Training acc over epoch:  34 0.9584398\n",
      "Validation loss:  34 0.20911321\n",
      "Validation acc:  34 0.9578562\n",
      "epoch 34: loss = 0.21000333\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.20959565\n",
      "Training acc over epoch:  35 0.95843154\n",
      "Validation loss:  35 0.20838311\n",
      "Validation acc:  35 0.9578562\n",
      "epoch 35: loss = 0.20959567\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.20954892\n",
      "Training acc over epoch:  36 0.9584208\n",
      "Validation loss:  36 0.20901679\n",
      "Validation acc:  36 0.9578562\n",
      "epoch 36: loss = 0.209549\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.20921382\n",
      "Training acc over epoch:  37 0.9584897\n",
      "Validation loss:  37 0.20807542\n",
      "Validation acc:  37 0.9578562\n",
      "epoch 37: loss = 0.20921388\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.20901729\n",
      "Training acc over epoch:  38 0.95838404\n",
      "Validation loss:  38 0.2076667\n",
      "Validation acc:  38 0.9578562\n",
      "epoch 38: loss = 0.20901729\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.20867154\n",
      "Training acc over epoch:  39 0.95848614\n",
      "Validation loss:  39 0.20759179\n",
      "Validation acc:  39 0.9578562\n",
      "epoch 39: loss = 0.20867151\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.20814031\n",
      "Training acc over epoch:  40 0.95850635\n",
      "Validation loss:  40 0.20777959\n",
      "Validation acc:  40 0.9578562\n",
      "epoch 40: loss = 0.20814033\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.20804371\n",
      "Training acc over epoch:  41 0.95850396\n",
      "Validation loss:  41 0.20695613\n",
      "Validation acc:  41 0.9578562\n",
      "epoch 41: loss = 0.20804368\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.20820211\n",
      "Training acc over epoch:  42 0.9584921\n",
      "Validation loss:  42 0.20660108\n",
      "Validation acc:  42 0.9578562\n",
      "epoch 42: loss = 0.20820211\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.20780988\n",
      "Training acc over epoch:  43 0.95853245\n",
      "Validation loss:  43 0.20654663\n",
      "Validation acc:  43 0.9578562\n",
      "epoch 43: loss = 0.20780988\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.20761073\n",
      "Training acc over epoch:  44 0.95850754\n",
      "Validation loss:  44 0.20633395\n",
      "Validation acc:  44 0.95865387\n",
      "epoch 44: loss = 0.20761073\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.20716761\n",
      "Training acc over epoch:  45 0.9585776\n",
      "Validation loss:  45 0.20593238\n",
      "Validation acc:  45 0.9578562\n",
      "epoch 45: loss = 0.20716763\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.20687962\n",
      "Training acc over epoch:  46 0.9585396\n",
      "Validation loss:  46 0.20588528\n",
      "Validation acc:  46 0.95865387\n",
      "epoch 46: loss = 0.20687963\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.20654802\n",
      "Training acc over epoch:  47 0.9586156\n",
      "Validation loss:  47 0.20554088\n",
      "Validation acc:  47 0.95865387\n",
      "epoch 47: loss = 0.206548\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.2062742\n",
      "Training acc over epoch:  48 0.9585776\n",
      "Validation loss:  48 0.2052638\n",
      "Validation acc:  48 0.95865387\n",
      "epoch 48: loss = 0.2062742\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.20620823\n",
      "Training acc over epoch:  49 0.95858115\n",
      "Validation loss:  49 0.20486984\n",
      "Validation acc:  49 0.95865387\n",
      "epoch 49: loss = 0.20620821\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.20581514\n",
      "Training acc over epoch:  50 0.9586441\n",
      "Validation loss:  50 0.2047181\n",
      "Validation acc:  50 0.95865387\n",
      "epoch 50: loss = 0.20581517\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.20516774\n",
      "Training acc over epoch:  51 0.9586679\n",
      "Validation loss:  51 0.20404083\n",
      "Validation acc:  51 0.95865387\n",
      "epoch 51: loss = 0.20516777\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.20103271\n",
      "Training acc over epoch:  52 0.9586394\n",
      "Validation loss:  52 0.19403198\n",
      "Validation acc:  52 0.9586211\n",
      "epoch 52: loss = 0.20103265\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.1892065\n",
      "Training acc over epoch:  53 0.9587356\n",
      "Validation loss:  53 0.17472334\n",
      "Validation acc:  53 0.9586429\n",
      "epoch 53: loss = 0.18920651\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.17692778\n",
      "Training acc over epoch:  54 0.95877594\n",
      "Validation loss:  54 0.16650236\n",
      "Validation acc:  54 0.9585664\n",
      "epoch 54: loss = 0.17692778\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.17032687\n",
      "Training acc over epoch:  55 0.9588329\n",
      "Validation loss:  55 0.16021104\n",
      "Validation acc:  55 0.95871943\n",
      "epoch 55: loss = 0.1703269\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.16151448\n",
      "Training acc over epoch:  56 0.95956457\n",
      "Validation loss:  56 0.14993954\n",
      "Validation acc:  56 0.95999783\n",
      "epoch 56: loss = 0.16151448\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.15287678\n",
      "Training acc over epoch:  57 0.9603508\n",
      "Validation loss:  57 0.13907126\n",
      "Validation acc:  57 0.9611014\n",
      "epoch 57: loss = 0.15287678\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.14117396\n",
      "Training acc over epoch:  58 0.96112275\n",
      "Validation loss:  58 0.122860245\n",
      "Validation acc:  58 0.9627513\n",
      "epoch 58: loss = 0.14117396\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.12313749\n",
      "Training acc over epoch:  59 0.9635266\n",
      "Validation loss:  59 0.103366464\n",
      "Validation acc:  59 0.96658653\n",
      "epoch 59: loss = 0.123137474\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:21<00:00, 38.63it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.2 missing genotypes is 0.9595: \n",
      "Sensitivity: 0.3233756578284923\n",
      "Specificity: 0.7815167378630512\n",
      "F1-score macro: 0.3588661141061724\n",
      "F1-score micro: 0.9595020485345099\n",
      "Training using fold 2\n",
      "*******************************************\n",
      "*******************************************\n",
      "Missing rate 0.05\n",
      "=====================================================\n",
      "train_X_fake diff: 84112.0\n",
      "valid_X_fake diff: 9352.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 0.7874472\n",
      "Training acc over epoch:  0 0.93615675\n",
      "Validation loss:  0 0.24416026\n",
      "Validation acc:  0 0.95787805\n",
      "epoch 0: loss = 0.7874472\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.23394652\n",
      "Training acc over epoch:  1 0.95797783\n",
      "Validation loss:  1 0.21524185\n",
      "Validation acc:  1 0.95787805\n",
      "epoch 1: loss = 0.23394649\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.2112519\n",
      "Training acc over epoch:  2 0.95799327\n",
      "Validation loss:  2 0.20212477\n",
      "Validation acc:  2 0.95787805\n",
      "epoch 2: loss = 0.21125188\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.19875248\n",
      "Training acc over epoch:  3 0.9580075\n",
      "Validation loss:  3 0.19145276\n",
      "Validation acc:  3 0.95787805\n",
      "epoch 3: loss = 0.1987525\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.19104704\n",
      "Training acc over epoch:  4 0.9579351\n",
      "Validation loss:  4 0.18320261\n",
      "Validation acc:  4 0.95787805\n",
      "epoch 4: loss = 0.19104703\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.18030664\n",
      "Training acc over epoch:  5 0.95800155\n",
      "Validation loss:  5 0.16723388\n",
      "Validation acc:  5 0.95787805\n",
      "epoch 5: loss = 0.18030666\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.16955939\n",
      "Training acc over epoch:  6 0.9579683\n",
      "Validation loss:  6 0.15871751\n",
      "Validation acc:  6 0.95788896\n",
      "epoch 6: loss = 0.16955937\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.1610211\n",
      "Training acc over epoch:  7 0.9584957\n",
      "Validation loss:  7 0.1473278\n",
      "Validation acc:  7 0.95911276\n",
      "epoch 7: loss = 0.16102113\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.14728887\n",
      "Training acc over epoch:  8 0.9596049\n",
      "Validation loss:  8 0.12845613\n",
      "Validation acc:  8 0.9614183\n",
      "epoch 8: loss = 0.14728887\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.1295704\n",
      "Training acc over epoch:  9 0.9612546\n",
      "Validation loss:  9 0.10774974\n",
      "Validation acc:  9 0.96487105\n",
      "epoch 9: loss = 0.12957036\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.11077329\n",
      "Training acc over epoch:  10 0.96539605\n",
      "Validation loss:  10 0.087213196\n",
      "Validation acc:  10 0.97304416\n",
      "epoch 10: loss = 0.1107733\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.095456526\n",
      "Training acc over epoch:  11 0.96931887\n",
      "Validation loss:  11 0.07326609\n",
      "Validation acc:  11 0.97686845\n",
      "epoch 11: loss = 0.09545655\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.08355213\n",
      "Training acc over epoch:  12 0.9732525\n",
      "Validation loss:  12 0.063172445\n",
      "Validation acc:  12 0.98107517\n",
      "epoch 12: loss = 0.08355211\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.07329945\n",
      "Training acc over epoch:  13 0.97651976\n",
      "Validation loss:  13 0.054022916\n",
      "Validation acc:  13 0.98343533\n",
      "epoch 13: loss = 0.07329946\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.0658004\n",
      "Training acc over epoch:  14 0.9791778\n",
      "Validation loss:  14 0.048780512\n",
      "Validation acc:  14 0.98533654\n",
      "epoch 14: loss = 0.0658004\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.06016458\n",
      "Training acc over epoch:  15 0.98110414\n",
      "Validation loss:  15 0.044568054\n",
      "Validation acc:  15 0.9869209\n",
      "epoch 15: loss = 0.060164597\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.055537328\n",
      "Training acc over epoch:  16 0.98267543\n",
      "Validation loss:  16 0.040503874\n",
      "Validation acc:  16 0.98810095\n",
      "epoch 16: loss = 0.05553732\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.052027322\n",
      "Training acc over epoch:  17 0.98388684\n",
      "Validation loss:  17 0.039963577\n",
      "Validation acc:  17 0.9890079\n",
      "epoch 17: loss = 0.05202733\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.049147677\n",
      "Training acc over epoch:  18 0.98496884\n",
      "Validation loss:  18 0.035514154\n",
      "Validation acc:  18 0.9900131\n",
      "epoch 18: loss = 0.049147673\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.045605585\n",
      "Training acc over epoch:  19 0.9860484\n",
      "Validation loss:  19 0.033201024\n",
      "Validation acc:  19 0.99092\n",
      "epoch 19: loss = 0.04560558\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.042714734\n",
      "Training acc over epoch:  20 0.98713636\n",
      "Validation loss:  20 0.031116502\n",
      "Validation acc:  20 0.9913899\n",
      "epoch 20: loss = 0.042714726\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.040209968\n",
      "Training acc over epoch:  21 0.98796654\n",
      "Validation loss:  21 0.029116228\n",
      "Validation acc:  21 0.9922203\n",
      "epoch 21: loss = 0.040209968\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.037721332\n",
      "Training acc over epoch:  22 0.9886079\n",
      "Validation loss:  22 0.02760395\n",
      "Validation acc:  22 0.9927229\n",
      "epoch 22: loss = 0.037721332\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.035180595\n",
      "Training acc over epoch:  23 0.9895188\n",
      "Validation loss:  23 0.026065754\n",
      "Validation acc:  23 0.9932146\n",
      "epoch 23: loss = 0.035180587\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.033527624\n",
      "Training acc over epoch:  24 0.990077\n",
      "Validation loss:  24 0.024689222\n",
      "Validation acc:  24 0.9935861\n",
      "epoch 24: loss = 0.033527624\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.031513028\n",
      "Training acc over epoch:  25 0.9907896\n",
      "Validation loss:  25 0.023329018\n",
      "Validation acc:  25 0.99438375\n",
      "epoch 25: loss = 0.03151303\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.02958473\n",
      "Training acc over epoch:  26 0.9913217\n",
      "Validation loss:  26 0.02314244\n",
      "Validation acc:  26 0.9943291\n",
      "epoch 26: loss = 0.029584737\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.02846063\n",
      "Training acc over epoch:  27 0.9917089\n",
      "Validation loss:  27 0.021326255\n",
      "Validation acc:  27 0.9947225\n",
      "epoch 27: loss = 0.028460633\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.026858874\n",
      "Training acc over epoch:  28 0.99214\n",
      "Validation loss:  28 0.020704405\n",
      "Validation acc:  28 0.9949191\n",
      "epoch 28: loss = 0.026858877\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.025426798\n",
      "Training acc over epoch:  29 0.9924797\n",
      "Validation loss:  29 0.020158634\n",
      "Validation acc:  29 0.9951377\n",
      "epoch 29: loss = 0.025426798\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.024237422\n",
      "Training acc over epoch:  30 0.9928419\n",
      "Validation loss:  30 0.019179083\n",
      "Validation acc:  30 0.9951158\n",
      "epoch 30: loss = 0.024237422\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.023475716\n",
      "Training acc over epoch:  31 0.99299514\n",
      "Validation loss:  31 0.01846992\n",
      "Validation acc:  31 0.99541086\n",
      "epoch 31: loss = 0.023475714\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.022090545\n",
      "Training acc over epoch:  32 0.9934595\n",
      "Validation loss:  32 0.017977409\n",
      "Validation acc:  32 0.9955529\n",
      "epoch 32: loss = 0.022090543\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.021344492\n",
      "Training acc over epoch:  33 0.9936863\n",
      "Validation loss:  33 0.017812258\n",
      "Validation acc:  33 0.99565125\n",
      "epoch 33: loss = 0.021344494\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.020199575\n",
      "Training acc over epoch:  34 0.9939821\n",
      "Validation loss:  34 0.017631907\n",
      "Validation acc:  34 0.99565125\n",
      "epoch 34: loss = 0.02019957\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.019463805\n",
      "Training acc over epoch:  35 0.99418515\n",
      "Validation loss:  35 0.017194102\n",
      "Validation acc:  35 0.9959572\n",
      "epoch 35: loss = 0.019463805\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.018812839\n",
      "Training acc over epoch:  36 0.9943883\n",
      "Validation loss:  36 0.016754705\n",
      "Validation acc:  36 0.9961757\n",
      "epoch 36: loss = 0.01881284\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.01792144\n",
      "Training acc over epoch:  37 0.9945593\n",
      "Validation loss:  37 0.016534088\n",
      "Validation acc:  37 0.9959681\n",
      "epoch 37: loss = 0.017921438\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.016842086\n",
      "Training acc over epoch:  38 0.9948716\n",
      "Validation loss:  38 0.016621273\n",
      "Validation acc:  38 0.99615383\n",
      "epoch 38: loss = 0.016842086\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.016508212\n",
      "Training acc over epoch:  39 0.99486923\n",
      "Validation loss:  39 0.01629619\n",
      "Validation acc:  39 0.996427\n",
      "epoch 39: loss = 0.016508207\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.01577751\n",
      "Training acc over epoch:  40 0.9951638\n",
      "Validation loss:  40 0.016695099\n",
      "Validation acc:  40 0.9962522\n",
      "epoch 40: loss = 0.015777512\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.015201214\n",
      "Training acc over epoch:  41 0.99524933\n",
      "Validation loss:  41 0.015707616\n",
      "Validation acc:  41 0.99652535\n",
      "epoch 41: loss = 0.015201214\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.014690625\n",
      "Training acc over epoch:  42 0.9955047\n",
      "Validation loss:  42 0.015598695\n",
      "Validation acc:  42 0.9963942\n",
      "epoch 42: loss = 0.014690625\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.013753599\n",
      "Training acc over epoch:  43 0.9956697\n",
      "Validation loss:  43 0.015570736\n",
      "Validation acc:  43 0.99658\n",
      "epoch 43: loss = 0.013753597\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.013699839\n",
      "Training acc over epoch:  44 0.99570894\n",
      "Validation loss:  44 0.015494928\n",
      "Validation acc:  44 0.996427\n",
      "epoch 44: loss = 0.013699835\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.013350423\n",
      "Training acc over epoch:  45 0.9958479\n",
      "Validation loss:  45 0.015643183\n",
      "Validation acc:  45 0.99651444\n",
      "epoch 45: loss = 0.013350423\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.013030756\n",
      "Training acc over epoch:  46 0.99587405\n",
      "Validation loss:  46 0.015908655\n",
      "Validation acc:  46 0.99676573\n",
      "epoch 46: loss = 0.013030755\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.01217379\n",
      "Training acc over epoch:  47 0.99616975\n",
      "Validation loss:  47 0.0150025375\n",
      "Validation acc:  47 0.9966346\n",
      "epoch 47: loss = 0.012173786\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.011876475\n",
      "Training acc over epoch:  48 0.9962541\n",
      "Validation loss:  48 0.015459008\n",
      "Validation acc:  48 0.9967111\n",
      "epoch 48: loss = 0.011876478\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.011101837\n",
      "Training acc over epoch:  49 0.9963705\n",
      "Validation loss:  49 0.016258178\n",
      "Validation acc:  49 0.99689686\n",
      "epoch 49: loss = 0.011101838\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.011300943\n",
      "Training acc over epoch:  50 0.99638355\n",
      "Validation loss:  50 0.015813028\n",
      "Validation acc:  50 0.99688596\n",
      "epoch 50: loss = 0.011300944\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.010978196\n",
      "Training acc over epoch:  51 0.9965213\n",
      "Validation loss:  51 0.01602073\n",
      "Validation acc:  51 0.9969187\n",
      "epoch 51: loss = 0.010978193\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.010265496\n",
      "Training acc over epoch:  52 0.99669\n",
      "Validation loss:  52 0.015386377\n",
      "Validation acc:  52 0.99674386\n",
      "epoch 52: loss = 0.010265492\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.00979491\n",
      "Training acc over epoch:  53 0.9967303\n",
      "Validation loss:  53 0.01620042\n",
      "Validation acc:  53 0.99697334\n",
      "epoch 53: loss = 0.00979491\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.009485207\n",
      "Training acc over epoch:  54 0.9969085\n",
      "Validation loss:  54 0.016993426\n",
      "Validation acc:  54 0.9970608\n",
      "epoch 54: loss = 0.009485207\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.0092720855\n",
      "Training acc over epoch:  55 0.99695957\n",
      "Validation loss:  55 0.017859695\n",
      "Validation acc:  55 0.997028\n",
      "epoch 55: loss = 0.0092720855\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.009229745\n",
      "Training acc over epoch:  56 0.99693227\n",
      "Validation loss:  56 0.015528709\n",
      "Validation acc:  56 0.9968204\n",
      "epoch 56: loss = 0.009229743\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.008916017\n",
      "Training acc over epoch:  57 0.9970522\n",
      "Validation loss:  57 0.017225865\n",
      "Validation acc:  57 0.99712634\n",
      "epoch 57: loss = 0.008916018\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.008669426\n",
      "Training acc over epoch:  58 0.9970997\n",
      "Validation loss:  58 0.015804112\n",
      "Validation acc:  58 0.996875\n",
      "epoch 58: loss = 0.008669427\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.008307183\n",
      "Training acc over epoch:  59 0.99728143\n",
      "Validation loss:  59 0.017498009\n",
      "Validation acc:  59 0.9970389\n",
      "epoch 59: loss = 0.008307182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:22<00:00, 37.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.05 missing genotypes is 0.9648: \n",
      "Sensitivity: 0.3756381331798436\n",
      "Specificity: 0.803527629039605\n",
      "F1-score macro: 0.41933098788417966\n",
      "F1-score micro: 0.9647562018819504\n",
      "Missing rate 0.1\n",
      "=====================================================\n",
      "train_X_fake diff: 171228.0\n",
      "valid_X_fake diff: 19038.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 1.0741166\n",
      "Training acc over epoch:  0 0.8773516\n",
      "Validation loss:  0 0.25141227\n",
      "Validation acc:  0 0.95787805\n",
      "epoch 0: loss = 1.0741167\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.23282301\n",
      "Training acc over epoch:  1 0.9579992\n",
      "Validation loss:  1 0.21663217\n",
      "Validation acc:  1 0.95787805\n",
      "epoch 1: loss = 0.23282301\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.21623775\n",
      "Training acc over epoch:  2 0.958017\n",
      "Validation loss:  2 0.21056838\n",
      "Validation acc:  2 0.95787805\n",
      "epoch 2: loss = 0.21623775\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.2123709\n",
      "Training acc over epoch:  3 0.9579897\n",
      "Validation loss:  3 0.20805784\n",
      "Validation acc:  3 0.95787805\n",
      "epoch 3: loss = 0.21237087\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.21043618\n",
      "Training acc over epoch:  4 0.9579838\n",
      "Validation loss:  4 0.20708488\n",
      "Validation acc:  4 0.95787805\n",
      "epoch 4: loss = 0.21043618\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.20722537\n",
      "Training acc over epoch:  5 0.95796\n",
      "Validation loss:  5 0.19982852\n",
      "Validation acc:  5 0.95787805\n",
      "epoch 5: loss = 0.20722537\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.2008871\n",
      "Training acc over epoch:  6 0.95799565\n",
      "Validation loss:  6 0.19396149\n",
      "Validation acc:  6 0.95787805\n",
      "epoch 6: loss = 0.2008871\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.19720216\n",
      "Training acc over epoch:  7 0.95796716\n",
      "Validation loss:  7 0.1924127\n",
      "Validation acc:  7 0.95787805\n",
      "epoch 7: loss = 0.19720216\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.1927159\n",
      "Training acc over epoch:  8 0.9579719\n",
      "Validation loss:  8 0.1848946\n",
      "Validation acc:  8 0.95787805\n",
      "epoch 8: loss = 0.19271593\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.18466619\n",
      "Training acc over epoch:  9 0.95797306\n",
      "Validation loss:  9 0.17445773\n",
      "Validation acc:  9 0.95787805\n",
      "epoch 9: loss = 0.18466617\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.17691737\n",
      "Training acc over epoch:  10 0.9579588\n",
      "Validation loss:  10 0.16549899\n",
      "Validation acc:  10 0.95787805\n",
      "epoch 10: loss = 0.17691734\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.170144\n",
      "Training acc over epoch:  11 0.95804316\n",
      "Validation loss:  11 0.1552076\n",
      "Validation acc:  11 0.9578999\n",
      "epoch 11: loss = 0.170144\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.1624947\n",
      "Training acc over epoch:  12 0.9582237\n",
      "Validation loss:  12 0.14674473\n",
      "Validation acc:  12 0.95893794\n",
      "epoch 12: loss = 0.1624947\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.15553959\n",
      "Training acc over epoch:  13 0.95862865\n",
      "Validation loss:  13 0.14037152\n",
      "Validation acc:  13 0.9595061\n",
      "epoch 13: loss = 0.15553957\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.14990282\n",
      "Training acc over epoch:  14 0.95908475\n",
      "Validation loss:  14 0.13148096\n",
      "Validation acc:  14 0.9605332\n",
      "epoch 14: loss = 0.14990284\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.14435598\n",
      "Training acc over epoch:  15 0.9596952\n",
      "Validation loss:  15 0.12699898\n",
      "Validation acc:  15 0.9620848\n",
      "epoch 15: loss = 0.14435595\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.13902517\n",
      "Training acc over epoch:  16 0.96036977\n",
      "Validation loss:  16 0.12040884\n",
      "Validation acc:  16 0.9641499\n",
      "epoch 16: loss = 0.13902515\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.13034324\n",
      "Training acc over epoch:  17 0.96188885\n",
      "Validation loss:  17 0.10901797\n",
      "Validation acc:  17 0.9674607\n",
      "epoch 17: loss = 0.13034326\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.11959567\n",
      "Training acc over epoch:  18 0.96397793\n",
      "Validation loss:  18 0.09665267\n",
      "Validation acc:  18 0.97079325\n",
      "epoch 18: loss = 0.119595684\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.10586142\n",
      "Training acc over epoch:  19 0.96762526\n",
      "Validation loss:  19 0.08114476\n",
      "Validation acc:  19 0.9750874\n",
      "epoch 19: loss = 0.105861425\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.09423888\n",
      "Training acc over epoch:  20 0.9710042\n",
      "Validation loss:  20 0.07117934\n",
      "Validation acc:  20 0.97957826\n",
      "epoch 20: loss = 0.09423887\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.08437536\n",
      "Training acc over epoch:  21 0.97433084\n",
      "Validation loss:  21 0.06307841\n",
      "Validation acc:  21 0.9825284\n",
      "epoch 21: loss = 0.08437536\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.0763852\n",
      "Training acc over epoch:  22 0.97686774\n",
      "Validation loss:  22 0.05464833\n",
      "Validation acc:  22 0.98497593\n",
      "epoch 22: loss = 0.07638519\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.06945586\n",
      "Training acc over epoch:  23 0.97923595\n",
      "Validation loss:  23 0.051595803\n",
      "Validation acc:  23 0.9861342\n",
      "epoch 23: loss = 0.06945587\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.06456469\n",
      "Training acc over epoch:  24 0.981154\n",
      "Validation loss:  24 0.046209548\n",
      "Validation acc:  24 0.98765296\n",
      "epoch 24: loss = 0.06456468\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.060257077\n",
      "Training acc over epoch:  25 0.98253053\n",
      "Validation loss:  25 0.045072928\n",
      "Validation acc:  25 0.988691\n",
      "epoch 25: loss = 0.060257077\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.05718\n",
      "Training acc over epoch:  26 0.9836268\n",
      "Validation loss:  26 0.040852133\n",
      "Validation acc:  26 0.98937935\n",
      "epoch 26: loss = 0.05718\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.05438306\n",
      "Training acc over epoch:  27 0.9846636\n",
      "Validation loss:  27 0.03898394\n",
      "Validation acc:  27 0.99015516\n",
      "epoch 27: loss = 0.054383054\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.05143577\n",
      "Training acc over epoch:  28 0.9854617\n",
      "Validation loss:  28 0.03765789\n",
      "Validation acc:  28 0.99063593\n",
      "epoch 28: loss = 0.051435757\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.050301205\n",
      "Training acc over epoch:  29 0.9859439\n",
      "Validation loss:  29 0.037000936\n",
      "Validation acc:  29 0.9908872\n",
      "epoch 29: loss = 0.050301205\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.047840677\n",
      "Training acc over epoch:  30 0.98668504\n",
      "Validation loss:  30 0.03464006\n",
      "Validation acc:  30 0.9914991\n",
      "epoch 30: loss = 0.047840673\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.046404183\n",
      "Training acc over epoch:  31 0.98699856\n",
      "Validation loss:  31 0.03381139\n",
      "Validation acc:  31 0.9915756\n",
      "epoch 31: loss = 0.04640418\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.04486564\n",
      "Training acc over epoch:  32 0.98746055\n",
      "Validation loss:  32 0.032251894\n",
      "Validation acc:  32 0.9921656\n",
      "epoch 32: loss = 0.044865638\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.043182846\n",
      "Training acc over epoch:  33 0.9880532\n",
      "Validation loss:  33 0.033318598\n",
      "Validation acc:  33 0.9922312\n",
      "epoch 33: loss = 0.04318284\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.04181839\n",
      "Training acc over epoch:  34 0.98844516\n",
      "Validation loss:  34 0.031489372\n",
      "Validation acc:  34 0.9926355\n",
      "epoch 34: loss = 0.04181839\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.040478926\n",
      "Training acc over epoch:  35 0.9890093\n",
      "Validation loss:  35 0.030524973\n",
      "Validation acc:  35 0.99295235\n",
      "epoch 35: loss = 0.040478926\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.03893434\n",
      "Training acc over epoch:  36 0.9893074\n",
      "Validation loss:  36 0.030258117\n",
      "Validation acc:  36 0.99278843\n",
      "epoch 36: loss = 0.03893434\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.03815742\n",
      "Training acc over epoch:  37 0.98953307\n",
      "Validation loss:  37 0.029057449\n",
      "Validation acc:  37 0.9930507\n",
      "epoch 37: loss = 0.03815742\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.03712444\n",
      "Training acc over epoch:  38 0.9898929\n",
      "Validation loss:  38 0.029537171\n",
      "Validation acc:  38 0.9930398\n",
      "epoch 38: loss = 0.037124436\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.03567887\n",
      "Training acc over epoch:  39 0.99023736\n",
      "Validation loss:  39 0.028890608\n",
      "Validation acc:  39 0.99299604\n",
      "epoch 39: loss = 0.03567887\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.034799926\n",
      "Training acc over epoch:  40 0.9904701\n",
      "Validation loss:  40 0.028292159\n",
      "Validation acc:  40 0.9933785\n",
      "epoch 40: loss = 0.034799926\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.03395643\n",
      "Training acc over epoch:  41 0.9906839\n",
      "Validation loss:  41 0.027309636\n",
      "Validation acc:  41 0.9936735\n",
      "epoch 41: loss = 0.033956427\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.03280605\n",
      "Training acc over epoch:  42 0.9909298\n",
      "Validation loss:  42 0.026702732\n",
      "Validation acc:  42 0.99381554\n",
      "epoch 42: loss = 0.032806057\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.032431144\n",
      "Training acc over epoch:  43 0.9910592\n",
      "Validation loss:  43 0.026593285\n",
      "Validation acc:  43 0.99380463\n",
      "epoch 43: loss = 0.032431144\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.031610504\n",
      "Training acc over epoch:  44 0.9913193\n",
      "Validation loss:  44 0.026813265\n",
      "Validation acc:  44 0.9936407\n",
      "epoch 44: loss = 0.031610496\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.030881206\n",
      "Training acc over epoch:  45 0.991507\n",
      "Validation loss:  45 0.026890326\n",
      "Validation acc:  45 0.99380463\n",
      "epoch 45: loss = 0.030881198\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.030228684\n",
      "Training acc over epoch:  46 0.9916055\n",
      "Validation loss:  46 0.026099352\n",
      "Validation acc:  46 0.993903\n",
      "epoch 46: loss = 0.030228686\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.029336272\n",
      "Training acc over epoch:  47 0.99190485\n",
      "Validation loss:  47 0.02588398\n",
      "Validation acc:  47 0.99393576\n",
      "epoch 47: loss = 0.029336272\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.028489463\n",
      "Training acc over epoch:  48 0.9920462\n",
      "Validation loss:  48 0.025066378\n",
      "Validation acc:  48 0.99414337\n",
      "epoch 48: loss = 0.02848946\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.027848972\n",
      "Training acc over epoch:  49 0.9921887\n",
      "Validation loss:  49 0.025696766\n",
      "Validation acc:  49 0.9938374\n",
      "epoch 49: loss = 0.027848974\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.027364252\n",
      "Training acc over epoch:  50 0.99239653\n",
      "Validation loss:  50 0.025131313\n",
      "Validation acc:  50 0.99417615\n",
      "epoch 50: loss = 0.027364247\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.026470447\n",
      "Training acc over epoch:  51 0.9925236\n",
      "Validation loss:  51 0.024831198\n",
      "Validation acc:  51 0.9941652\n",
      "epoch 51: loss = 0.02647045\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.026340293\n",
      "Training acc over epoch:  52 0.9925224\n",
      "Validation loss:  52 0.024365775\n",
      "Validation acc:  52 0.9945258\n",
      "epoch 52: loss = 0.02634029\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.025687853\n",
      "Training acc over epoch:  53 0.992697\n",
      "Validation loss:  53 0.024538219\n",
      "Validation acc:  53 0.99439466\n",
      "epoch 53: loss = 0.025687855\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.025078718\n",
      "Training acc over epoch:  54 0.9928348\n",
      "Validation loss:  54 0.024266254\n",
      "Validation acc:  54 0.99441653\n",
      "epoch 54: loss = 0.025078714\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.024520108\n",
      "Training acc over epoch:  55 0.9929417\n",
      "Validation loss:  55 0.024952754\n",
      "Validation acc:  55 0.99401224\n",
      "epoch 55: loss = 0.02452011\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.023639185\n",
      "Training acc over epoch:  56 0.9931566\n",
      "Validation loss:  56 0.024973761\n",
      "Validation acc:  56 0.9941652\n",
      "epoch 56: loss = 0.023639183\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.023089197\n",
      "Training acc over epoch:  57 0.9933253\n",
      "Validation loss:  57 0.024422487\n",
      "Validation acc:  57 0.9943728\n",
      "epoch 57: loss = 0.023089198\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.022707421\n",
      "Training acc over epoch:  58 0.9933811\n",
      "Validation loss:  58 0.024557997\n",
      "Validation acc:  58 0.9945149\n",
      "epoch 58: loss = 0.022707418\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.022111695\n",
      "Training acc over epoch:  59 0.9934654\n",
      "Validation loss:  59 0.024943879\n",
      "Validation acc:  59 0.99396855\n",
      "epoch 59: loss = 0.022111695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:22<00:00, 37.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.1 missing genotypes is 0.9672: \n",
      "Sensitivity: 0.41368144573499654\n",
      "Specificity: 0.8243085358556377\n",
      "F1-score macro: 0.46116736445959206\n",
      "F1-score micro: 0.967244458451518\n",
      "Missing rate 0.2\n",
      "=====================================================\n",
      "train_X_fake diff: 342456.0\n",
      "valid_X_fake diff: 38076.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 0.91989595\n",
      "Training acc over epoch:  0 0.8957308\n",
      "Validation loss:  0 0.2330729\n",
      "Validation acc:  0 0.95787805\n",
      "epoch 0: loss = 0.9198958\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.22582759\n",
      "Training acc over epoch:  1 0.9580135\n",
      "Validation loss:  1 0.21664682\n",
      "Validation acc:  1 0.95787805\n",
      "epoch 1: loss = 0.22582759\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.21535827\n",
      "Training acc over epoch:  2 0.9580123\n",
      "Validation loss:  2 0.20925498\n",
      "Validation acc:  2 0.95787805\n",
      "epoch 2: loss = 0.21535826\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.21052864\n",
      "Training acc over epoch:  3 0.9579683\n",
      "Validation loss:  3 0.20685145\n",
      "Validation acc:  3 0.95787805\n",
      "epoch 3: loss = 0.2105286\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.20826058\n",
      "Training acc over epoch:  4 0.9580123\n",
      "Validation loss:  4 0.20347877\n",
      "Validation acc:  4 0.95787805\n",
      "epoch 4: loss = 0.2082606\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.20323665\n",
      "Training acc over epoch:  5 0.9579992\n",
      "Validation loss:  5 0.19604345\n",
      "Validation acc:  5 0.95787805\n",
      "epoch 5: loss = 0.20323667\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.19701874\n",
      "Training acc over epoch:  6 0.958055\n",
      "Validation loss:  6 0.18948156\n",
      "Validation acc:  6 0.95787805\n",
      "epoch 6: loss = 0.19701874\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.19047236\n",
      "Training acc over epoch:  7 0.9579624\n",
      "Validation loss:  7 0.18064763\n",
      "Validation acc:  7 0.95787805\n",
      "epoch 7: loss = 0.19047235\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.18286867\n",
      "Training acc over epoch:  8 0.9580324\n",
      "Validation loss:  8 0.17252961\n",
      "Validation acc:  8 0.95787805\n",
      "epoch 8: loss = 0.18286867\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.17584965\n",
      "Training acc over epoch:  9 0.95797664\n",
      "Validation loss:  9 0.16399424\n",
      "Validation acc:  9 0.9578999\n",
      "epoch 9: loss = 0.17584969\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.1680452\n",
      "Training acc over epoch:  10 0.95834005\n",
      "Validation loss:  10 0.15579897\n",
      "Validation acc:  10 0.95868665\n",
      "epoch 10: loss = 0.1680452\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.159289\n",
      "Training acc over epoch:  11 0.9590728\n",
      "Validation loss:  11 0.14489019\n",
      "Validation acc:  11 0.9600415\n",
      "epoch 11: loss = 0.159289\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.14961629\n",
      "Training acc over epoch:  12 0.95980567\n",
      "Validation loss:  12 0.13391888\n",
      "Validation acc:  12 0.96189904\n",
      "epoch 12: loss = 0.14961629\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.13758248\n",
      "Training acc over epoch:  13 0.9612249\n",
      "Validation loss:  13 0.119454905\n",
      "Validation acc:  13 0.96445584\n",
      "epoch 13: loss = 0.13758248\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.12716751\n",
      "Training acc over epoch:  14 0.96312046\n",
      "Validation loss:  14 0.11052124\n",
      "Validation acc:  14 0.96671766\n",
      "epoch 14: loss = 0.12716751\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.11661612\n",
      "Training acc over epoch:  15 0.96538174\n",
      "Validation loss:  15 0.096878044\n",
      "Validation acc:  15 0.9716783\n",
      "epoch 15: loss = 0.11661611\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.1061774\n",
      "Training acc over epoch:  16 0.96823096\n",
      "Validation loss:  16 0.08786391\n",
      "Validation acc:  16 0.9754698\n",
      "epoch 16: loss = 0.106177405\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.096861005\n",
      "Training acc over epoch:  17 0.97135574\n",
      "Validation loss:  17 0.07894364\n",
      "Validation acc:  17 0.97813594\n",
      "epoch 17: loss = 0.096861\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.089103475\n",
      "Training acc over epoch:  18 0.97396034\n",
      "Validation loss:  18 0.07280959\n",
      "Validation acc:  18 0.9801136\n",
      "epoch 18: loss = 0.08910348\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.08235969\n",
      "Training acc over epoch:  19 0.9762466\n",
      "Validation loss:  19 0.06799637\n",
      "Validation acc:  19 0.9820695\n",
      "epoch 19: loss = 0.0823597\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.07671358\n",
      "Training acc over epoch:  20 0.97834164\n",
      "Validation loss:  20 0.06294926\n",
      "Validation acc:  20 0.9838833\n",
      "epoch 20: loss = 0.076713584\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.07130575\n",
      "Training acc over epoch:  21 0.98032266\n",
      "Validation loss:  21 0.061094973\n",
      "Validation acc:  21 0.9842002\n",
      "epoch 21: loss = 0.07130575\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.06701141\n",
      "Training acc over epoch:  22 0.98191416\n",
      "Validation loss:  22 0.05378469\n",
      "Validation acc:  22 0.98639643\n",
      "epoch 22: loss = 0.06701141\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.06278224\n",
      "Training acc over epoch:  23 0.9831184\n",
      "Validation loss:  23 0.051699616\n",
      "Validation acc:  23 0.98706293\n",
      "epoch 23: loss = 0.06278225\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.059837442\n",
      "Training acc over epoch:  24 0.98400325\n",
      "Validation loss:  24 0.04871602\n",
      "Validation acc:  24 0.98801357\n",
      "epoch 24: loss = 0.059837434\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.057306964\n",
      "Training acc over epoch:  25 0.9847907\n",
      "Validation loss:  25 0.047865503\n",
      "Validation acc:  25 0.9885927\n",
      "epoch 25: loss = 0.057306956\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.054837342\n",
      "Training acc over epoch:  26 0.98530257\n",
      "Validation loss:  26 0.04676477\n",
      "Validation acc:  26 0.9885927\n",
      "epoch 26: loss = 0.054837346\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.053012855\n",
      "Training acc over epoch:  27 0.98589164\n",
      "Validation loss:  27 0.04485738\n",
      "Validation acc:  27 0.98907346\n",
      "epoch 27: loss = 0.053012863\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.051060945\n",
      "Training acc over epoch:  28 0.9864035\n",
      "Validation loss:  28 0.044601858\n",
      "Validation acc:  28 0.98911715\n",
      "epoch 28: loss = 0.05106094\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.0496184\n",
      "Training acc over epoch:  29 0.98668027\n",
      "Validation loss:  29 0.04463443\n",
      "Validation acc:  29 0.9891062\n",
      "epoch 29: loss = 0.049618393\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.048369754\n",
      "Training acc over epoch:  30 0.9870995\n",
      "Validation loss:  30 0.04383583\n",
      "Validation acc:  30 0.9892373\n",
      "epoch 30: loss = 0.04836975\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.046657104\n",
      "Training acc over epoch:  31 0.98739284\n",
      "Validation loss:  31 0.04257758\n",
      "Validation acc:  31 0.9896088\n",
      "epoch 31: loss = 0.046657108\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.04564777\n",
      "Training acc over epoch:  32 0.9876363\n",
      "Validation loss:  32 0.043624848\n",
      "Validation acc:  32 0.98913896\n",
      "epoch 32: loss = 0.04564775\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.04460034\n",
      "Training acc over epoch:  33 0.9878513\n",
      "Validation loss:  33 0.04272549\n",
      "Validation acc:  33 0.98948866\n",
      "epoch 33: loss = 0.044600338\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.044003103\n",
      "Training acc over epoch:  34 0.9878786\n",
      "Validation loss:  34 0.04166425\n",
      "Validation acc:  34 0.9896635\n",
      "epoch 34: loss = 0.0440031\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.04246892\n",
      "Training acc over epoch:  35 0.9882706\n",
      "Validation loss:  35 0.04198263\n",
      "Validation acc:  35 0.9896088\n",
      "epoch 35: loss = 0.042468917\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.04129278\n",
      "Training acc over epoch:  36 0.9885093\n",
      "Validation loss:  36 0.041067928\n",
      "Validation acc:  36 0.9896744\n",
      "epoch 36: loss = 0.041292775\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.040483937\n",
      "Training acc over epoch:  37 0.98877054\n",
      "Validation loss:  37 0.041451264\n",
      "Validation acc:  37 0.9896853\n",
      "epoch 37: loss = 0.040483937\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.039279576\n",
      "Training acc over epoch:  38 0.9888549\n",
      "Validation loss:  38 0.041059744\n",
      "Validation acc:  38 0.9897618\n",
      "epoch 38: loss = 0.039279576\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.038589194\n",
      "Training acc over epoch:  39 0.98915654\n",
      "Validation loss:  39 0.040962055\n",
      "Validation acc:  39 0.98982733\n",
      "epoch 39: loss = 0.038589194\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.037746638\n",
      "Training acc over epoch:  40 0.9892635\n",
      "Validation loss:  40 0.040255472\n",
      "Validation acc:  40 0.9903409\n",
      "epoch 40: loss = 0.037746638\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.03658443\n",
      "Training acc over epoch:  41 0.9896043\n",
      "Validation loss:  41 0.041107386\n",
      "Validation acc:  41 0.98972905\n",
      "epoch 41: loss = 0.036584426\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.03581913\n",
      "Training acc over epoch:  42 0.9896459\n",
      "Validation loss:  42 0.040735323\n",
      "Validation acc:  42 0.99024254\n",
      "epoch 42: loss = 0.035819124\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.03479891\n",
      "Training acc over epoch:  43 0.9898668\n",
      "Validation loss:  43 0.040682416\n",
      "Validation acc:  43 0.99017704\n",
      "epoch 43: loss = 0.0347989\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.03392104\n",
      "Training acc over epoch:  44 0.99002117\n",
      "Validation loss:  44 0.041925833\n",
      "Validation acc:  44 0.9894777\n",
      "epoch 44: loss = 0.033921048\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.032859884\n",
      "Training acc over epoch:  45 0.990254\n",
      "Validation loss:  45 0.040852066\n",
      "Validation acc:  45 0.9901333\n",
      "epoch 45: loss = 0.03285989\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.032146245\n",
      "Training acc over epoch:  46 0.99046654\n",
      "Validation loss:  46 0.040503927\n",
      "Validation acc:  46 0.9904611\n",
      "epoch 46: loss = 0.032146245\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.031099882\n",
      "Training acc over epoch:  47 0.9906138\n",
      "Validation loss:  47 0.040558517\n",
      "Validation acc:  47 0.99014425\n",
      "epoch 47: loss = 0.03109988\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.03032635\n",
      "Training acc over epoch:  48 0.990963\n",
      "Validation loss:  48 0.04146917\n",
      "Validation acc:  48 0.9896853\n",
      "epoch 48: loss = 0.030326348\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.029375022\n",
      "Training acc over epoch:  49 0.9910224\n",
      "Validation loss:  49 0.040784944\n",
      "Validation acc:  49 0.99024254\n",
      "epoch 49: loss = 0.029375017\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.028331544\n",
      "Training acc over epoch:  50 0.9914832\n",
      "Validation loss:  50 0.040649064\n",
      "Validation acc:  50 0.99019885\n",
      "epoch 50: loss = 0.028331546\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.027646942\n",
      "Training acc over epoch:  51 0.99144757\n",
      "Validation loss:  51 0.042216294\n",
      "Validation acc:  51 0.9896853\n",
      "epoch 51: loss = 0.027646938\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.026864523\n",
      "Training acc over epoch:  52 0.99161386\n",
      "Validation loss:  52 0.042374633\n",
      "Validation acc:  52 0.9895105\n",
      "epoch 52: loss = 0.026864521\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.026541797\n",
      "Training acc over epoch:  53 0.9917944\n",
      "Validation loss:  53 0.04233997\n",
      "Validation acc:  53 0.98937935\n",
      "epoch 53: loss = 0.026541797\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.025274\n",
      "Training acc over epoch:  54 0.9920675\n",
      "Validation loss:  54 0.04354479\n",
      "Validation acc:  54 0.9902207\n",
      "epoch 54: loss = 0.025273997\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.025065167\n",
      "Training acc over epoch:  55 0.99209845\n",
      "Validation loss:  55 0.04295492\n",
      "Validation acc:  55 0.9898711\n",
      "epoch 55: loss = 0.025065172\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.024061207\n",
      "Training acc over epoch:  56 0.99239534\n",
      "Validation loss:  56 0.044028424\n",
      "Validation acc:  56 0.9896853\n",
      "epoch 56: loss = 0.024061203\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.023510346\n",
      "Training acc over epoch:  57 0.99255687\n",
      "Validation loss:  57 0.044005938\n",
      "Validation acc:  57 0.9896744\n",
      "epoch 57: loss = 0.023510348\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.022807147\n",
      "Training acc over epoch:  58 0.9926934\n",
      "Validation loss:  58 0.04680511\n",
      "Validation acc:  58 0.9898711\n",
      "epoch 58: loss = 0.022807147\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.02202706\n",
      "Training acc over epoch:  59 0.9929369\n",
      "Validation loss:  59 0.045233198\n",
      "Validation acc:  59 0.9898711\n",
      "epoch 59: loss = 0.022027062\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 835/835 [00:21<00:00, 38.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.2 missing genotypes is 0.9613: \n",
      "Sensitivity: 0.4206018074641978\n",
      "Specificity: 0.8305960719475627\n",
      "F1-score macro: 0.46091968907873426\n",
      "F1-score micro: 0.9612984557201387\n",
      "Training using fold 3\n",
      "*******************************************\n",
      "*******************************************\n",
      "Missing rate 0.05\n",
      "=====================================================\n",
      "train_X_fake diff: 84168.0\n",
      "valid_X_fake diff: 9352.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 0.68774754\n",
      "Training acc over epoch:  0 0.9373242\n",
      "Validation loss:  0 0.24377324\n",
      "Validation acc:  0 0.9584681\n",
      "epoch 0: loss = 0.6877476\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.22981277\n",
      "Training acc over epoch:  1 0.95802534\n",
      "Validation loss:  1 0.21392263\n",
      "Validation acc:  1 0.9584681\n",
      "epoch 1: loss = 0.22981282\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.21634178\n",
      "Training acc over epoch:  2 0.95804316\n",
      "Validation loss:  2 0.20583184\n",
      "Validation acc:  2 0.9584681\n",
      "epoch 2: loss = 0.21634175\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.20474695\n",
      "Training acc over epoch:  3 0.958017\n",
      "Validation loss:  3 0.19171202\n",
      "Validation acc:  3 0.9584681\n",
      "epoch 3: loss = 0.20474695\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.19315346\n",
      "Training acc over epoch:  4 0.9580277\n",
      "Validation loss:  4 0.18627496\n",
      "Validation acc:  4 0.9584681\n",
      "epoch 4: loss = 0.19315349\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.18776098\n",
      "Training acc over epoch:  5 0.9580348\n",
      "Validation loss:  5 0.17885183\n",
      "Validation acc:  5 0.9584681\n",
      "epoch 5: loss = 0.18776095\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.17786786\n",
      "Training acc over epoch:  6 0.9581239\n",
      "Validation loss:  6 0.16189826\n",
      "Validation acc:  6 0.9584681\n",
      "epoch 6: loss = 0.17786787\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.1627144\n",
      "Training acc over epoch:  7 0.9584149\n",
      "Validation loss:  7 0.1444865\n",
      "Validation acc:  7 0.9598995\n",
      "epoch 7: loss = 0.16271442\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.14914994\n",
      "Training acc over epoch:  8 0.9594161\n",
      "Validation loss:  8 0.12911296\n",
      "Validation acc:  8 0.9620192\n",
      "epoch 8: loss = 0.14914992\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.13601463\n",
      "Training acc over epoch:  9 0.9608603\n",
      "Validation loss:  9 0.11416841\n",
      "Validation acc:  9 0.96482736\n",
      "epoch 9: loss = 0.13601461\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.122655965\n",
      "Training acc over epoch:  10 0.9628758\n",
      "Validation loss:  10 0.10107652\n",
      "Validation acc:  10 0.9684222\n",
      "epoch 10: loss = 0.12265597\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.11015149\n",
      "Training acc over epoch:  11 0.9654079\n",
      "Validation loss:  11 0.08899472\n",
      "Validation acc:  11 0.97055286\n",
      "epoch 11: loss = 0.110151485\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.098545566\n",
      "Training acc over epoch:  12 0.96806234\n",
      "Validation loss:  12 0.07547562\n",
      "Validation acc:  12 0.9761364\n",
      "epoch 12: loss = 0.09854556\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.088459946\n",
      "Training acc over epoch:  13 0.97105646\n",
      "Validation loss:  13 0.066962056\n",
      "Validation acc:  13 0.9790975\n",
      "epoch 13: loss = 0.088459924\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.07940586\n",
      "Training acc over epoch:  14 0.97391164\n",
      "Validation loss:  14 0.05878545\n",
      "Validation acc:  14 0.98222244\n",
      "epoch 14: loss = 0.079405844\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.07180248\n",
      "Training acc over epoch:  15 0.9765174\n",
      "Validation loss:  15 0.053765\n",
      "Validation acc:  15 0.98407996\n",
      "epoch 15: loss = 0.07180248\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.066331476\n",
      "Training acc over epoch:  16 0.9783927\n",
      "Validation loss:  16 0.049834486\n",
      "Validation acc:  16 0.9858719\n",
      "epoch 16: loss = 0.06633148\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.06178907\n",
      "Training acc over epoch:  17 0.98002696\n",
      "Validation loss:  17 0.04681111\n",
      "Validation acc:  17 0.9869537\n",
      "epoch 17: loss = 0.06178906\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.057529252\n",
      "Training acc over epoch:  18 0.9815246\n",
      "Validation loss:  18 0.04317453\n",
      "Validation acc:  18 0.9877841\n",
      "epoch 18: loss = 0.057529263\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.054114964\n",
      "Training acc over epoch:  19 0.98291296\n",
      "Validation loss:  19 0.0404919\n",
      "Validation acc:  19 0.98911715\n",
      "epoch 19: loss = 0.054114964\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.050470345\n",
      "Training acc over epoch:  20 0.98414695\n",
      "Validation loss:  20 0.038189407\n",
      "Validation acc:  20 0.9902535\n",
      "epoch 20: loss = 0.05047035\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.04796019\n",
      "Training acc over epoch:  21 0.98494387\n",
      "Validation loss:  21 0.03674172\n",
      "Validation acc:  21 0.99033\n",
      "epoch 21: loss = 0.04796019\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.044264626\n",
      "Training acc over epoch:  22 0.98635244\n",
      "Validation loss:  22 0.032625917\n",
      "Validation acc:  22 0.99144447\n",
      "epoch 22: loss = 0.044264626\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.041286778\n",
      "Training acc over epoch:  23 0.98746413\n",
      "Validation loss:  23 0.03135564\n",
      "Validation acc:  23 0.99188155\n",
      "epoch 23: loss = 0.041286774\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.038851134\n",
      "Training acc over epoch:  24 0.98835254\n",
      "Validation loss:  24 0.028746175\n",
      "Validation acc:  24 0.99270105\n",
      "epoch 24: loss = 0.03885114\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.036110338\n",
      "Training acc over epoch:  25 0.98917556\n",
      "Validation loss:  25 0.027257271\n",
      "Validation acc:  25 0.9932474\n",
      "epoch 25: loss = 0.036110334\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.034067255\n",
      "Training acc over epoch:  26 0.99006516\n",
      "Validation loss:  26 0.027297419\n",
      "Validation acc:  26 0.99352056\n",
      "epoch 26: loss = 0.03406725\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.032147378\n",
      "Training acc over epoch:  27 0.9906103\n",
      "Validation loss:  27 0.02439034\n",
      "Validation acc:  27 0.99401224\n",
      "epoch 27: loss = 0.03214737\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.030460704\n",
      "Training acc over epoch:  28 0.99111027\n",
      "Validation loss:  28 0.023391057\n",
      "Validation acc:  28 0.99462414\n",
      "epoch 28: loss = 0.030460704\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.028517498\n",
      "Training acc over epoch:  29 0.9917219\n",
      "Validation loss:  29 0.02217682\n",
      "Validation acc:  29 0.9949738\n",
      "epoch 29: loss = 0.028517505\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.027053924\n",
      "Training acc over epoch:  30 0.9921887\n",
      "Validation loss:  30 0.021903453\n",
      "Validation acc:  30 0.99506116\n",
      "epoch 30: loss = 0.027053917\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.026046772\n",
      "Training acc over epoch:  31 0.99258894\n",
      "Validation loss:  31 0.020945847\n",
      "Validation acc:  31 0.9951267\n",
      "epoch 31: loss = 0.026046768\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.024963958\n",
      "Training acc over epoch:  32 0.9928906\n",
      "Validation loss:  32 0.020613376\n",
      "Validation acc:  32 0.99542177\n",
      "epoch 32: loss = 0.02496396\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.023426706\n",
      "Training acc over epoch:  33 0.9931756\n",
      "Validation loss:  33 0.020507876\n",
      "Validation acc:  33 0.995531\n",
      "epoch 33: loss = 0.023426704\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.023402993\n",
      "Training acc over epoch:  34 0.9932778\n",
      "Validation loss:  34 0.01896322\n",
      "Validation acc:  34 0.99541086\n",
      "epoch 34: loss = 0.02340299\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.0216393\n",
      "Training acc over epoch:  35 0.9937362\n",
      "Validation loss:  35 0.017958827\n",
      "Validation acc:  35 0.9957168\n",
      "epoch 35: loss = 0.021639299\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.020972913\n",
      "Training acc over epoch:  36 0.994007\n",
      "Validation loss:  36 0.017812511\n",
      "Validation acc:  36 0.99585885\n",
      "epoch 36: loss = 0.020972911\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.019608978\n",
      "Training acc over epoch:  37 0.9943645\n",
      "Validation loss:  37 0.017652072\n",
      "Validation acc:  37 0.9957605\n",
      "epoch 37: loss = 0.019608982\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.019036505\n",
      "Training acc over epoch:  38 0.99442506\n",
      "Validation loss:  38 0.017106423\n",
      "Validation acc:  38 0.99611014\n",
      "epoch 38: loss = 0.019036505\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.018258508\n",
      "Training acc over epoch:  39 0.9946982\n",
      "Validation loss:  39 0.016828375\n",
      "Validation acc:  39 0.99627405\n",
      "epoch 39: loss = 0.01825851\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.017981416\n",
      "Training acc over epoch:  40 0.9947695\n",
      "Validation loss:  40 0.016423086\n",
      "Validation acc:  40 0.9963724\n",
      "epoch 40: loss = 0.017981416\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.017155971\n",
      "Training acc over epoch:  41 0.99503195\n",
      "Validation loss:  41 0.016454091\n",
      "Validation acc:  41 0.99628496\n",
      "epoch 41: loss = 0.017155971\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.01636582\n",
      "Training acc over epoch:  42 0.995241\n",
      "Validation loss:  42 0.01665558\n",
      "Validation acc:  42 0.99643797\n",
      "epoch 42: loss = 0.016365822\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.015840983\n",
      "Training acc over epoch:  43 0.99537164\n",
      "Validation loss:  43 0.01592314\n",
      "Validation acc:  43 0.99653625\n",
      "epoch 43: loss = 0.015840983\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.015557383\n",
      "Training acc over epoch:  44 0.99539185\n",
      "Validation loss:  44 0.0158905\n",
      "Validation acc:  44 0.9967548\n",
      "epoch 44: loss = 0.015557382\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.014851142\n",
      "Training acc over epoch:  45 0.99565077\n",
      "Validation loss:  45 0.015379683\n",
      "Validation acc:  45 0.9966128\n",
      "epoch 45: loss = 0.014851141\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.014120307\n",
      "Training acc over epoch:  46 0.9957648\n",
      "Validation loss:  46 0.015890034\n",
      "Validation acc:  46 0.9968094\n",
      "epoch 46: loss = 0.014120305\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.013666065\n",
      "Training acc over epoch:  47 0.99588233\n",
      "Validation loss:  47 0.0147768045\n",
      "Validation acc:  47 0.9967985\n",
      "epoch 47: loss = 0.0136660645\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.0133823\n",
      "Training acc over epoch:  48 0.99599516\n",
      "Validation loss:  48 0.014937559\n",
      "Validation acc:  48 0.99668926\n",
      "epoch 48: loss = 0.013382302\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.012967789\n",
      "Training acc over epoch:  49 0.9960557\n",
      "Validation loss:  49 0.014887531\n",
      "Validation acc:  49 0.9968532\n",
      "epoch 49: loss = 0.012967789\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.012315691\n",
      "Training acc over epoch:  50 0.996222\n",
      "Validation loss:  50 0.016833805\n",
      "Validation acc:  50 0.9969078\n",
      "epoch 50: loss = 0.012315691\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.011905255\n",
      "Training acc over epoch:  51 0.99638355\n",
      "Validation loss:  51 0.014382834\n",
      "Validation acc:  51 0.9968094\n",
      "epoch 51: loss = 0.011905256\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.011374053\n",
      "Training acc over epoch:  52 0.99652725\n",
      "Validation loss:  52 0.014427772\n",
      "Validation acc:  52 0.9968204\n",
      "epoch 52: loss = 0.011374056\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.011139714\n",
      "Training acc over epoch:  53 0.99654865\n",
      "Validation loss:  53 0.014619803\n",
      "Validation acc:  53 0.9968422\n",
      "epoch 53: loss = 0.011139715\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.010791362\n",
      "Training acc over epoch:  54 0.9966341\n",
      "Validation loss:  54 0.015489962\n",
      "Validation acc:  54 0.9968313\n",
      "epoch 54: loss = 0.01079136\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.010506485\n",
      "Training acc over epoch:  55 0.99678975\n",
      "Validation loss:  55 0.014525291\n",
      "Validation acc:  55 0.9966674\n",
      "epoch 55: loss = 0.010506484\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.010254446\n",
      "Training acc over epoch:  56 0.99679923\n",
      "Validation loss:  56 0.015197454\n",
      "Validation acc:  56 0.9968313\n",
      "epoch 56: loss = 0.010254448\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.009683088\n",
      "Training acc over epoch:  57 0.9969287\n",
      "Validation loss:  57 0.015408938\n",
      "Validation acc:  57 0.9970061\n",
      "epoch 57: loss = 0.00968309\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.0094787115\n",
      "Training acc over epoch:  58 0.9969833\n",
      "Validation loss:  58 0.016180215\n",
      "Validation acc:  58 0.9970608\n",
      "epoch 58: loss = 0.009478711\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.008692497\n",
      "Training acc over epoch:  59 0.9972256\n",
      "Validation loss:  59 0.01639154\n",
      "Validation acc:  59 0.9970717\n",
      "epoch 59: loss = 0.008692496\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 834/834 [00:22<00:00, 36.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.05 missing genotypes is 0.9643: \n",
      "Sensitivity: 0.3677340443108977\n",
      "Specificity: 0.8009452972653394\n",
      "F1-score macro: 0.41523660320636413\n",
      "F1-score micro: 0.9643285371702638\n",
      "Missing rate 0.1\n",
      "=====================================================\n",
      "train_X_fake diff: 171342.0\n",
      "valid_X_fake diff: 19038.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 1.0091143\n",
      "Training acc over epoch:  0 0.80194396\n",
      "Validation loss:  0 0.2362702\n",
      "Validation acc:  0 0.9584681\n",
      "epoch 0: loss = 1.009114\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.23112798\n",
      "Training acc over epoch:  1 0.9580562\n",
      "Validation loss:  1 0.21677116\n",
      "Validation acc:  1 0.9584681\n",
      "epoch 1: loss = 0.23112799\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.21567065\n",
      "Training acc over epoch:  2 0.9580336\n",
      "Validation loss:  2 0.20704067\n",
      "Validation acc:  2 0.9584681\n",
      "epoch 2: loss = 0.21567069\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.20804971\n",
      "Training acc over epoch:  3 0.9580135\n",
      "Validation loss:  3 0.198512\n",
      "Validation acc:  3 0.9584681\n",
      "epoch 3: loss = 0.20804971\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.19722994\n",
      "Training acc over epoch:  4 0.9580158\n",
      "Validation loss:  4 0.18905403\n",
      "Validation acc:  4 0.9584681\n",
      "epoch 4: loss = 0.19722992\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.18682916\n",
      "Training acc over epoch:  5 0.95796597\n",
      "Validation loss:  5 0.1746531\n",
      "Validation acc:  5 0.9584681\n",
      "epoch 5: loss = 0.1868292\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.1754773\n",
      "Training acc over epoch:  6 0.9580408\n",
      "Validation loss:  6 0.1639762\n",
      "Validation acc:  6 0.95847905\n",
      "epoch 6: loss = 0.17547731\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.16436395\n",
      "Training acc over epoch:  7 0.9584196\n",
      "Validation loss:  7 0.14749722\n",
      "Validation acc:  7 0.96046764\n",
      "epoch 7: loss = 0.16436395\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.15091227\n",
      "Training acc over epoch:  8 0.9595337\n",
      "Validation loss:  8 0.13085379\n",
      "Validation acc:  8 0.9617133\n",
      "epoch 8: loss = 0.15091227\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.13714257\n",
      "Training acc over epoch:  9 0.9605907\n",
      "Validation loss:  9 0.11489147\n",
      "Validation acc:  9 0.96416086\n",
      "epoch 9: loss = 0.13714257\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.12345588\n",
      "Training acc over epoch:  10 0.96290904\n",
      "Validation loss:  10 0.09870471\n",
      "Validation acc:  10 0.9705092\n",
      "epoch 10: loss = 0.12345587\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.11075938\n",
      "Training acc over epoch:  11 0.9660397\n",
      "Validation loss:  11 0.0853564\n",
      "Validation acc:  11 0.9747159\n",
      "epoch 11: loss = 0.11075936\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.09912235\n",
      "Training acc over epoch:  12 0.9692571\n",
      "Validation loss:  12 0.07396454\n",
      "Validation acc:  12 0.9786713\n",
      "epoch 12: loss = 0.099122345\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.08903612\n",
      "Training acc over epoch:  13 0.97236645\n",
      "Validation loss:  13 0.066903144\n",
      "Validation acc:  13 0.98085666\n",
      "epoch 13: loss = 0.08903612\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.08100893\n",
      "Training acc over epoch:  14 0.974933\n",
      "Validation loss:  14 0.059754122\n",
      "Validation acc:  14 0.98342437\n",
      "epoch 14: loss = 0.08100893\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.075234115\n",
      "Training acc over epoch:  15 0.9770162\n",
      "Validation loss:  15 0.05645905\n",
      "Validation acc:  15 0.9847465\n",
      "epoch 15: loss = 0.075234115\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.06998846\n",
      "Training acc over epoch:  16 0.97904235\n",
      "Validation loss:  16 0.050174206\n",
      "Validation acc:  16 0.9865494\n",
      "epoch 16: loss = 0.06998847\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.0649025\n",
      "Training acc over epoch:  17 0.9807514\n",
      "Validation loss:  17 0.047425956\n",
      "Validation acc:  17 0.9877404\n",
      "epoch 17: loss = 0.064902484\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.061961588\n",
      "Training acc over epoch:  18 0.98180604\n",
      "Validation loss:  18 0.04558688\n",
      "Validation acc:  18 0.9882102\n",
      "epoch 18: loss = 0.061961588\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.057967868\n",
      "Training acc over epoch:  19 0.98282987\n",
      "Validation loss:  19 0.041234016\n",
      "Validation acc:  19 0.9891936\n",
      "epoch 19: loss = 0.057967875\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.055142913\n",
      "Training acc over epoch:  20 0.98407453\n",
      "Validation loss:  20 0.03915629\n",
      "Validation acc:  20 0.9899148\n",
      "epoch 20: loss = 0.055142917\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.05291827\n",
      "Training acc over epoch:  21 0.9847776\n",
      "Validation loss:  21 0.03816307\n",
      "Validation acc:  21 0.9903191\n",
      "epoch 21: loss = 0.052918263\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.05086214\n",
      "Training acc over epoch:  22 0.98528236\n",
      "Validation loss:  22 0.03738584\n",
      "Validation acc:  22 0.9906687\n",
      "epoch 22: loss = 0.05086214\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.04951265\n",
      "Training acc over epoch:  23 0.98576576\n",
      "Validation loss:  23 0.03496641\n",
      "Validation acc:  23 0.99097466\n",
      "epoch 23: loss = 0.049512655\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.047607534\n",
      "Training acc over epoch:  24 0.9864522\n",
      "Validation loss:  24 0.035564013\n",
      "Validation acc:  24 0.9917832\n",
      "epoch 24: loss = 0.047607537\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.045847513\n",
      "Training acc over epoch:  25 0.9867408\n",
      "Validation loss:  25 0.03255771\n",
      "Validation acc:  25 0.9922094\n",
      "epoch 25: loss = 0.04584752\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.04445485\n",
      "Training acc over epoch:  26 0.98726696\n",
      "Validation loss:  26 0.032218643\n",
      "Validation acc:  26 0.9925153\n",
      "epoch 26: loss = 0.044454854\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.042991746\n",
      "Training acc over epoch:  27 0.9876126\n",
      "Validation loss:  27 0.030389879\n",
      "Validation acc:  27 0.99269015\n",
      "epoch 27: loss = 0.04299175\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.04224483\n",
      "Training acc over epoch:  28 0.9879487\n",
      "Validation loss:  28 0.029954828\n",
      "Validation acc:  28 0.9927775\n",
      "epoch 28: loss = 0.04224483\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.040445723\n",
      "Training acc over epoch:  29 0.9884214\n",
      "Validation loss:  29 0.030317295\n",
      "Validation acc:  29 0.99271196\n",
      "epoch 29: loss = 0.040445723\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.04000901\n",
      "Training acc over epoch:  30 0.9883668\n",
      "Validation loss:  30 0.029589878\n",
      "Validation acc:  30 0.99307257\n",
      "epoch 30: loss = 0.040009014\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.038743865\n",
      "Training acc over epoch:  31 0.9887872\n",
      "Validation loss:  31 0.028864\n",
      "Validation acc:  31 0.99334574\n",
      "epoch 31: loss = 0.038743865\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.038152903\n",
      "Training acc over epoch:  32 0.9888276\n",
      "Validation loss:  32 0.028750472\n",
      "Validation acc:  32 0.9929742\n",
      "epoch 32: loss = 0.03815291\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.036759857\n",
      "Training acc over epoch:  33 0.9893169\n",
      "Validation loss:  33 0.028321998\n",
      "Validation acc:  33 0.99336755\n",
      "epoch 33: loss = 0.036759857\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.0362128\n",
      "Training acc over epoch:  34 0.9893359\n",
      "Validation loss:  34 0.02783484\n",
      "Validation acc:  34 0.99332386\n",
      "epoch 34: loss = 0.0362128\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.035399925\n",
      "Training acc over epoch:  35 0.98951524\n",
      "Validation loss:  35 0.027862005\n",
      "Validation acc:  35 0.9934441\n",
      "epoch 35: loss = 0.035399918\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.034474324\n",
      "Training acc over epoch:  36 0.98970765\n",
      "Validation loss:  36 0.027476445\n",
      "Validation acc:  36 0.9934987\n",
      "epoch 36: loss = 0.034474317\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.03442043\n",
      "Training acc over epoch:  37 0.9897955\n",
      "Validation loss:  37 0.027661057\n",
      "Validation acc:  37 0.9937063\n",
      "epoch 37: loss = 0.034420434\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.033379927\n",
      "Training acc over epoch:  38 0.99005324\n",
      "Validation loss:  38 0.027168686\n",
      "Validation acc:  38 0.99381554\n",
      "epoch 38: loss = 0.03337992\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.03250068\n",
      "Training acc over epoch:  39 0.99026227\n",
      "Validation loss:  39 0.027207984\n",
      "Validation acc:  39 0.99375\n",
      "epoch 39: loss = 0.032500677\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.032292508\n",
      "Training acc over epoch:  40 0.9903502\n",
      "Validation loss:  40 0.027236395\n",
      "Validation acc:  40 0.993302\n",
      "epoch 40: loss = 0.032292508\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.031149875\n",
      "Training acc over epoch:  41 0.9904963\n",
      "Validation loss:  41 0.02659291\n",
      "Validation acc:  41 0.9941215\n",
      "epoch 41: loss = 0.031149872\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.030915823\n",
      "Training acc over epoch:  42 0.99067324\n",
      "Validation loss:  42 0.026978385\n",
      "Validation acc:  42 0.99420893\n",
      "epoch 42: loss = 0.030915821\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.03010008\n",
      "Training acc over epoch:  43 0.9908395\n",
      "Validation loss:  43 0.026564596\n",
      "Validation acc:  43 0.99396855\n",
      "epoch 43: loss = 0.03010008\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.029412495\n",
      "Training acc over epoch:  44 0.9911245\n",
      "Validation loss:  44 0.026881127\n",
      "Validation acc:  44 0.9939248\n",
      "epoch 44: loss = 0.029412495\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.02878821\n",
      "Training acc over epoch:  45 0.99116135\n",
      "Validation loss:  45 0.026451025\n",
      "Validation acc:  45 0.99397945\n",
      "epoch 45: loss = 0.028788207\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.028362697\n",
      "Training acc over epoch:  46 0.99120295\n",
      "Validation loss:  46 0.026517054\n",
      "Validation acc:  46 0.99413246\n",
      "epoch 46: loss = 0.028362697\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.027485836\n",
      "Training acc over epoch:  47 0.9915604\n",
      "Validation loss:  47 0.026209839\n",
      "Validation acc:  47 0.99413246\n",
      "epoch 47: loss = 0.027485836\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.026847944\n",
      "Training acc over epoch:  48 0.99166846\n",
      "Validation loss:  48 0.025805697\n",
      "Validation acc:  48 0.99423075\n",
      "epoch 48: loss = 0.026847947\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.025795415\n",
      "Training acc over epoch:  49 0.992083\n",
      "Validation loss:  49 0.02550442\n",
      "Validation acc:  49 0.9941215\n",
      "epoch 49: loss = 0.025795419\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.025247782\n",
      "Training acc over epoch:  50 0.9921792\n",
      "Validation loss:  50 0.025726868\n",
      "Validation acc:  50 0.9941543\n",
      "epoch 50: loss = 0.025247777\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.024323495\n",
      "Training acc over epoch:  51 0.9923906\n",
      "Validation loss:  51 0.025903972\n",
      "Validation acc:  51 0.99442744\n",
      "epoch 51: loss = 0.024323495\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.023256637\n",
      "Training acc over epoch:  52 0.9927695\n",
      "Validation loss:  52 0.025491491\n",
      "Validation acc:  52 0.994493\n",
      "epoch 52: loss = 0.023256632\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.023213703\n",
      "Training acc over epoch:  53 0.99281937\n",
      "Validation loss:  53 0.025027363\n",
      "Validation acc:  53 0.9941652\n",
      "epoch 53: loss = 0.023213705\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.02284674\n",
      "Training acc over epoch:  54 0.99279916\n",
      "Validation loss:  54 0.025658455\n",
      "Validation acc:  54 0.9944821\n",
      "epoch 54: loss = 0.02284674\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.021961868\n",
      "Training acc over epoch:  55 0.9931115\n",
      "Validation loss:  55 0.026182996\n",
      "Validation acc:  55 0.9947662\n",
      "epoch 55: loss = 0.021961868\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.021908911\n",
      "Training acc over epoch:  56 0.9929286\n",
      "Validation loss:  56 0.025318552\n",
      "Validation acc:  56 0.9942417\n",
      "epoch 56: loss = 0.021908915\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.021750292\n",
      "Training acc over epoch:  57 0.9931305\n",
      "Validation loss:  57 0.025594631\n",
      "Validation acc:  57 0.9943291\n",
      "epoch 57: loss = 0.02175029\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.020636426\n",
      "Training acc over epoch:  58 0.9934939\n",
      "Validation loss:  58 0.025596472\n",
      "Validation acc:  58 0.9944602\n",
      "epoch 58: loss = 0.020636428\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.021004451\n",
      "Training acc over epoch:  59 0.9932754\n",
      "Validation loss:  59 0.027083041\n",
      "Validation acc:  59 0.99467874\n",
      "epoch 59: loss = 0.021004451\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 834/834 [00:21<00:00, 38.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.1 missing genotypes is 0.9663: \n",
      "Sensitivity: 0.39416409968000166\n",
      "Specificity: 0.8063992323220865\n",
      "F1-score macro: 0.42743884338336813\n",
      "F1-score micro: 0.9663216794985064\n",
      "Missing rate 0.2\n",
      "=====================================================\n",
      "train_X_fake diff: 342684.0\n",
      "valid_X_fake diff: 38076.0\n",
      "Start of epoch 0\n",
      "Training loss over epoch:  0 1.4374926\n",
      "Training acc over epoch:  0 0.9407946\n",
      "Validation loss:  0 0.2818975\n",
      "Validation acc:  0 0.9584681\n",
      "epoch 0: loss = 1.4374924\n",
      "Start of epoch 1\n",
      "Training loss over epoch:  1 0.24287789\n",
      "Training acc over epoch:  1 0.9580811\n",
      "Validation loss:  1 0.23209995\n",
      "Validation acc:  1 0.9584681\n",
      "epoch 1: loss = 0.2428779\n",
      "Start of epoch 2\n",
      "Training loss over epoch:  2 0.23455621\n",
      "Training acc over epoch:  2 0.95807165\n",
      "Validation loss:  2 0.22992694\n",
      "Validation acc:  2 0.9584681\n",
      "epoch 2: loss = 0.23455621\n",
      "Start of epoch 3\n",
      "Training loss over epoch:  3 0.23262233\n",
      "Training acc over epoch:  3 0.95802414\n",
      "Validation loss:  3 0.22823499\n",
      "Validation acc:  3 0.9584681\n",
      "epoch 3: loss = 0.23262237\n",
      "Start of epoch 4\n",
      "Training loss over epoch:  4 0.23106663\n",
      "Training acc over epoch:  4 0.9580384\n",
      "Validation loss:  4 0.22660355\n",
      "Validation acc:  4 0.9584681\n",
      "epoch 4: loss = 0.23106666\n",
      "Start of epoch 5\n",
      "Training loss over epoch:  5 0.22944759\n",
      "Training acc over epoch:  5 0.9580099\n",
      "Validation loss:  5 0.22477436\n",
      "Validation acc:  5 0.9584681\n",
      "epoch 5: loss = 0.22944757\n",
      "Start of epoch 6\n",
      "Training loss over epoch:  6 0.22750248\n",
      "Training acc over epoch:  6 0.9579802\n",
      "Validation loss:  6 0.22262143\n",
      "Validation acc:  6 0.9584681\n",
      "epoch 6: loss = 0.2275025\n",
      "Start of epoch 7\n",
      "Training loss over epoch:  7 0.2251018\n",
      "Training acc over epoch:  7 0.9580182\n",
      "Validation loss:  7 0.22042799\n",
      "Validation acc:  7 0.9584681\n",
      "epoch 7: loss = 0.22510175\n",
      "Start of epoch 8\n",
      "Training loss over epoch:  8 0.22273496\n",
      "Training acc over epoch:  8 0.95805025\n",
      "Validation loss:  8 0.21783689\n",
      "Validation acc:  8 0.9584681\n",
      "epoch 8: loss = 0.22273491\n",
      "Start of epoch 9\n",
      "Training loss over epoch:  9 0.21990243\n",
      "Training acc over epoch:  9 0.95799565\n",
      "Validation loss:  9 0.21558522\n",
      "Validation acc:  9 0.9584681\n",
      "epoch 9: loss = 0.21990246\n",
      "Start of epoch 10\n",
      "Training loss over epoch:  10 0.21889226\n",
      "Training acc over epoch:  10 0.9580384\n",
      "Validation loss:  10 0.21496053\n",
      "Validation acc:  10 0.9584681\n",
      "epoch 10: loss = 0.2188922\n",
      "Start of epoch 11\n",
      "Training loss over epoch:  11 0.21825126\n",
      "Training acc over epoch:  11 0.9579897\n",
      "Validation loss:  11 0.21419388\n",
      "Validation acc:  11 0.9584681\n",
      "epoch 11: loss = 0.21825127\n",
      "Start of epoch 12\n",
      "Training loss over epoch:  12 0.21734594\n",
      "Training acc over epoch:  12 0.9580099\n",
      "Validation loss:  12 0.21333534\n",
      "Validation acc:  12 0.9584681\n",
      "epoch 12: loss = 0.21734594\n",
      "Start of epoch 13\n",
      "Training loss over epoch:  13 0.2168104\n",
      "Training acc over epoch:  13 0.95797545\n",
      "Validation loss:  13 0.21245775\n",
      "Validation acc:  13 0.9584681\n",
      "epoch 13: loss = 0.21681044\n",
      "Start of epoch 14\n",
      "Training loss over epoch:  14 0.21597748\n",
      "Training acc over epoch:  14 0.95800155\n",
      "Validation loss:  14 0.21164413\n",
      "Validation acc:  14 0.9584681\n",
      "epoch 14: loss = 0.21597748\n",
      "Start of epoch 15\n",
      "Training loss over epoch:  15 0.21570192\n",
      "Training acc over epoch:  15 0.9579434\n",
      "Validation loss:  15 0.21128288\n",
      "Validation acc:  15 0.9584681\n",
      "epoch 15: loss = 0.2157019\n",
      "Start of epoch 16\n",
      "Training loss over epoch:  16 0.21483006\n",
      "Training acc over epoch:  16 0.95801467\n",
      "Validation loss:  16 0.21058655\n",
      "Validation acc:  16 0.9584681\n",
      "epoch 16: loss = 0.21483004\n",
      "Start of epoch 17\n",
      "Training loss over epoch:  17 0.21403328\n",
      "Training acc over epoch:  17 0.95804197\n",
      "Validation loss:  17 0.20982644\n",
      "Validation acc:  17 0.9584681\n",
      "epoch 17: loss = 0.21403332\n",
      "Start of epoch 18\n",
      "Training loss over epoch:  18 0.213643\n",
      "Training acc over epoch:  18 0.9580158\n",
      "Validation loss:  18 0.20932618\n",
      "Validation acc:  18 0.9584681\n",
      "epoch 18: loss = 0.21364307\n",
      "Start of epoch 19\n",
      "Training loss over epoch:  19 0.21281584\n",
      "Training acc over epoch:  19 0.9580776\n",
      "Validation loss:  19 0.20859851\n",
      "Validation acc:  19 0.9584681\n",
      "epoch 19: loss = 0.21281585\n",
      "Start of epoch 20\n",
      "Training loss over epoch:  20 0.21241674\n",
      "Training acc over epoch:  20 0.9580538\n",
      "Validation loss:  20 0.20779593\n",
      "Validation acc:  20 0.9584681\n",
      "epoch 20: loss = 0.21241671\n",
      "Start of epoch 21\n",
      "Training loss over epoch:  21 0.21173233\n",
      "Training acc over epoch:  21 0.9580895\n",
      "Validation loss:  21 0.20716873\n",
      "Validation acc:  21 0.9584681\n",
      "epoch 21: loss = 0.21173234\n",
      "Start of epoch 22\n",
      "Training loss over epoch:  22 0.21133028\n",
      "Training acc over epoch:  22 0.9581085\n",
      "Validation loss:  22 0.20674217\n",
      "Validation acc:  22 0.9584681\n",
      "epoch 22: loss = 0.21133026\n",
      "Start of epoch 23\n",
      "Training loss over epoch:  23 0.21076885\n",
      "Training acc over epoch:  23 0.9581845\n",
      "Validation loss:  23 0.20604591\n",
      "Validation acc:  23 0.9584681\n",
      "epoch 23: loss = 0.21076882\n",
      "Start of epoch 24\n",
      "Training loss over epoch:  24 0.21040091\n",
      "Training acc over epoch:  24 0.9582474\n",
      "Validation loss:  24 0.20551862\n",
      "Validation acc:  24 0.9584681\n",
      "epoch 24: loss = 0.21040086\n",
      "Start of epoch 25\n",
      "Training loss over epoch:  25 0.2097527\n",
      "Training acc over epoch:  25 0.9582676\n",
      "Validation loss:  25 0.20508905\n",
      "Validation acc:  25 0.9592111\n",
      "epoch 25: loss = 0.20975266\n",
      "Start of epoch 26\n",
      "Training loss over epoch:  26 0.20944935\n",
      "Training acc over epoch:  26 0.95831037\n",
      "Validation loss:  26 0.20473872\n",
      "Validation acc:  26 0.9592111\n",
      "epoch 26: loss = 0.20944934\n",
      "Start of epoch 27\n",
      "Training loss over epoch:  27 0.20921195\n",
      "Training acc over epoch:  27 0.9584125\n",
      "Validation loss:  27 0.20604344\n",
      "Validation acc:  27 0.9592111\n",
      "epoch 27: loss = 0.20921192\n",
      "Start of epoch 28\n",
      "Training loss over epoch:  28 0.20891805\n",
      "Training acc over epoch:  28 0.95838517\n",
      "Validation loss:  28 0.20375887\n",
      "Validation acc:  28 0.9592111\n",
      "epoch 28: loss = 0.20891804\n",
      "Start of epoch 29\n",
      "Training loss over epoch:  29 0.20839459\n",
      "Training acc over epoch:  29 0.9584137\n",
      "Validation loss:  29 0.20245716\n",
      "Validation acc:  29 0.9592111\n",
      "epoch 29: loss = 0.20839457\n",
      "Start of epoch 30\n",
      "Training loss over epoch:  30 0.20682937\n",
      "Training acc over epoch:  30 0.95842916\n",
      "Validation loss:  30 0.20096308\n",
      "Validation acc:  30 0.9592111\n",
      "epoch 30: loss = 0.20682934\n",
      "Start of epoch 31\n",
      "Training loss over epoch:  31 0.205518\n",
      "Training acc over epoch:  31 0.9584434\n",
      "Validation loss:  31 0.1995697\n",
      "Validation acc:  31 0.9592111\n",
      "epoch 31: loss = 0.20551798\n",
      "Start of epoch 32\n",
      "Training loss over epoch:  32 0.20486264\n",
      "Training acc over epoch:  32 0.95841014\n",
      "Validation loss:  32 0.1986793\n",
      "Validation acc:  32 0.9592111\n",
      "epoch 32: loss = 0.20486264\n",
      "Start of epoch 33\n",
      "Training loss over epoch:  33 0.20392857\n",
      "Training acc over epoch:  33 0.9584481\n",
      "Validation loss:  33 0.19821481\n",
      "Validation acc:  33 0.9592111\n",
      "epoch 33: loss = 0.20392859\n",
      "Start of epoch 34\n",
      "Training loss over epoch:  34 0.20391203\n",
      "Training acc over epoch:  34 0.95838636\n",
      "Validation loss:  34 0.19759154\n",
      "Validation acc:  34 0.9592111\n",
      "epoch 34: loss = 0.20391205\n",
      "Start of epoch 35\n",
      "Training loss over epoch:  35 0.2030862\n",
      "Training acc over epoch:  35 0.95843863\n",
      "Validation loss:  35 0.19697571\n",
      "Validation acc:  35 0.9592111\n",
      "epoch 35: loss = 0.20308617\n",
      "Start of epoch 36\n",
      "Training loss over epoch:  36 0.20322342\n",
      "Training acc over epoch:  36 0.95842916\n",
      "Validation loss:  36 0.19728528\n",
      "Validation acc:  36 0.9592111\n",
      "epoch 36: loss = 0.20322342\n",
      "Start of epoch 37\n",
      "Training loss over epoch:  37 0.20264573\n",
      "Training acc over epoch:  37 0.9584042\n",
      "Validation loss:  37 0.19642714\n",
      "Validation acc:  37 0.9592111\n",
      "epoch 37: loss = 0.20264573\n",
      "Start of epoch 38\n",
      "Training loss over epoch:  38 0.20231262\n",
      "Training acc over epoch:  38 0.9584208\n",
      "Validation loss:  38 0.19613555\n",
      "Validation acc:  38 0.9592111\n",
      "epoch 38: loss = 0.20231263\n",
      "Start of epoch 39\n",
      "Training loss over epoch:  39 0.20207316\n",
      "Training acc over epoch:  39 0.9584018\n",
      "Validation loss:  39 0.19593151\n",
      "Validation acc:  39 0.9592111\n",
      "epoch 39: loss = 0.20207316\n",
      "Start of epoch 40\n",
      "Training loss over epoch:  40 0.20195934\n",
      "Training acc over epoch:  40 0.95843625\n",
      "Validation loss:  40 0.19564809\n",
      "Validation acc:  40 0.9592111\n",
      "epoch 40: loss = 0.20195933\n",
      "Start of epoch 41\n",
      "Training loss over epoch:  41 0.2015392\n",
      "Training acc over epoch:  41 0.95843744\n",
      "Validation loss:  41 0.19610192\n",
      "Validation acc:  41 0.9592111\n",
      "epoch 41: loss = 0.20153925\n",
      "Start of epoch 42\n",
      "Training loss over epoch:  42 0.20141493\n",
      "Training acc over epoch:  42 0.95843863\n",
      "Validation loss:  42 0.194962\n",
      "Validation acc:  42 0.9592111\n",
      "epoch 42: loss = 0.20141491\n",
      "Start of epoch 43\n",
      "Training loss over epoch:  43 0.20095906\n",
      "Training acc over epoch:  43 0.95845765\n",
      "Validation loss:  43 0.19483179\n",
      "Validation acc:  43 0.9592111\n",
      "epoch 43: loss = 0.20095909\n",
      "Start of epoch 44\n",
      "Training loss over epoch:  44 0.20090838\n",
      "Training acc over epoch:  44 0.95845765\n",
      "Validation loss:  44 0.19467726\n",
      "Validation acc:  44 0.9592111\n",
      "epoch 44: loss = 0.20090838\n",
      "Start of epoch 45\n",
      "Training loss over epoch:  45 0.20052983\n",
      "Training acc over epoch:  45 0.95846593\n",
      "Validation loss:  45 0.19435301\n",
      "Validation acc:  45 0.9592111\n",
      "epoch 45: loss = 0.20052984\n",
      "Start of epoch 46\n",
      "Training loss over epoch:  46 0.20035627\n",
      "Training acc over epoch:  46 0.9584256\n",
      "Validation loss:  46 0.19407126\n",
      "Validation acc:  46 0.9592111\n",
      "epoch 46: loss = 0.20035626\n",
      "Start of epoch 47\n",
      "Training loss over epoch:  47 0.20000586\n",
      "Training acc over epoch:  47 0.95838875\n",
      "Validation loss:  47 0.193888\n",
      "Validation acc:  47 0.9592111\n",
      "epoch 47: loss = 0.20000586\n",
      "Start of epoch 48\n",
      "Training loss over epoch:  48 0.19987625\n",
      "Training acc over epoch:  48 0.95838517\n",
      "Validation loss:  48 0.19352566\n",
      "Validation acc:  48 0.9592111\n",
      "epoch 48: loss = 0.19987625\n",
      "Start of epoch 49\n",
      "Training loss over epoch:  49 0.19948314\n",
      "Training acc over epoch:  49 0.95840776\n",
      "Validation loss:  49 0.19311143\n",
      "Validation acc:  49 0.9592111\n",
      "epoch 49: loss = 0.19948314\n",
      "Start of epoch 50\n",
      "Training loss over epoch:  50 0.19925568\n",
      "Training acc over epoch:  50 0.9584125\n",
      "Validation loss:  50 0.19305208\n",
      "Validation acc:  50 0.9592111\n",
      "epoch 50: loss = 0.19925569\n",
      "Start of epoch 51\n",
      "Training loss over epoch:  51 0.19915855\n",
      "Training acc over epoch:  51 0.9583757\n",
      "Validation loss:  51 0.19260694\n",
      "Validation acc:  51 0.9592111\n",
      "epoch 51: loss = 0.19915855\n",
      "Start of epoch 52\n",
      "Training loss over epoch:  52 0.19882677\n",
      "Training acc over epoch:  52 0.95834124\n",
      "Validation loss:  52 0.19272946\n",
      "Validation acc:  52 0.9592111\n",
      "epoch 52: loss = 0.19882683\n",
      "Start of epoch 53\n",
      "Training loss over epoch:  53 0.19849542\n",
      "Training acc over epoch:  53 0.95845884\n",
      "Validation loss:  53 0.19250198\n",
      "Validation acc:  53 0.9592111\n",
      "epoch 53: loss = 0.1984954\n",
      "Start of epoch 54\n",
      "Training loss over epoch:  54 0.1983579\n",
      "Training acc over epoch:  54 0.9584505\n",
      "Validation loss:  54 0.19186598\n",
      "Validation acc:  54 0.9592111\n",
      "epoch 54: loss = 0.19835791\n",
      "Start of epoch 55\n",
      "Training loss over epoch:  55 0.19778477\n",
      "Training acc over epoch:  55 0.95852536\n",
      "Validation loss:  55 0.19158897\n",
      "Validation acc:  55 0.9592111\n",
      "epoch 55: loss = 0.1977848\n",
      "Start of epoch 56\n",
      "Training loss over epoch:  56 0.1981532\n",
      "Training acc over epoch:  56 0.9584042\n",
      "Validation loss:  56 0.19185749\n",
      "Validation acc:  56 0.9592111\n",
      "epoch 56: loss = 0.19815317\n",
      "Start of epoch 57\n",
      "Training loss over epoch:  57 0.19754449\n",
      "Training acc over epoch:  57 0.95843744\n",
      "Validation loss:  57 0.19133528\n",
      "Validation acc:  57 0.9592111\n",
      "epoch 57: loss = 0.19754452\n",
      "Start of epoch 58\n",
      "Training loss over epoch:  58 0.19759278\n",
      "Training acc over epoch:  58 0.9584493\n",
      "Validation loss:  58 0.19119224\n",
      "Validation acc:  58 0.9592111\n",
      "epoch 58: loss = 0.19759275\n",
      "Start of epoch 59\n",
      "Training loss over epoch:  59 0.19775155\n",
      "Training acc over epoch:  59 0.95836145\n",
      "Validation loss:  59 0.19140229\n",
      "Validation acc:  59 0.9592111\n",
      "epoch 59: loss = 0.19775157\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 834/834 [00:23<00:00, 35.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average imputation accuracyon test data with 0.2 missing genotypes is 0.9590: \n",
      "Sensitivity: 0.281704327363932\n",
      "Specificity: 0.7588822592388104\n",
      "F1-score macro: 0.29795880189925994\n",
      "F1-score micro: 0.9590012200765703\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ],
   "metadata": {
    "id": "ifLke-oWc1Ok"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1lo9cmptjRRESsVlVECvlJFHbLeaygq2s",
     "timestamp": 1640128751823
    },
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/perceiver_image_classification.ipynb",
     "timestamp": 1621552889682
    }
   ],
   "toc_visible": true,
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
