{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13258,
     "status": "ok",
     "timestamp": 1694108097224,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "s-9aa8yrHj9j",
    "outputId": "d806c69c-7cc2-4d94-f298-fa8689ac157f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13696,
     "status": "ok",
     "timestamp": 1694108110912,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "liJJGzQp4qzO",
    "outputId": "04098ab8-7833-47a8-e363-ad1d9a691f8d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m612.1/612.1 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "!pip install pyyaml h5py\n",
    "!pip install toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3341,
     "status": "ok",
     "timestamp": 1694108114240,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "ZWzi3Z3L5RO2",
    "outputId": "e07663fd-c131-472c-d326-296ee119f3ff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
      "Tensorflow version 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjGOO5PdFPf7"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2366,
     "status": "ok",
     "timestamp": 1694108116596,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "odmhCqSVFPf8",
    "outputId": "193337e4-03cb-465a-e5ae-f913e57c3f5b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"MODIN_CPUS\"] = \"8\"\n",
    "# from distributed import Client\n",
    "# client = Client()\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "# import allel\n",
    "from scipy.spatial.distance import squareform\n",
    "%matplotlib inline\n",
    "from toolz import interleave\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLd26RspFhaS"
   },
   "source": [
    "## Hardware Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31480,
     "status": "ok",
     "timestamp": 1694108148074,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "SLd7mAFgFUnR",
    "outputId": "488278cf-4f01-418c-fef4-c665609d2c4a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on TPU  grpc://10.126.251.74:8470\n",
      "N_REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on GPU')\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.TPUStrategy(TPU)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "N_REPLICAS = strategy.num_replicas_in_sync\n",
    "# Number of computing cores, is 8 for a TPU V3-8\n",
    "print(f'N_REPLICAS: {N_REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A77GFE3xFPf8"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j3zy8i_8FPf_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190095,
     "user_tz": 240,
     "elapsed": 42025,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "# load genotype\n",
    "genotypes = pd.read_csv('[data_dir]/genotype_full.txt', sep='\\t', index_col=0)\n",
    "genotypes[genotypes == -1] = 0\n",
    "\n",
    "headers = genotypes.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1694108190095,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "H2LdnKzXnW0P",
    "outputId": "e0749737-cb3b-4ca2-8dc3-cc00ae550adb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       33070_chrI_33070_A_T  33147_chrI_33147_G_T  33152_chrI_33152_T_C  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     0                     0                     0   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     0                     0                     0   \n",
       "\n",
       "       33200_chrI_33200_C_T  33293_chrI_33293_A_T  33328_chrI_33328_C_A  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     0                     0                     0   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     0                     0                     0   \n",
       "\n",
       "       33348_chrI_33348_G_C  33403_chrI_33403_C_T  33502_chrI_33502_A_G  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     0                     0                     0   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     0                     0                     0   \n",
       "\n",
       "       33548_chrI_33548_A_C  ...  12048853_chrXVI_925593_G_C  \\\n",
       "SAMID                        ...                               \n",
       "01_01                     1  ...                           0   \n",
       "01_02                     1  ...                           0   \n",
       "01_03                     0  ...                           1   \n",
       "01_04                     1  ...                           1   \n",
       "01_06                     0  ...                           0   \n",
       "\n",
       "       12049199_chrXVI_925939_T_C  12049441_chrXVI_926181_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           0                           0   \n",
       "01_02                           0                           0   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           0                           0   \n",
       "\n",
       "       12050613_chrXVI_927353_T_G  12051167_chrXVI_927907_A_C  \\\n",
       "SAMID                                                           \n",
       "01_01                           0                           0   \n",
       "01_02                           0                           0   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           0                           0   \n",
       "\n",
       "       12051240_chrXVI_927980_A_G  12051367_chrXVI_928107_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           0                           0   \n",
       "01_02                           0                           0   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           0                           0   \n",
       "\n",
       "       12052782_chrXVI_929522_C_T  12052988_chrXVI_929728_A_G  \\\n",
       "SAMID                                                           \n",
       "01_01                           0                           0   \n",
       "01_02                           0                           0   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           0                           0   \n",
       "\n",
       "       12053130_chrXVI_929870_C_T  \n",
       "SAMID                              \n",
       "01_01                           0  \n",
       "01_02                           0  \n",
       "01_03                           1  \n",
       "01_04                           1  \n",
       "01_06                           0  \n",
       "\n",
       "[5 rows x 28220 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-6971f222-1f75-4981-9cb3-1841ff0be3ce\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33070_chrI_33070_A_T</th>\n",
       "      <th>33147_chrI_33147_G_T</th>\n",
       "      <th>33152_chrI_33152_T_C</th>\n",
       "      <th>33200_chrI_33200_C_T</th>\n",
       "      <th>33293_chrI_33293_A_T</th>\n",
       "      <th>33328_chrI_33328_C_A</th>\n",
       "      <th>33348_chrI_33348_G_C</th>\n",
       "      <th>33403_chrI_33403_C_T</th>\n",
       "      <th>33502_chrI_33502_A_G</th>\n",
       "      <th>33548_chrI_33548_A_C</th>\n",
       "      <th>...</th>\n",
       "      <th>12048853_chrXVI_925593_G_C</th>\n",
       "      <th>12049199_chrXVI_925939_T_C</th>\n",
       "      <th>12049441_chrXVI_926181_C_T</th>\n",
       "      <th>12050613_chrXVI_927353_T_G</th>\n",
       "      <th>12051167_chrXVI_927907_A_C</th>\n",
       "      <th>12051240_chrXVI_927980_A_G</th>\n",
       "      <th>12051367_chrXVI_928107_C_T</th>\n",
       "      <th>12052782_chrXVI_929522_C_T</th>\n",
       "      <th>12052988_chrXVI_929728_A_G</th>\n",
       "      <th>12053130_chrXVI_929870_C_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_04</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28220 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6971f222-1f75-4981-9cb3-1841ff0be3ce')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6971f222-1f75-4981-9cb3-1841ff0be3ce button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6971f222-1f75-4981-9cb3-1841ff0be3ce');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-e541c44c-5edf-4ebb-a9af-412d04c8901f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e541c44c-5edf-4ebb-a9af-412d04c8901f')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-e541c44c-5edf-4ebb-a9af-412d04c8901f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "genotypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1694108190096,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "hiP0EEwsEMNP",
    "outputId": "e7e70d44-cf9f-4551-cd49-7c9cda2c087b"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4390, 28220)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X = genotypes\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_pZoO-FvKdr3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190097,
     "user_tz": 240,
     "elapsed": 29,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "feature_size = X.shape[1]\n",
    "inChannel = 3\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.00001\n",
    "embed_dim = 64  # Embedding size for each token\n",
    "num_heads = 8 # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "regularization_coef_l1 = 1e-4\n",
    "batch_size = 20\n",
    "dropout_rate = 0.25\n",
    "chunk_size = 3000\n",
    "flanking_region_range = chunk_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtSxW2eMOOCU"
   },
   "source": [
    "## Convert to tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KDiVoe67JHcy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190098,
     "user_tz": 240,
     "elapsed": 27,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def add_attention_mask(X_sample, y_sample):\n",
    "  depth = 3\n",
    "  mask_size = tf.cast(X_sample.shape[0]*0.5, dtype=tf.int64)\n",
    "  mask_idx = tf.reshape(tf.random.shuffle(tf.range(X_sample.shape[0]))[:mask_size], (-1, 1))\n",
    "  updates = tf.math.add(tf.ones(shape=(mask_idx.shape[0]), dtype=tf.int64), 1)\n",
    "  X_masked = tf.tensor_scatter_nd_update(X_sample, mask_idx, updates)\n",
    "\n",
    "  return tf.one_hot(X_masked, depth), tf.one_hot(y_sample, depth-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SlyxYCy96H7V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190098,
     "user_tz": 240,
     "elapsed": 25,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "def map_values_1(x):\n",
    "  return 0 if (x == 0 or x == 1) else 1\n",
    "\n",
    "def map_values_2(x):\n",
    "  return 0 if (x == 0 or x == 2) else 1\n",
    "\n",
    "def get_dataset(x, chunk_start, chunk_end, start_offset, end_offset, batch_size, training=True):\n",
    "  AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "  new_chunk_end = x.shape[1]\n",
    "\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x,\n",
    "                                                x[:, start_offset:new_chunk_end-end_offset]))\n",
    "  # # Add Attention Mask\n",
    "\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(x.shape[0], reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "  # Add Attention Mask\n",
    "  dataset = dataset.map(add_attention_mask, num_parallel_calls=AUTO, deterministic=False)\n",
    "\n",
    "  # Prefetech to not map the whole dataset\n",
    "  dataset = dataset.prefetch(AUTO)\n",
    "\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=True, num_parallel_calls=AUTO)\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpRUjMp_L914"
   },
   "source": [
    "## Custom Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sD7WOyyoNYGv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190099,
     "user_tz": 240,
     "elapsed": 24,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "class SharedNet(tf.keras.Model):\n",
    "    def __init__(self, conv1_n_filters, conv2_n_filters, conv1_kernel_size, conv2_kernel_size, fc_len, start_offset, end_offset, n_features_out):\n",
    "        super(SharedNet, self).__init__()\n",
    "        self.fc_len = fc_len\n",
    "        self.start_offset = start_offset\n",
    "        self.end_offset = end_offset\n",
    "        self.n_features_out = n_features_out\n",
    "        self.conv1 = layers.Conv1D(conv1_n_filters, kernel_size=conv1_kernel_size, strides=1, padding='same', activation=tf.nn.relu)\n",
    "        self.pool1 = layers.MaxPooling1D(2)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.do1 = layers.Dropout(0.5)\n",
    "        self.conv2 = layers.Conv1D(conv2_n_filters, kernel_size=conv2_kernel_size, strides=1, padding='same', activation=tf.nn.relu)\n",
    "        self.pool2 = layers.MaxPooling1D(2)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.do2 = layers.Dropout(0.5)\n",
    "        # self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(4*(inChannel-1), activation=tf.nn.relu)\n",
    "        self.reshape = layers.Reshape((-1, inChannel-1))\n",
    "        # self.fc1 = layers.Dense(inChannel-1, activation=tf.nn.relu)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "      self.input_len = input_shape[1]\n",
    "      # self.reshape = layers.Reshape((self.input_len, self.fc_len))\n",
    "      # super(SharedNet, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        # x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.reshape(x)\n",
    "        return x[:, self.start_offset:self.input_len-self.end_offset,]\n",
    "\n",
    "\n",
    "class EachNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EachNet, self).__init__()\n",
    "        self.fc1 = layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dropout(inputs)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modules"
   ],
   "metadata": {
    "id": "HqmHhclvOPiU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def chunk_module(conv1_n_filters, conv2_n_filters,\n",
    "                conv1_kernel_size, conv2_kernel_size,\n",
    "                input_len, inChannel, fc_len=256,\n",
    "                start_offset=0, end_offset=0):\n",
    "  inputs = layers.Input(shape=(input_len, inChannel))\n",
    "  n_features_out = input_len - start_offset - end_offset\n",
    "  xa = SharedNet(conv1_n_filters, conv2_n_filters, conv1_kernel_size, conv2_kernel_size, fc_len, start_offset, end_offset, n_features_out)(inputs)\n",
    "  xa_out1 = EachNet(inChannel-1)(xa)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=xa_out1)\n",
    "  return model"
   ],
   "metadata": {
    "id": "tE4IWuS-N9cp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190100,
     "user_tz": 240,
     "elapsed": 24,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCkow4q5MJk_"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vgGz9_6u8u-O",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190101,
     "user_tz": 240,
     "elapsed": 22,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "class DEEP_HLA(keras.Model):\n",
    "  def __init__(\n",
    "      self, in_channel,\n",
    "      conv1_n_filters, conv2_n_filters,\n",
    "      conv1_kernel_size, conv2_kernel_size,\n",
    "      chunk_size=chunk_size,\n",
    "      activation=tf.nn.relu,\n",
    "      dropout_rate=0.5,\n",
    "      flanking_region_range=flanking_region_range):\n",
    "    super(DEEP_HLA, self).__init__()\n",
    "    self.in_channel = in_channel\n",
    "    self.embed_dim = embed_dim\n",
    "    self.conv1_n_filters = conv1_n_filters\n",
    "    self.conv2_n_filters = conv2_n_filters\n",
    "    self.conv1_kernel_size = conv1_kernel_size\n",
    "    self.conv2_kernel_size = conv2_kernel_size\n",
    "    self.chunk_size = chunk_size\n",
    "    self.activation = activation\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.flanking_region_range = flanking_region_range\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.chunk_starts = list(range(0, input_shape[1], self.chunk_size))\n",
    "    self.chunk_ends = []\n",
    "    for cs in self.chunk_starts:\n",
    "      self.chunk_ends.append(min(cs+self.chunk_size, input_shape[1]))\n",
    "    self.mask_starts = [max(0, cs-self.flanking_region_range) for cs in self.chunk_starts]\n",
    "    self.mask_ends = [min(ce+self.flanking_region_range, input_shape[1]) for ce in self.chunk_ends]\n",
    "    self.chunkers = [chunk_module(self.conv1_n_filters, self.conv2_n_filters,\n",
    "                                  self.conv1_kernel_size, self.conv2_kernel_size,\n",
    "                                  self.mask_ends[i] - self.mask_starts[i],\n",
    "                                  self.in_channel,\n",
    "                                  start_offset=cs - self.mask_starts[i],\n",
    "                                  end_offset=self.mask_ends[i]-self.chunk_ends[i]) for i,cs in enumerate(self.chunk_starts)]\n",
    "    self.concat_layer = layers.Concatenate(axis=-2)\n",
    "    super(DEEP_HLA, self).build(input_shape)\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    chunks = [self.chunkers[i](inputs[:, self.mask_starts[i]:self.mask_ends[i]]) for i, chunker in enumerate(self.chunkers)]\n",
    "    y = self.concat_layer(chunks)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vcbAoT90Ihvc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108190101,
     "user_tz": 240,
     "elapsed": 20,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "def create_model(base_dim = 512):\n",
    "  model =  DEEP_HLA(in_channel=inChannel,\n",
    "      conv1_n_filters=base_dim, conv2_n_filters=base_dim//2,\n",
    "      conv1_kernel_size=base_dim//2, conv2_kernel_size=base_dim//2)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  model.compile(optimizer, loss='categorical_crossentropy', metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = create_model()\n",
    "model.build((1, feature_size, inChannel))\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Py1VVVTfdf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108192413,
     "user_tz": 240,
     "elapsed": 2330,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    },
    "outputId": "48a062f9-5b0e-4d3d-bfb3-a8ed14bb8bbb"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"deep_hla\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_2 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_3 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_6 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_7 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_8 (Functional)        (None, 3000, 2)           33953550  \n",
      "                                                                 \n",
      " model_9 (Functional)        (None, 1220, 2)           33953550  \n",
      "                                                                 \n",
      " concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339,535,500\n",
      "Trainable params: 339,520,140\n",
      "Non-trainable params: 15,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "61EgnuNmoFLT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108192415,
     "user_tz": 240,
     "elapsed": 12,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "outputs": [],
   "source": [
    "METRIC = \"val_loss\"\n",
    "\n",
    "def create_callbacks(kfold=0, metric = METRIC):\n",
    "\n",
    "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor= metric,\n",
    "        mode='auto',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor= metric,\n",
    "        mode='auto',\n",
    "        patience= 20,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "                 reducelr,\n",
    "                 earlystop]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOA_NexzN5Qq"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "save_dir = \"./drive/MyDrive/ShiLab/YEAST/DEEP_HLA/\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "  # shutil.rmtree(save_dir)\n",
    "  os.makedirs(save_dir)"
   ],
   "metadata": {
    "id": "JW5woVoYH6ie",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108192577,
     "user_tz": 240,
     "elapsed": 172,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1694108192699,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     },
     "user_tz": 240
    },
    "id": "Ey5lpPElXlUd",
    "outputId": "48062400-2da4-44ca-a86a-0c54eff0d1a6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# A TPU V3-8 has 8 computing cores, the global batch size will be 1/16 x 8 = 8/128\n",
    "BATCH_SIZE_BASE = 4\n",
    "# Training configuration\n",
    "BATCH_SIZE = BATCH_SIZE_BASE * N_REPLICAS if TPU else 32\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Timing test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "N_SPLITS=3\n",
    "NUM_EPOCHS = 1000\n",
    "results = None\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n",
    "fold = 0\n",
    "_x = X.to_numpy()\n",
    "for train_index, test_index in kf.split(_x):\n",
    "  fold += 1\n",
    "  if fold != 1:\n",
    "    continue\n",
    "  accuracies = []\n",
    "  print(f\"Training using fold {fold}\")\n",
    "\n",
    "  x_train = _x[train_index]\n",
    "  test_dataset = _x[test_index]\n",
    "  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n",
    "                                      random_state=fold,\n",
    "                                      shuffle=True,)\n",
    "\n",
    "  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n",
    "  validation_steps = x_valid.shape[0]//BATCH_SIZE\n",
    "  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n",
    "  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n",
    "\n",
    "  K.clear_session()\n",
    "  callbacks = create_callbacks()\n",
    "  with strategy.scope():\n",
    "    model = create_model()\n",
    "    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=1,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks, verbose=1)\n",
    "  for missing_perc in [ 0.1,\n",
    "                        0.2\n",
    "                        ]:\n",
    "    save_name = save_dir + f\"preds_mixed_mr_{missing_perc}_fold_{fold}_probs\"\n",
    "    avg_accuracy = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    to_save_array = np.zeros((test_dataset.shape[0], test_dataset.shape[1], inChannel-1), dtype=np.float32)\n",
    "    test_X_missing = np.copy(test_dataset)\n",
    "    test_X_missing = to_categorical(test_X_missing, 3)\n",
    "\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n",
    "      # mMask = np.tile(attention_mask, (1, 1, 1))\n",
    "      # predict\n",
    "    predict_onehot = model.predict(test_X_missing, verbose=1)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQJXTcI_s9RD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694108607179,
     "user_tz": 240,
     "elapsed": 414484,
     "user": {
      "displayName": "net crowmaster",
      "userId": "14126946344391667924"
     }
    },
    "outputId": "69bd5c15-f870-43bc-ab6f-4ee788e5c372"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training using fold 1\n",
      "82/82 [==============================] - 272s 2s/step - loss: 0.4042 - categorical_accuracy: 0.7398 - val_loss: 0.5340 - val_categorical_accuracy: 0.8125 - lr: 0.0100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1464/1464 [00:00<00:00, 4988.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46/46 [==============================] - 79s 2s/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1464/1464 [00:00<00:00, 3130.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46/46 [==============================] - 33s 719ms/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "N_SPLITS=3\n",
    "NUM_EPOCHS = 1000\n",
    "results = None\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n",
    "fold = 0\n",
    "_x = X.to_numpy()\n",
    "for train_index, test_index in kf.split(_x):\n",
    "  fold += 1\n",
    "  if fold != 3:\n",
    "    continue\n",
    "  accuracies = []\n",
    "  print(f\"Training using fold {fold}\")\n",
    "\n",
    "  x_train = _x[train_index]\n",
    "  test_dataset = _x[test_index]\n",
    "  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n",
    "                                      random_state=fold,\n",
    "                                      shuffle=True,)\n",
    "\n",
    "  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n",
    "  validation_steps = x_valid.shape[0]//BATCH_SIZE\n",
    "  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n",
    "  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n",
    "\n",
    "  K.clear_session()\n",
    "  callbacks = create_callbacks()\n",
    "  with strategy.scope():\n",
    "    model = create_model()\n",
    "    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks, verbose=1)\n",
    "  for missing_perc in [\n",
    "                        0.01,\n",
    "                        0.05,\n",
    "                        0.1,\n",
    "                        0.2\n",
    "                        ]:\n",
    "    save_name = save_dir + f\"preds_mixed_mr_{missing_perc}_fold_{fold}_probs\"\n",
    "    avg_accuracy = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    to_save_array = np.zeros((test_dataset.shape[0], test_dataset.shape[1], inChannel-1), dtype=np.float32)\n",
    "    test_X_missing = np.copy(test_dataset)\n",
    "    test_X_missing = to_categorical(test_X_missing, 3)\n",
    "\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n",
    "      predict_onehot = model.predict(test_X_missing[i:i+1], verbose=0)\n",
    "      predict_missing_onehot = predict_onehot[:, missing_index, :]\n",
    "      # predict label\n",
    "      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n",
    "\n",
    "      preds.extend(predict_missing.ravel().tolist())\n",
    "\n",
    "      predict_haplotypes = np.argmax(predict_onehot, axis=2)\n",
    "      to_save_array[i] = predict_onehot[:]\n",
    "      # real label\n",
    "      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n",
    "      # label_missing = np.argmax(label_missing_onehot, axis=2)\n",
    "      label_missing = test_dataset[i:i + 1, missing_index]\n",
    "      true_labels.extend(label_missing.ravel().tolist())\n",
    "      # accuracy\n",
    "      correct_prediction = np.equal(predict_missing, label_missing)\n",
    "      accuracy = np.mean(correct_prediction)\n",
    "      # print('{}/{}, accuracy: {:.4f}'.format(\n",
    "      #     i, test_X_missing.shape[0], accuracy))\n",
    "\n",
    "      avg_accuracy.append(accuracy)\n",
    "\n",
    "    # df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n",
    "    # df.to_csv(save_name)\n",
    "    np.save(save_name, to_save_array)\n",
    "    print('The average imputation accuracy' \\\n",
    "          'on test data with {} missing genotypes is {:.4f}: '\n",
    "        .format(missing_perc, np.mean(avg_accuracy)))\n",
    "    cnf_matrix = confusion_matrix(true_labels, preds)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP)\n",
    "    print(f\"Sensitivity: {np.mean(TPR)}\")\n",
    "    print(f\"Specificity: {np.mean(TNR)}\")\n",
    "    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n",
    "    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n",
    "    accuracies.append(np.mean(avg_accuracy))\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YY5dshO_hNrs",
    "outputId": "d58b8bd9-b337-4452-9cfe-7136413c2d97"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training using fold 3\n",
      "Epoch 1/1000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ7TbkVjCnw8"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "N_SPLITS=3\n",
    "NUM_EPOCHS = 1000\n",
    "results = None\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n",
    "fold = 0\n",
    "_x = X.to_numpy()\n",
    "for train_index, test_index in kf.split(_x):\n",
    "  fold += 1\n",
    "  if fold != 2:\n",
    "    continue\n",
    "  accuracies = []\n",
    "  print(f\"Training using fold {fold}\")\n",
    "\n",
    "  x_train = _x[train_index]\n",
    "  test_dataset = _x[test_index]\n",
    "  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n",
    "                                      random_state=fold,\n",
    "                                      shuffle=True,)\n",
    "\n",
    "  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n",
    "  validation_steps = x_valid.shape[0]//BATCH_SIZE\n",
    "  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n",
    "  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n",
    "\n",
    "  K.clear_session()\n",
    "  callbacks = create_callbacks()\n",
    "  with strategy.scope():\n",
    "    model = create_model()\n",
    "    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks, verbose=1)\n",
    "  for missing_perc in [\n",
    "                        0.01,\n",
    "                        0.05,\n",
    "                        0.1,\n",
    "                        0.2\n",
    "                        ]:\n",
    "    save_name = save_dir + f\"preds_mixed_mr_{missing_perc}_fold_{fold}_probs\"\n",
    "    avg_accuracy = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    test_X_missing = np.copy(test_dataset)\n",
    "    test_X_missing = to_categorical(test_X_missing, 3)\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n",
    "      # mMask = np.tile(attention_mask, (1, 1, 1))\n",
    "      # predict\n",
    "    predict_onehot = model.predict(test_X_missing, verbose=1)\n",
    "    to_save_array = np.copy(predict_onehot)\n",
    "      # predict_onehot = model.predict([test_X_missing[i:i + 1, :, :], mMask])\n",
    "      # only care the missing position\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      predict_missing_onehot = predict_onehot[i:i+1, missing_index, :]\n",
    "      # predict label\n",
    "      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n",
    "\n",
    "      preds.extend(predict_missing.ravel().tolist())\n",
    "\n",
    "      predict_haplotypes = np.argmax(predict_onehot[i:i+1, :, :], axis=2)\n",
    "      # to_save_array[i] = np.where(predict_haplotypes==0, -1, 1)\n",
    "      # real label\n",
    "      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n",
    "      # label_missing = np.argmax(label_missing_onehot, axis=2)\n",
    "      label_missing = test_dataset[i:i + 1, missing_index]\n",
    "      true_labels.extend(label_missing.ravel().tolist())\n",
    "      # accuracy\n",
    "      correct_prediction = np.equal(predict_missing, label_missing)\n",
    "      accuracy = np.mean(correct_prediction)\n",
    "      # print('{}/{}, accuracy: {:.4f}'.format(\n",
    "      #     i, test_X_missing.shape[0], accuracy))\n",
    "\n",
    "      avg_accuracy.append(accuracy)\n",
    "\n",
    "    # df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n",
    "    # df.to_csv(save_name)\n",
    "    np.save(save_name, to_save_array)\n",
    "    print('The average imputation accuracy' \\\n",
    "          'on test data with {} missing genotypes is {:.4f}: '\n",
    "        .format(missing_perc, np.mean(avg_accuracy)))\n",
    "    cnf_matrix = confusion_matrix(true_labels, preds)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP)\n",
    "    print(f\"Sensitivity: {np.mean(TPR)}\")\n",
    "    print(f\"Specificity: {np.mean(TNR)}\")\n",
    "    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n",
    "    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n",
    "    accuracies.append(np.mean(avg_accuracy))\n",
    "\n"
   ],
   "metadata": {
    "id": "K2yuqWozxuMW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpjyNHRLUcjV"
   },
   "outputs": [],
   "source": [
    "N_SPLITS=3\n",
    "NUM_EPOCHS = 1000\n",
    "results = None\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=2022)\n",
    "fold = 0\n",
    "_x = X.to_numpy()\n",
    "for train_index, test_index in kf.split(_x):\n",
    "  fold += 1\n",
    "  if fold != 1:\n",
    "    continue\n",
    "  accuracies = []\n",
    "  print(f\"Training using fold {fold}\")\n",
    "\n",
    "  x_train = _x[train_index]\n",
    "  test_dataset = _x[test_index]\n",
    "  x_train, x_valid = train_test_split(x_train, test_size=0.10,\n",
    "                                      random_state=fold,\n",
    "                                      shuffle=True,)\n",
    "\n",
    "  steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n",
    "  validation_steps = x_valid.shape[0]//BATCH_SIZE\n",
    "  train_dataset = get_dataset(x_train, 0, feature_size, 0, 0, BATCH_SIZE)\n",
    "  valid_dataset = get_dataset(x_valid, 0, feature_size, 0, 0, BATCH_SIZE, training=False)\n",
    "\n",
    "  K.clear_session()\n",
    "  callbacks = create_callbacks()\n",
    "  with strategy.scope():\n",
    "    model = create_model()\n",
    "    history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks, verbose=1)\n",
    "  for missing_perc in [\n",
    "                        0.01,\n",
    "                        0.05,\n",
    "                        0.1,\n",
    "                        0.2\n",
    "                        ]:\n",
    "    save_name = save_dir + f\"preds_mixed_mr_{missing_perc}_fold_{fold}_probs\"\n",
    "    avg_accuracy = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    test_X_missing = np.copy(test_dataset)\n",
    "    test_X_missing = to_categorical(test_X_missing, 3)\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      test_X_missing[i:i+1, missing_index, :] = [0, 0, 1]\n",
    "      # mMask = np.tile(attention_mask, (1, 1, 1))\n",
    "      # predict\n",
    "    predict_onehot = model.predict(test_X_missing, verbose=1)\n",
    "    to_save_array = np.copy(predict_onehot)\n",
    "      # predict_onehot = model.predict([test_X_missing[i:i + 1, :, :], mMask])\n",
    "      # only care the missing position\n",
    "    for i in tqdm(list(range(test_dataset.shape[0]))):\n",
    "      rng = np.random.default_rng(i + fold)\n",
    "      # Generates missing genotypes\n",
    "      missing_size = int(missing_perc * test_X_missing.shape[1])\n",
    "      missing_index = rng.integers(low=0, high=test_X_missing.shape[1],\n",
    "                                        size=missing_size)\n",
    "      predict_missing_onehot = predict_onehot[i:i+1, missing_index, :]\n",
    "      # predict label\n",
    "      predict_missing = np.argmax(predict_missing_onehot, axis=2)\n",
    "\n",
    "      preds.extend(predict_missing.ravel().tolist())\n",
    "\n",
    "      predict_haplotypes = np.argmax(predict_onehot[i:i+1, :, :], axis=2)\n",
    "      # to_save_array[i] = np.where(predict_haplotypes==0, -1, 1)\n",
    "      # real label\n",
    "      label_missing_onehot = test_dataset[i:i + 1, missing_index]\n",
    "      # label_missing = np.argmax(label_missing_onehot, axis=2)\n",
    "      label_missing = test_dataset[i:i + 1, missing_index]\n",
    "      true_labels.extend(label_missing.ravel().tolist())\n",
    "      # accuracy\n",
    "      correct_prediction = np.equal(predict_missing, label_missing)\n",
    "      accuracy = np.mean(correct_prediction)\n",
    "      # print('{}/{}, accuracy: {:.4f}'.format(\n",
    "      #     i, test_X_missing.shape[0], accuracy))\n",
    "\n",
    "      avg_accuracy.append(accuracy)\n",
    "\n",
    "    # df = pd.DataFrame(to_save_array, columns= headers[:], index = test_index)\n",
    "    # df.to_csv(save_name)\n",
    "    np.save(save_name, to_save_array)\n",
    "    print('The average imputation accuracy' \\\n",
    "          'on test data with {} missing genotypes is {:.4f}: '\n",
    "        .format(missing_perc, np.mean(avg_accuracy)))\n",
    "    cnf_matrix = confusion_matrix(true_labels, preds)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP)\n",
    "    print(f\"Sensitivity: {np.mean(TPR)}\")\n",
    "    print(f\"Specificity: {np.mean(TNR)}\")\n",
    "    print(f\"F1-score macro: {f1_score(true_labels, preds, average='macro')}\")\n",
    "    print(f\"F1-score micro: {f1_score(true_labels, preds, average='micro')}\")\n",
    "    accuracies.append(np.mean(avg_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tTVTcGHXJFrW"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1lo9cmptjRRESsVlVECvlJFHbLeaygq2s",
     "timestamp": 1640128751823
    },
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/perceiver_image_classification.ipynb",
     "timestamp": 1621552889682
    }
   ],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
